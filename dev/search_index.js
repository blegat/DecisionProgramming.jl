var documenterSearchIndex = {"docs":
[{"location":"decision-programming/decision-model/#Decision-Model","page":"Decision Model","title":"Decision Model","text":"","category":"section"},{"location":"decision-programming/decision-model/#Formulation","page":"Decision Model","title":"Formulation","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"The model is based on [1], section 3. We highly recommend to read them for motivation, details, and proofs of the formulation explained here.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"The mixed-integer linear program maximizes the expected utility (1) over all decision strategies as follows.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"undersetZℤtextmaximizequad\n_sS π(s) mathcalU(s) tag1","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Subject to","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"z(s_js_I(j))  01quad jD s_jS_j s_I(j)S_I(j) tag2","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_s_jS_j z(s_js_I(j))=1quad jD s_I(j)S_I(j) tag3","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"0π(s)p(s)quad sS tag4","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"π(s)  z(s_js_I(j))quad jD sS tag5","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"π(s)  p(s) + _jD z(s_js_I(j)) - Dquad sS tag6","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Decision variables z are binary variables (2) that model different decision strategies. The condition (3) limits decisions s_j to one per information path s_I(j) Decision strategy Z_j(s_I(j))=s_j is equivalent to z(s_js_I(j))=1","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We denote the probability distribution of paths using π The path probability π(s) is between zero and the upper bound of the path probability (4). The path probability is zero on paths where at least one decision variable is zero (5) and equal to the upper bound on paths if all decision variables on the path are one (6).","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can omit the constraint (6) from the model if we use a positive utility function U^+ which is an affine transformation of utility function U As an example, we can normalize and add one to the original utility function.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"U^+(c) = fracU(c) - min_cℂU(c)max_cℂU(c) - min_cℂU(c) + 1","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"There are also alternative objectives and ways to model risk, which are discussed later.","category":"page"},{"location":"decision-programming/decision-model/#Lazy-Cuts","page":"Decision Model","title":"Lazy Cuts","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Probability sum cut","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_sSπ(s)=1 tag7","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Number of active paths cut","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_sS fracπ(s)p(s)=S^+ tag8","category":"page"},{"location":"decision-programming/decision-model/#Conditional-Value-at-Risk","page":"Decision Model","title":"Conditional Value-at-Risk","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Conditional Value at Risk (CVaR), [1], section 5.3","category":"page"},{"location":"decision-programming/decision-model/#References","page":"Decision Model","title":"References","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/#Model","page":"API Reference","title":"Model","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"paths\nInfluenceDiagram\nInfluenceDiagram(::Vector{Int}, ::Vector{Int}, ::Vector{Int}, ::Vector{Pair{Int, Int}}, ::Vector{Int})\nParams\nParams(::InfluenceDiagram, ::Dict{Int, Array{Float64}}, ::Dict{Int, Array{Float64}})\nDecisionModel\nDecisionModel(::InfluenceDiagram, ::Params)\nprobability_sum_cut\nnumber_of_paths_cut","category":"page"},{"location":"api/#DecisionProgramming.paths","page":"API Reference","title":"DecisionProgramming.paths","text":"Iterate over paths.\n\n\n\n\n\nIterate over paths with fixed states.\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.InfluenceDiagram","page":"API Reference","title":"DecisionProgramming.InfluenceDiagram","text":"Influence diagram.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.InfluenceDiagram-Tuple{Array{Int64,1},Array{Int64,1},Array{Int64,1},Array{Pair{Int64,Int64},1},Array{Int64,1}}","page":"API Reference","title":"DecisionProgramming.InfluenceDiagram","text":"Construct and validate an influence diagram.\n\nArguments\n\nC::Vector{Int}: Change nodes.\nD::Vector{Int}: Decision nodes.\nV::Vector{Int}: Value nodes.\nA::Vector{Pair{Int, Int}}: Arcs between nodes.\nS_j::Vector{Int}: Number of states.\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.Params","page":"API Reference","title":"DecisionProgramming.Params","text":"Decision model parameters.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.Params-Tuple{InfluenceDiagram,Dict{Int64,Array{Float64,N} where N},Dict{Int64,Array{Float64,N} where N}}","page":"API Reference","title":"DecisionProgramming.Params","text":"Construct and validate decision model parameters.\n\nArguments\n\ndiagram::InfluenceDiagram: The influence diagram associated with the probabilities and consequences.\nX::Dict{Int, Array{Float64}}: Probabilities\nY::Dict{Int, Array{Float64}}: Consequences\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.DecisionModel","page":"API Reference","title":"DecisionProgramming.DecisionModel","text":"Defines the DecisionModel type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DecisionModel-Tuple{InfluenceDiagram,Params}","page":"API Reference","title":"DecisionProgramming.DecisionModel","text":"Construct a DecisionModel from an influence diagram and parameters.\n\nArguments\n\ndiagram::InfluenceDiagram\nparams::Params\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.probability_sum_cut","page":"API Reference","title":"DecisionProgramming.probability_sum_cut","text":"Adds a probability sum cut to the model as a lazy constraint.\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.number_of_paths_cut","page":"API Reference","title":"DecisionProgramming.number_of_paths_cut","text":"Adds a number of paths cut to the model as a lazy constraint.\n\n\n\n\n\n","category":"function"},{"location":"api/#Analysis","page":"API Reference","title":"Analysis","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"active_paths\nis_compatible\nstate_probabilities\nutility_distribution","category":"page"},{"location":"api/#DecisionProgramming.active_paths","page":"API Reference","title":"DecisionProgramming.active_paths","text":"Generate all active paths from a decision strategy with fixed states.\n\n\n\n\n\nGenerate all active paths from a decision strategy.\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.is_compatible","page":"API Reference","title":"DecisionProgramming.is_compatible","text":"Test is path is compatible with a decision strategy.\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.state_probabilities","page":"API Reference","title":"DecisionProgramming.state_probabilities","text":"State probabilities.\n\n\n\n\n\nState probabilities.\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.utility_distribution","page":"API Reference","title":"DecisionProgramming.utility_distribution","text":"The probability distribution of utilities.\n\nusing Plots\nx, y = distribution(z, diagram, params)\ny2 = cumsum(y)\np = plot(x, y,\n    linestyle=:dash,\n    markershape=:circle,\n    ylims=(0, 1.1),\n    label=\"Distribution\",\n    legend=:topleft)\nplot!(p, x, y2,\n    linestyle=:dash,\n    markershape=:circle,\n    label=\"Cumulative distribution\")\nsavefig(p, \"distribution.svg\")\n\n\n\n\n\n","category":"function"},{"location":"api/#Printing","page":"API Reference","title":"Printing","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"print_results\nprint_decision_strategy\nprint_state_probabilities","category":"page"},{"location":"api/#DecisionProgramming.print_results","page":"API Reference","title":"DecisionProgramming.print_results","text":"Print number of paths, number of active paths and expected utility.\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_decision_strategy","page":"API Reference","title":"DecisionProgramming.print_decision_strategy","text":"Print decision strategy.\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_state_probabilities","page":"API Reference","title":"DecisionProgramming.print_state_probabilities","text":"Print state probabilities with fixed states.\n\n\n\n\n\nPrint state probabilities.\n\n\n\n\n\n","category":"function"},{"location":"api/#Random","page":"API Reference","title":"Random","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"random_influence_diagram\nrandom_params","category":"page"},{"location":"api/#DecisionProgramming.random_influence_diagram","page":"API Reference","title":"DecisionProgramming.random_influence_diagram","text":"Create random influence diagram of given size.\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.random_params","page":"API Reference","title":"DecisionProgramming.random_params","text":"Generate random params.\n\n\n\n\n\n","category":"function"},{"location":"decision-programming/complexity/#Complexity","page":"Complexity","title":"Complexity","text":"","category":"section"},{"location":"decision-programming/complexity/","page":"Complexity","title":"Complexity","text":"Number of paths","category":"page"},{"location":"decision-programming/complexity/","page":"Complexity","title":"Complexity","text":"S=_iCD S_i = _iC S_i  _iD S_i","category":"page"},{"location":"decision-programming/complexity/","page":"Complexity","title":"Complexity","text":"Probability stages","category":"page"},{"location":"decision-programming/complexity/","page":"Complexity","title":"Complexity","text":"_iC (S_I(i)S_i)","category":"page"},{"location":"decision-programming/complexity/","page":"Complexity","title":"Complexity","text":"Number of probability stages","category":"page"},{"location":"decision-programming/complexity/","page":"Complexity","title":"Complexity","text":"_iCS_I(i) S_i","category":"page"},{"location":"decision-programming/complexity/","page":"Complexity","title":"Complexity","text":"Decision stages","category":"page"},{"location":"decision-programming/complexity/","page":"Complexity","title":"Complexity","text":"_iD (S_I(i)S_i)","category":"page"},{"location":"decision-programming/complexity/","page":"Complexity","title":"Complexity","text":"Number of decision stages","category":"page"},{"location":"decision-programming/complexity/","page":"Complexity","title":"Complexity","text":"_iDS_I(i) S_i","category":"page"},{"location":"decision-programming/complexity/","page":"Complexity","title":"Complexity","text":"Utility stages","category":"page"},{"location":"decision-programming/complexity/","page":"Complexity","title":"Complexity","text":"_iV S_I(i)","category":"page"},{"location":"decision-programming/complexity/","page":"Complexity","title":"Complexity","text":"Number of utility stages","category":"page"},{"location":"decision-programming/complexity/","page":"Complexity","title":"Complexity","text":"_vVS_I(v)","category":"page"},{"location":"analysis/#Analysis","page":"Analysis","title":"Analysis","text":"","category":"section"},{"location":"analysis/#Utility-Distribution","page":"Analysis","title":"Utility Distribution","text":"","category":"section"},{"location":"analysis/#State-Probabilities","page":"Analysis","title":"State Probabilities","text":"","category":"section"},{"location":"analysis/","page":"Analysis","title":"Analysis","text":"We denote paths with fixed states where ϵ denotes an empty state using a recursive definition.","category":"page"},{"location":"analysis/","page":"Analysis","title":"Analysis","text":"beginaligned\nS_ϵ = S \nS_ϵs_i^ = sS_ϵ  s_i=s_i^ \nS_ϵs_i^s_j^ = sS_ϵs_i^  s_j=s_j^quad ji\nendaligned","category":"page"},{"location":"analysis/","page":"Analysis","title":"Analysis","text":"The probability of all paths sums to one","category":"page"},{"location":"analysis/","page":"Analysis","title":"Analysis","text":"ℙ(ϵ) = sum_sS_ϵ π(s) = 1","category":"page"},{"location":"analysis/","page":"Analysis","title":"Analysis","text":"State probabilities for each node iCD and state s_iS_i denote how likely the state occurs given all path probabilities","category":"page"},{"location":"analysis/","page":"Analysis","title":"Analysis","text":"ℙ(s_iϵ) = sum_sS_ϵs_i fracπ(s)ℙ(ϵ) = sum_sS_ϵs_i π(s)","category":"page"},{"location":"analysis/","page":"Analysis","title":"Analysis","text":"An active state is a state with positive state probability ℙ(s_ic)0 given conditions c","category":"page"},{"location":"analysis/","page":"Analysis","title":"Analysis","text":"We can generalize the state probabilities as conditional probabilities using a recursive definition. Generalized state probabilities allow us to explore how fixing active states affect the probabilities of other states. First, we choose an active state s_i and fix its value. Fixing an inactive state would make all state probabilities zero. Then, we can compute the conditional state probabilities as follows.","category":"page"},{"location":"analysis/","page":"Analysis","title":"Analysis","text":"ℙ(s_jϵs_i) = sum_sS_ϵs_is_j fracπ(s)ℙ(s_iϵ)","category":"page"},{"location":"analysis/","page":"Analysis","title":"Analysis","text":"We can then repeat this process by choosing an active state from the new conditional state probabilities s_k that is different from previously chosen states kj","category":"page"},{"location":"analysis/","page":"Analysis","title":"Analysis","text":"A robust recommendation is a decision state s_i where iD and subpath c such the state probability is one ℙ(s_ic)=1","category":"page"},{"location":"examples/n-monitoring/#N-Monitoring","page":"N-Monitoring","title":"N-Monitoring","text":"","category":"section"},{"location":"examples/n-monitoring/#Description","page":"N-Monitoring","title":"Description","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The N-monitoring problem is described in [1], sections 4.1 and 6.1.","category":"page"},{"location":"examples/n-monitoring/#Formulation","page":"N-Monitoring","title":"Formulation","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"(Image: )","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The 2-monitoring problem.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"(Image: )","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The incluence diagram of generalized N-monitoring problem where N1 and indices k=1N The nodes are associated with states as follows. Load state L=high low denotes the load, report states R_k=high low report the load state to the action states A_k=yes no which decide whether to fortificate failure state F=failure success Finally, the utility at target T depends on the whether F fails and the fortification costs.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"We draw the magnitude and cost of fortification c_kU(01) from a uniform distribution. Fortification is defined","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"f(A_k) =\nbegincases\nc_k  A_k=yes \n0  A_k=no\nendcases","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probability that the load is high. We draw xU(01) from uniform distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(L=high)=x","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probabilities of the report states correspond to the load state. We draw the values xU(01) and yU(01) from uniform distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(R_k=highL=high)=maxxx-1","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(R_k=lowL=low)=maxyy-1","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probabilities of failure which are decresead by fortifications. We draw the values zU(01) and wU(01) from uniform distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(F=failureA_NA_1L=high)=fraczexp(_k=1N f(A_k))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(F=failureA_NA_1L=low)=fracwexp(_k=1N f(A_k))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Utility from consequences at target T from failure state F","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"U(Y(F)) =\nbegincases\n0  F = failure \n100  F = success\nendcases","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Utility from consequences at target T from action states A_k","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"U(Y(A_k))=\nbegincases\n-c_k  A_k=yes \n0  A_k=no\nendcases","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Total utility at target T","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"U(Y(FA_NA_1))=U(Y(F))+_k=1N U(Y(A_k))","category":"page"},{"location":"examples/n-monitoring/#References","page":"N-Monitoring","title":"References","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"decision-programming/influence-diagram/#Influence-Diagram","page":"Influence Diagram","title":"Influence Diagram","text":"","category":"section"},{"location":"decision-programming/influence-diagram/#Definition","page":"Influence Diagram","title":"Definition","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(Image: )","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Based on [1], sections 3.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The paper [2] explains details about influence diagrams.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the influence diagram as a directed, acyclic graph such that part of its nodes have a finite number of states associated with them","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"G=(NAS_j)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The set of nodes N=CDV consists of chance nodes C decision nodes D and value nodes V. We index the nodes such that CD=1n and V=n+1n+V where n=C+D The set of arcs consists of pairs of nodes such that","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"A(ij)1ijNiV","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The condition enforces that the graph is directed and acyclic, and there are no arcs from value nodes to other nodes.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Each chance and decision node jCD is associates with a finite number of states S_j We use integers from one to number of states S_j to encode individual states","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"S_j=1S_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the information set of node jN to be its predecessor nodes","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"I(j)=i(ij)A","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Practically, the information set is an edge list to reverse direction in the graph.","category":"page"},{"location":"decision-programming/influence-diagram/#Paths","page":"Influence Diagram","title":"Paths","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Paths in influence diagrams represent realizations of states for chance and decision nodes. Formally, a path is a sequence of states","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"s=(s_1 s_2 s_n)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"where each state s_iS_i for all chance and decision nodes iCD","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define a subpath of s is a subsequence","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(s_i_1 s_i_2  s_i_k)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"where 1i_1i_2i_kn and kn","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The information path of node jN on path s is a subpath defined as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"s_I(j)=(s_i  iI(j))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Concatenation of two paths s and s^ is denoted ss^","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the set of all paths as a product set of all states","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"S=_jCD S_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The set of information paths of node jN is the product set of the states in its information set","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"S_I(j)=_iI(j) S_i","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We denote elements of the sets using notation s_jS_j, sS, and s_I(j)S_I(j)","category":"page"},{"location":"decision-programming/influence-diagram/#Probabilities","page":"Influence Diagram","title":"Probabilities","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"For each chance node jC, we denote the probability of state s_j given information path s_I(j) as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"ℙ(X_j=s_jX_I(j)=s_I(j))0 1","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the upper bound of path probability s as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"p(s) = _jC ℙ(X_j=s_jX_I(j)=s_I(j))","category":"page"},{"location":"decision-programming/influence-diagram/#Decisions","page":"Influence Diagram","title":"Decisions","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"For each decision node jD a local decision strategy maps an information path s_I(j) to a state s_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Z_jS_I(j)S_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Decision strategy Z contains one local decision strategy for each decision node. Set of all decision strategies is denoted ℤ","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"A decision stategy Zℤ is compatible with the path sS if and only if Z_j(s_I(j))=s_j forall Z_jZ and jD","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The probability of path s that is compatible with decision strategy Z is ℙ(sZ)=p(s) Otherwise, the path cannot occur ℙ(sZ)=0","category":"page"},{"location":"decision-programming/influence-diagram/#Active-Paths","page":"Influence Diagram","title":"Active Paths","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"An active path is path sS that is compatible with decision strategy Z We denote the set of all active paths using S^+ Since each decision strategy Z_j chooses only one state out of all of its states, the number of active paths is","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"S^+=Sprod_jDS_j=prod_jCS_j","category":"page"},{"location":"decision-programming/influence-diagram/#Consequences","page":"Influence Diagram","title":"Consequences","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"For each value node jV, we define the consequence given information path s_I(j) as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Y_jS_I(j)ℂ","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"where ℂ is the set of consequences. In the code, the consequences are implicit, and we map information paths directly to the utility values.","category":"page"},{"location":"decision-programming/influence-diagram/#Utilities","page":"Influence Diagram","title":"Utilities","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The utility function maps consequences to real-valued utilities","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Uℂℝ","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The utility of a path is defined as the sum of utilities for consequences of value nodes jV with information paths I(j)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"mathcalU(s) = _jV U(Y_j(s_I(j)))","category":"page"},{"location":"decision-programming/influence-diagram/#References","page":"Influence Diagram","title":"References","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"[2]: Bielza, C., Gómez, M., & Shenoy, P. P. (2011). A review of representation issues and modeling challenges with influence diagrams. Omega, 39(3), 227–241. https://doi.org/10.1016/j.omega.2010.07.003","category":"page"},{"location":"#DecisionProgramming.jl","page":"Home","title":"DecisionProgramming.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for DecisionProgramming.jl","category":"page"},{"location":"examples/pig-breeding/#Pig-Breeding","page":"Pig Breeding","title":"Pig Breeding","text":"","category":"section"},{"location":"examples/pig-breeding/#Description","page":"Pig Breeding","title":"Description","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The pig breeding problem as described in [1].","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"A pig breeder is growing pigs for a period of four months and subsequently selling them. During this period the pig may or may not develop a certain disease. If the pig has the disease at the time it must be sold, the pig must be sold for slaughtering, and its expected market price is then 300 DKK (Danish kroner). If it is disease free, its expected market price as a breeding animal is 1000 DKKOnce a month, a veterinary doctor sees the pig and makes a test for presence of the disease. If the pig is ill, the test will indicate this with probability 0.80, and if the pig is healthy, the test will indicate this with probability 0.90. At each monthly visit, the doctor may or may not treat the pig for the disease by injecting a certain drug. The cost of an injection is 100 DKK.A pig has the disease in the first month with probability 0.10. A healthy pig develops the disease in the subsequent month with probability 0.20 without injection, whereas a healthy and treated pig develops the disease with probability 0.10, so the injection has some preventive effect. An untreated pig that is unhealthy will remain so in the subsequent month with probability 0.90, whereas the similar probability is 0.50 for an unhealthy pig that is treated. Thus spontaneous cure is possible, but treatment is beneficial on average.","category":"page"},{"location":"examples/pig-breeding/#Formulation","page":"Pig Breeding","title":"Formulation","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"(Image: )","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The original 4-month formulation.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"(Image: )","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The influence diagram for the the generalized N-month pig breeding. The nodes are associated with the following states. Health states h_k=illhealthy represents the health of the pig at month k=1N. Test states t_k=positivenegative represents the result from testing the pig at month k=1N-1. Treat state d_k=treat pass represents the decision to treat the pig with an injection at month k=1N-1. The dashed arcs represent the no-forgetting principle and we can toggle them on and off in the formulation.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The probabilities that test indicates pig's health correctly at month k=1N-1.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(t_k = positive  h_k = ill) = 08","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(t_k = negative  h_k = healthy) = 09","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The probability that pig is ill in the first month.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_1 = ill)=01","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The probability that the pig is ill in the subsequent months k=2N given the treatment decision in and state of health in the previous month.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = pass h_k-1 = healthy)=02","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = treat h_k-1 = healthy)=01","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = pass h_k-1 = ill)=09","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = treat h_k-1 = ill)=05","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The cost of treatment decision for the pig at month k=1N-1","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"U(Y(d_k))=begincases\n-100  d_k = treat \n0  d_k = pass\nendcases","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The price of given the pig health at month N","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"U(Y(h_N))=begincases\n300  h_N = ill \n1000  h_N = healthy\nendcases","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Total utility","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"U(Y(h_Nd_N-1d_1))=U(Y(h_n))+_k=1N U(Y(d_k))","category":"page"},{"location":"examples/pig-breeding/#References","page":"Pig Breeding","title":"References","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"[1]: Lauritzen, S. L., & Nilsson, D. (2001). Representing and solving decision problems with limited information. Management Science, 47(9), 1235–1251. https://doi.org/10.1287/mnsc.47.9.1235.9779","category":"page"},{"location":"examples/contingent-portfolio-programming/#Contingent-Portfolio-Programming","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/#Decription","page":"Contingent Portfolio Programming","title":"Decription","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/#Formulation","page":"Contingent Portfolio Programming","title":"Formulation","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/#References","page":"Contingent Portfolio Programming","title":"References","text":"","category":"section"}]
}
