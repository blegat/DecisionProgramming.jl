var documenterSearchIndex = {"docs":
[{"location":"decision-programming/decision-model/#Decision-Model","page":"Decision Model","title":"Decision Model","text":"","category":"section"},{"location":"decision-programming/decision-model/#Introduction","page":"Decision Model","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Decision programming aims to find a decision strategy Z which optimizes some metric of the path distribution on an influence diagram such as expected value or risk. The decision model is a mixed-integer linear programming formulation of this optimization problem. The model that is presented here, is based on [1], sections 3 and 5. We recommend reading it for motivation, details, and proofs of the formulation.","category":"page"},{"location":"decision-programming/decision-model/#Formulation","page":"Decision Model","title":"Formulation","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"The mixed-integer linear program maximizes a linear objective function f that acts on the path distribution over all decision strategies as follows.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"undersetZℤtextmaximizequad\nf((ℙ(𝐬Z) mathcalU(𝐬))  𝐬𝐒) tag1","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Decision variables z(s_j𝐬_I(j)) are equivalent to the decision strategies Z such that Z_j(𝐬_I(j))=s_j if and only if z(s_j𝐬_I(j))=1 and z(s_j^𝐬_I(j))=0 for all s_j^s_j Constraint (2) defines the decisions to be binary variables and the constraint (3) limits decisions to one per information path.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"z(𝐬_j𝐬_I(j))  01quad jD 𝐬_j𝐒_j 𝐬_I(j)𝐒_I(j) tag2","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_s_jS_j z(s_j𝐬_I(j))=1quad jD 𝐬_I(j)𝐒_I(j) tag3","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Path probability variables π(𝐬) are equivalent to the path probabilities ℙ(𝐬Z) where decision variables z define the decision strategy Z. The constraint (4) defines the lower and upper bound to the probability, constraint (5) defines that the probability equals zero if path is not compatible with the decision strategy, and constraint (6) defines that probability equals path probability if the path is compatible with the decision strategy.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"0π(𝐬)p(𝐬)quad 𝐬𝐒 tag4","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"π(𝐬)  z(𝐬_j𝐬_I(j))quad jD 𝐬𝐒 tag5","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"π(𝐬)  p(𝐬) + _jD z(𝐬_j𝐬_I(j)) - Dquad 𝐬𝐒 tag6","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can omit the constraint (6) from the model if we use a positive path utility function mathcalU^+ which is an affine transformation of path utility function mathcalU As an example, we can normalize the original utility function and then add one as follows.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"mathcalU^+(𝐬) = fracmathcalU(𝐬) - min_𝐬𝐒 mathcalU(𝐬)max_𝐬𝐒 mathcalU(𝐬) - min_𝐬𝐒 mathcalU(𝐬) + 1","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Next we discuss lazy constraint and concrete objective functions below.","category":"page"},{"location":"decision-programming/decision-model/#Lazy-Constraints","page":"Decision Model","title":"Lazy Constraints","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Valid equalities are equalities that can be be derived from the problem structure. They can help in computing the optimal decision strategies, but adding them directly may slow down the overall solution process. By adding valid equalities during the solution process as lazy constraints, the MILP solver can prune nodes of the branch-and-bound tree more efficiently. We have the following valid equalities.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can exploit the fact that the path probabilities sum to one by using the probability sum cut","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_𝐬𝐒π(𝐬)=1 tag7","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"For problems where the number of active paths 𝐒^Z is known, we can exploit it by using the number of active paths cut","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_𝐬𝐒 fracπ(𝐬)p(𝐬)=𝐒^Z tag8","category":"page"},{"location":"decision-programming/decision-model/#Expected-Value","page":"Decision Model","title":"Expected Value","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We define the expected value as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameE(Z) = _𝐬𝐒 π(𝐬) mathcalU(𝐬) tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"However, the expected value objective does not account for risk caused by the variablity in the path distribution.","category":"page"},{"location":"decision-programming/decision-model/#Conditional-Value-at-Risk","page":"Decision Model","title":"Conditional Value-at-Risk","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Given a probability level α(0 1 and decision strategy Z we denote value-at-Risk operatornameVaR_α(Z) and conditional Value-at-Risk operatornameCVaR_α(Z)","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Pre-computed parameters","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"u^+=maxmathcalU(𝐬)𝐬𝐒","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"u^-=minmathcalU(𝐬)𝐬𝐒","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"M=u^+-u^-","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"ϵ=frac12 minmathcalU(𝐬)-mathcalU(𝐬^)  mathcalU(𝐬)-mathcalU(𝐬^)  0 𝐬 𝐬^𝐒","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Objective","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"min η","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Constraints","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"η-mathcalU(𝐬)M λ(𝐬)quad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"η-mathcalU(𝐬)(M+ϵ) λ(𝐬) - Mquad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"η-mathcalU(𝐬)(M+ϵ) barλ(𝐬) - ϵquad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"η-mathcalU(𝐬)M (barλ(𝐬) - 1)quad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"barρ(𝐬)  barλ(𝐬)quad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"π(𝐬) - (1 - λ(𝐬))  ρ(𝐬)  λ(𝐬)quad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"ρ(𝐬)  barρ(𝐬)  π(𝐬)quad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_𝐬𝐒barρ(𝐬) = α tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"barλ(𝐬) λ(𝐬)0 1quad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"barρ(𝐬)ρ(𝐬)0 1quad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"ηu^- u^+ tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Solution","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameVaR_α(Z)=η tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameCVaR_α(Z)=frac1α_𝐬𝐒barρ(𝐬) mathcalU(𝐬)tag","category":"page"},{"location":"decision-programming/decision-model/#Mixed-Objective","page":"Decision Model","title":"Mixed Objective","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can formulate","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"w operatornameE(Z) + (1-w) operatornameCVaR_α(Z) tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"where w(0 1) is the trade-off between maximization of","category":"page"},{"location":"decision-programming/decision-model/#References","page":"Decision Model","title":"References","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#Analyzing-Decision-Strategies","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/#Introduction","page":"Analyzing Decision Strategies","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We can analyze fixed decision strategies Z on an influence diagram G, such as ones resulting from the optimization, by generating the active paths 𝐒^Z","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#Active-Paths","page":"Analyzing Decision Strategies","title":"Active Paths","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We can generate active paths 𝐬𝐒^Z as follows.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"Initialize path 𝐬 of length n with undefined values.\nFill path with chance states 𝐬_jS_j for all jC\nIn increasing order of decision nodes jD, fill decision states by computing decision strategy 𝐬_j=Z_j(𝐬_I(j))","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The path probability for all active paths is equal to the upper bound","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(𝐬Z)=p(𝐬) quad 𝐬𝐒^Z","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We exclude inactive paths from the analysis because their path probabilities are zero.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#Utility-Distribution","page":"Analyzing Decision Strategies","title":"Utility Distribution","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We define unique path utility values as","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"mathcalU^=mathcalU(𝐬)𝐬𝐒^Z","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The probability mass function of the utility distribution associates each unique path utility to a probability as follows","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(X=u)=_𝐬𝐒^ZmathcalU(𝐬)=u p(𝐬)quad umathcalU^","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"From the utility distribution, we can calculate the cumulative distribution, statistics, and risk measures. The relevant statistics are expected value, standard deviation, skewness and kurtosis. Risk measures focus on the conditional value-at-risk (CVaR), also known as, expected shortfall.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#State-Probabilities","page":"Analyzing Decision Strategies","title":"State Probabilities","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We denote paths with fixed states where ϵ denotes an empty state using a recursive definition.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"beginaligned\n𝐒_ϵ = 𝐒^Z \n𝐒_ϵs_i = 𝐬𝐒_ϵ  𝐬_i=s_i \n𝐒_ϵs_is_j = 𝐬𝐒_ϵs_i  𝐬_j=s_jquad ji\nendaligned","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The probability of all paths sums to one","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(ϵ) = sum_𝐬𝐒_ϵ p(𝐬) = 1","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"State probabilities for each node iCD and state s_iS_i denote how likely the state occurs given all path probabilities","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(s_iϵ) = sum_𝐬𝐒_ϵs_i fracp(𝐬)ℙ(ϵ) = sum_𝐬𝐒_ϵs_i p(𝐬)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"An active state is a state with positive state probability ℙ(s_ic)0 given conditions c","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We can generalize the state probabilities as conditional probabilities using a recursive definition. Generalized state probabilities allow us to explore how fixing active states affect the probabilities of other states. First, we choose an active state s_i and fix its value. Fixing an inactive state would make all state probabilities zero. Then, we can compute the conditional state probabilities as follows.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(s_jϵs_i) = sum_𝐬𝐒_ϵs_is_j fracp(𝐬)ℙ(s_iϵ)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We can then repeat this process by choosing an active state from the new conditional state probabilities s_k that is different from previously chosen states kj","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"A robust recommendation is a decision state s_i where iD and subpath c such the state probability is one ℙ(s_ic)=1","category":"page"},{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"DecisionProgramming.jl API reference.","category":"page"},{"location":"api/#influence_diagram.jl","page":"API Reference","title":"influence_diagram.jl","text":"","category":"section"},{"location":"api/#Nodes","page":"API Reference","title":"Nodes","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Node\nChanceNode\nDecisionNode\nValueNode\nState\nStates\nStates(::Vector{Tuple{State, Vector{Node}}})\nvalidate_influence_diagram","category":"page"},{"location":"api/#DecisionProgramming.Node","page":"API Reference","title":"DecisionProgramming.Node","text":"Node type. Alias for Int.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.ChanceNode","page":"API Reference","title":"DecisionProgramming.ChanceNode","text":"Chance node type.\n\nExamples\n\nc = ChanceNode(3, [1, 2])\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DecisionNode","page":"API Reference","title":"DecisionProgramming.DecisionNode","text":"Decision node type.\n\nExamples\n\nd = DecisionNode(2, [1])\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.ValueNode","page":"API Reference","title":"DecisionProgramming.ValueNode","text":"Value node type.\n\nExamples\n\nv = ValueNode(4, [1, 3])\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.State","page":"API Reference","title":"DecisionProgramming.State","text":"State type. Alias for Int.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.States","page":"API Reference","title":"DecisionProgramming.States","text":"States type. Works like Vector{State}.\n\nExamples\n\nS = States([2, 3, 2, 4])\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.States-Tuple{Array{Tuple{Int64,Array{Int64,1}},1}}","page":"API Reference","title":"DecisionProgramming.States","text":"Construct states from vector of (state, nodes) tuples.\n\nExamples\n\njulia> S = States([(2, [1, 3]), (3, [2, 4, 5])])\nStates([2, 3, 2, 3, 3])\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.validate_influence_diagram","page":"API Reference","title":"DecisionProgramming.validate_influence_diagram","text":"Validate influence diagram.\n\n\n\n\n\n","category":"function"},{"location":"api/#Paths","page":"API Reference","title":"Paths","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Path\npaths","category":"page"},{"location":"api/#DecisionProgramming.Path","page":"API Reference","title":"DecisionProgramming.Path","text":"Path type. Alias for NTuple{N, State} where N.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.paths","page":"API Reference","title":"DecisionProgramming.paths","text":"Iterate over paths in lexicographical order.\n\nExamples\n\njulia> states = States([2, 3])\njulia> collect(paths(states))[:]\n[(1, 1), (2, 1), (1, 2), (2, 2), (1, 3), (2, 3)]\n\n\n\n\n\nIterate over paths with fixed states in lexicographical order.\n\nExamples\n\njulia> states = States([2, 3])\njulia> collect(paths(states, fixed=Dict(1=>2)))[:]\n[(2, 1), (2, 2), (2, 3)]\n\n\n\n\n\n","category":"function"},{"location":"api/#Probabilities","page":"API Reference","title":"Probabilities","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Probabilities\nProbabilities(::Path)","category":"page"},{"location":"api/#DecisionProgramming.Probabilities","page":"API Reference","title":"DecisionProgramming.Probabilities","text":"Construct and validate stage probabilities.\n\nExamples\n\ndata = [0.5 0.5 ; 0.2 0.8]\nX = Probabilities(data)\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.Probabilities-Tuple{Tuple{Vararg{Int64,N}} where N}","page":"API Reference","title":"DecisionProgramming.Probabilities","text":"Return probabilities of information path s.\n\nExamples\n\njulia> s = (1, 2)\njulia> X(s)\n0.5\n\n\n\n\n\n","category":"method"},{"location":"api/#Path-Probability","page":"API Reference","title":"Path Probability","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"AbstractPathProbability\nDefaultPathProbability\nDefaultPathProbability(::Path)","category":"page"},{"location":"api/#DecisionProgramming.AbstractPathProbability","page":"API Reference","title":"DecisionProgramming.AbstractPathProbability","text":"Abstract path probability type.\n\nExamples\n\nstruct PathProbability <: AbstractPathProbability\n    C::Vector{ChanceNode}\n    # ...\nend\n\n(U::PathProbability)(s::Path) = ...\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DefaultPathProbability","page":"API Reference","title":"DecisionProgramming.DefaultPathProbability","text":"Path probability.\n\nExamples\n\nP = DefaultPathProbability(C, X)\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DefaultPathProbability-Tuple{Tuple{Vararg{Int64,N}} where N}","page":"API Reference","title":"DecisionProgramming.DefaultPathProbability","text":"Evalute path probability.\n\n\n\n\n\n","category":"method"},{"location":"api/#Consequences","page":"API Reference","title":"Consequences","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Consequences\nConsequences(::Path)","category":"page"},{"location":"api/#DecisionProgramming.Consequences","page":"API Reference","title":"DecisionProgramming.Consequences","text":"State utilities.\n\nExamples\n\nvals = [1.0 -2.0; 3.0 4.0]\nY = Consequences(vals)\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.Consequences-Tuple{Tuple{Vararg{Int64,N}} where N}","page":"API Reference","title":"DecisionProgramming.Consequences","text":"Return consequences of information path s.\n\nExamples\n\njulia> s = (1, 2)\njulia> Y(s)\n-2.0\n\n\n\n\n\n","category":"method"},{"location":"api/#Path-Utility","page":"API Reference","title":"Path Utility","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"AbstractPathUtility\nDefaultPathUtility\nDefaultPathUtility(::Path)","category":"page"},{"location":"api/#DecisionProgramming.AbstractPathUtility","page":"API Reference","title":"DecisionProgramming.AbstractPathUtility","text":"Abstract path utility type.\n\nExamples\n\nstruct PathUtility <: AbstractPathUtility\n    V::Vector{ValueNode}\n    # ...\nend\n\n(U::PathUtility)(s::Path) = ...\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DefaultPathUtility","page":"API Reference","title":"DecisionProgramming.DefaultPathUtility","text":"Default path utility.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DefaultPathUtility-Tuple{Tuple{Vararg{Int64,N}} where N}","page":"API Reference","title":"DecisionProgramming.DefaultPathUtility","text":"Evaluate default path utility.\n\n\n\n\n\n","category":"method"},{"location":"api/#decision_model.jl","page":"API Reference","title":"decision_model.jl","text":"","category":"section"},{"location":"api/#Decision-Model","page":"API Reference","title":"Decision Model","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"PositivePathUtility\nPositivePathUtility(::Path)\nvariables\nDecisionModel\nDecisionModel(::States, ::Vector{DecisionNode}, ::AbstractPathProbability; ::Bool)\nprobability_sum_cut(::DecisionModel, ::States, ::AbstractPathProbability)\nnumber_of_paths_cut(::DecisionModel, ::States, ::AbstractPathProbability; ::Float64)","category":"page"},{"location":"api/#DecisionProgramming.PositivePathUtility","page":"API Reference","title":"DecisionProgramming.PositivePathUtility","text":"Positive affine transformation of path utility. Normalized to into range from 1 to 2.\n\nExamples\n\nU⁺ = PositivePathUtility(S, U)\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.PositivePathUtility-Tuple{Tuple{Vararg{Int64,N}} where N}","page":"API Reference","title":"DecisionProgramming.PositivePathUtility","text":"Evaluate positive affine transformation of the path utility.\n\nExamples\n\njulia> 1 ≤ U⁺(s) ≤ 2\ntrue\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.variables","page":"API Reference","title":"DecisionProgramming.variables","text":"Create a multidimensional array of JuMP variables.\n\nExamples\n\nmodel = Model()\nv1 = variables(model, [2, 3, 2])\nv2 = variables(model, [2, 3, 2]; binary=true)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.DecisionModel","page":"API Reference","title":"DecisionProgramming.DecisionModel","text":"DecisionModel type. Alias for JuMP.Model.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DecisionModel-Tuple{States,Array{DecisionNode,1},AbstractPathProbability}","page":"API Reference","title":"DecisionProgramming.DecisionModel","text":"Construct a DecisionModel from states, decision nodes and path probability.\n\nExamples\n\nmodel = DecisionModel(S, D, P; positive_path_utility=true)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.probability_sum_cut-Tuple{JuMP.Model,States,AbstractPathProbability}","page":"API Reference","title":"DecisionProgramming.probability_sum_cut","text":"Adds a probability sum cut to the model as a lazy constraint.\n\nExamples\n\nprobability_sum_cut(model, S, P)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.number_of_paths_cut-Tuple{JuMP.Model,States,AbstractPathProbability}","page":"API Reference","title":"DecisionProgramming.number_of_paths_cut","text":"Adds a number of paths cut to the model as a lazy constraint.\n\nExamples\n\natol = 0.9  # Tolerance to trigger the creation of the lazy cut\nnumber_of_paths_cut(model, S, P; atol=atol)\n\n\n\n\n\n","category":"method"},{"location":"api/#Objective-Functions","page":"API Reference","title":"Objective Functions","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"expected_value(::DecisionModel, ::States, ::AbstractPathUtility)\nconditional_value_at_risk(::DecisionModel, ::States, ::AbstractPathUtility, ::Float64)","category":"page"},{"location":"api/#DecisionProgramming.expected_value-Tuple{JuMP.Model,States,AbstractPathUtility}","page":"API Reference","title":"DecisionProgramming.expected_value","text":"Create an expected value objective.\n\nExamples\n\nEV = expected_value(model, S, U)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.conditional_value_at_risk-Tuple{JuMP.Model,States,AbstractPathUtility,Float64}","page":"API Reference","title":"DecisionProgramming.conditional_value_at_risk","text":"Create a conditional value-at-risk (CVaR) objective.\n\nExamples\n\nα = 0.05  # Parameter such that 0 ≤ α ≤ 1\nCVaR = conditional_value_at_risk(model, S, U, α)\n\n\n\n\n\n","category":"method"},{"location":"api/#Decision-Strategy","page":"API Reference","title":"Decision Strategy","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"LocalDecisionStrategy\nLocalDecisionStrategy(::Vector{VariableRef})\nLocalDecisionStrategy(::Path)\nDecisionStrategy\nDecisionStrategy(::DecisionModel, ::Vector{DecisionNode})","category":"page"},{"location":"api/#DecisionProgramming.LocalDecisionStrategy","page":"API Reference","title":"DecisionProgramming.LocalDecisionStrategy","text":"Decision strategy type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.LocalDecisionStrategy-Tuple{Array{VariableRef,1}}","page":"API Reference","title":"DecisionProgramming.LocalDecisionStrategy","text":"Construct decision strategy from variable refs.\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.DecisionStrategy","page":"API Reference","title":"DecisionProgramming.DecisionStrategy","text":"Global decision strategy type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DecisionStrategy-Tuple{JuMP.Model,Array{DecisionNode,1}}","page":"API Reference","title":"DecisionProgramming.DecisionStrategy","text":"Extract values for decision variables from solved decision model.\n\nExamples\n\nZ = GlobalDecisionStrategy(model, D)\n\n\n\n\n\n","category":"method"},{"location":"api/#analysis.jl","page":"API Reference","title":"analysis.jl","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"ActivePaths\nUtilityDistribution\nUtilityDistribution(::States, ::AbstractPathProbability, ::AbstractPathUtility, ::DecisionStrategy)\nStateProbabilities\nStateProbabilities(::States, ::AbstractPathProbability, ::DecisionStrategy)\nStateProbabilities(::States, ::AbstractPathProbability, ::DecisionStrategy, ::Node, ::State, ::StateProbabilities)\nvalue_at_risk(::Vector{Float64}, ::Vector{Float64}, ::Float64)\nconditional_value_at_risk(::Vector{Float64}, ::Vector{Float64}, ::Float64)","category":"page"},{"location":"api/#DecisionProgramming.ActivePaths","page":"API Reference","title":"DecisionProgramming.ActivePaths","text":"Interface for iterating over active paths given influence diagram and decision strategy.\n\nInitialize path s of length n\nFill chance states s[C] by generating subpaths paths(C)\nFill decision states s[D] by decision strategy Z and path s\n\nExamples\n\nfor s in ActivePaths(S, C, Z)\n    ...\nend\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.UtilityDistribution","page":"API Reference","title":"DecisionProgramming.UtilityDistribution","text":"UtilityDistribution type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.UtilityDistribution-Tuple{States,AbstractPathProbability,AbstractPathUtility,DecisionStrategy}","page":"API Reference","title":"DecisionProgramming.UtilityDistribution","text":"Constructs the probability mass function for path utilities on active paths.\n\nExamples\n\nUtilityDistribution(S, P, U, Z)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.StateProbabilities","page":"API Reference","title":"DecisionProgramming.StateProbabilities","text":"StateProbabilities type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.StateProbabilities-Tuple{States,AbstractPathProbability,DecisionStrategy}","page":"API Reference","title":"DecisionProgramming.StateProbabilities","text":"Associates each node with array of probabilities for each of its states occuring in active paths.\n\nExamples\n\nStateProbabilities(S, P, Z)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.StateProbabilities-Tuple{States,AbstractPathProbability,DecisionStrategy,Int64,Int64,StateProbabilities}","page":"API Reference","title":"DecisionProgramming.StateProbabilities","text":"Associates each node with array of conditional probabilities for each of its states occuring in active paths given fixed states and prior probability.\n\nExamples\n\n# Prior probabilities\nprev = StateProbabilities(S, P, Z)\n\n# Select node and fix its state\nnode = 1\nstate = 2\nStateProbabilities(S, P, Z, node, state, prev)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.value_at_risk-Tuple{Array{Float64,1},Array{Float64,1},Float64}","page":"API Reference","title":"DecisionProgramming.value_at_risk","text":"Value-at-risk.\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.conditional_value_at_risk-Tuple{Array{Float64,1},Array{Float64,1},Float64}","page":"API Reference","title":"DecisionProgramming.conditional_value_at_risk","text":"Conditional value-at-risk.\n\n\n\n\n\n","category":"method"},{"location":"api/#printing.jl","page":"API Reference","title":"printing.jl","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"print_decision_strategy\nprint_utility_distribution\nprint_state_probabilities\nprint_statistics\nprint_risk_measures","category":"page"},{"location":"api/#DecisionProgramming.print_decision_strategy","page":"API Reference","title":"DecisionProgramming.print_decision_strategy","text":"Print decision strategy.\n\nExamples\n\nprint_decision_strategy(S, Z)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_utility_distribution","page":"API Reference","title":"DecisionProgramming.print_utility_distribution","text":"Print utility distribution\n\nExamples\n\nudist = UtilityDistribution(S, P, U, Z)\nprint_utility_distribution(udist)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_state_probabilities","page":"API Reference","title":"DecisionProgramming.print_state_probabilities","text":"Print state probabilities with fixed states.\n\nExamples\n\nsprobs = StateProbabilities(S, P, U, Z)\nprint_state_probabilities(sprobs, [c.j for c in C])\nprint_state_probabilities(sprobs, [d.j for d in D])\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_statistics","page":"API Reference","title":"DecisionProgramming.print_statistics","text":"Print statistics.\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_risk_measures","page":"API Reference","title":"DecisionProgramming.print_risk_measures","text":"Print risk measures.\n\n\n\n\n\n","category":"function"},{"location":"api/#random.jl","page":"API Reference","title":"random.jl","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"random_diagram(::AbstractRNG, ::Int, ::Int, ::Int, ::Int)\nStates(::AbstractRNG, ::Vector{State}, ::Int)\nProbabilities(::AbstractRNG, ::ChanceNode, ::States)\nConsequences(::AbstractRNG, ::ValueNode, ::States; ::Float64, ::Float64)\nLocalDecisionStrategy(::AbstractRNG, ::DecisionNode, ::States)","category":"page"},{"location":"api/#DecisionProgramming.random_diagram-Tuple{AbstractRNG,Int64,Int64,Int64,Int64}","page":"API Reference","title":"DecisionProgramming.random_diagram","text":"Generate random decision diagram with n_C chance nodes, n_D decision nodes, and n_V value nodes. Parameter n_I is the upper bound on the size of the information set.\n\nExamples\n\nrng = MersenneTwister(3)\nrandom_diagram(rng, 5, 2, 3, 2)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.States-Tuple{AbstractRNG,Array{Int64,1},Int64}","page":"API Reference","title":"DecisionProgramming.States","text":"Generate n random states from states.\n\nExamples\n\nrng = MersenneTwister(3)\nS = States(rng, [2, 3], 10)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.Probabilities-Tuple{AbstractRNG,ChanceNode,States}","page":"API Reference","title":"DecisionProgramming.Probabilities","text":"Generate random probabilities for chance node c with S states.\n\nExamples\n\nrng = MersenneTwister(3)\nc = ChanceNode(2, [1])\nS = States([2, 2])\nProbabilities(rng, c, S)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.Consequences-Tuple{AbstractRNG,ValueNode,States}","page":"API Reference","title":"DecisionProgramming.Consequences","text":"Generate random consequences between low and high for value node v with S states.\n\nExamples\n\nrng = MersenneTwister(3)\nv = ValueNode(3, [1])\nS = States([2, 2])\nConsequences(rng, v, S; low=-1.0, high=1.0)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.LocalDecisionStrategy-Tuple{AbstractRNG,DecisionNode,States}","page":"API Reference","title":"DecisionProgramming.LocalDecisionStrategy","text":"Generate random decision strategy for decision node d with S states.\n\nExamples\n\nrng = MersenneTwister(3)\nd = DecisionNode(2, [1])\nS = States([2, 2])\nDecisionStrategy(rng, d, S)\n\n\n\n\n\n","category":"method"},{"location":"examples/multi-period-investment/#Multi-period-Investment","page":"Multi-period Investment","title":"Multi-period Investment","text":"","category":"section"},{"location":"examples/multi-period-investment/#Description","page":"Multi-period Investment","title":"Description","text":"","category":"section"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"[1], section 4.2","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"For instance, assume that the first-stage decisions specify which technology development projects will be started to generate patent-based intellectual property (P) for a platform. This intellectual property contributes subject to some uncertainties to the technical competitiveness (T) of the platform. In the second stage, it is possible to carry out application (A) development projects which, when completed, yield cash flows that depend on the market share of the platform. This market share (M) depends on the competitiveness of the platform and the number of developed applications. The aim is to maximize the cash flows from application projects less the cost of technology and application development projects.","category":"page"},{"location":"examples/multi-period-investment/#Formulation","page":"Multi-period Investment","title":"Formulation","text":"","category":"section"},{"location":"examples/multi-period-investment/#Projects","page":"Multi-period Investment","title":"Projects","text":"","category":"section"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"(Image: )","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"The influence diagram of an individual multi-period investment project.","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"There are i1n_T technology development projects and k1n_A application development projects.","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Decision states to develop patents","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"d_i^PD_i^P=q_1^P q_2^P q_2^P q_3^P  q_D^P^P q_D^P+1^P","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Chance states of technical competitiveness c_i^TC_i^T","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Decision states to develop applications","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"d_k^AD^A=q_1^A q_2^A q_2^A q_3^A  q_D^A^A q_D^A+1^A","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Chance states of market size c_k^MC_k^M","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Probability ℙ(c_i^Td_i^P)01","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Probability ℙ(c_k^Md_k^Ac_n_T^Tc_1^T)01","category":"page"},{"location":"examples/multi-period-investment/#Portfolio-Selection","page":"Multi-period Investment","title":"Portfolio Selection","text":"","category":"section"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Technology project i costs r_i^Tℝ^+ and generates p_i^Tℕ patents.","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Application project k costs r_k^Aℝ^+ and generates a_k^Aℕ applications. If completed, provides cash flow Y(c_k^M)ℝ^+","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Decision variables x^T(i)0 1 indicate which technologies are selected.","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Decision variables x^A(kc_n_T^Tc_1^T)0 1 indicate which applications are selected.","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Number of patents x^T = _i x^T(i) p_i^T","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Number of applications x^A = _k x^A(kc_n_T^Tc_1^T) a_k^A","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Constraints","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"x^T - y_i^P M  q_i^P  x^T + (1 - y_i^P) Mquad i","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"x^A - y_k^A M  q_k^A  x^A + (1 - y_k^A) Mquad  k","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"_i y_i^P=1","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"_k y_k^A=1","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"y_i^P0 1quad i","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"y_k^A0 1quad k","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"y_0^P=y_0^A=0","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"z(d_i^P)=y_i^P-y_i-1^Pquad i","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"z(d_k^Ac_n_T^Tc_1^T)=y_k^A-y_k-1^Aquad k","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Large constant M (value?)","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Path utility","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"mathcalU(s) =\n_k x^A(kc_n_T^Tc_1^T) (Y(c_k^M) - r_k^A) - _i x^T(i) r_i^T","category":"page"},{"location":"examples/multi-period-investment/#References","page":"Multi-period Investment","title":"References","text":"","category":"section"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"decision-programming/computational-complexity/#Computational-Complexity","page":"Computational Complexity","title":"Computational Complexity","text":"","category":"section"},{"location":"decision-programming/computational-complexity/#Introduction","page":"Computational Complexity","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"Decision programming relies on mixed-integer linear programming, which is known to be an NP-complete problem. In this section, we analyze how the influence diagram affects the size of the mixed-integer linear model, determining whether it is tractable.","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We use the following inequalities for sum and product of non-negative elements A to derive the lower and upper bounds for the number of paths and the number of decision stages. Sum inequality:","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"A left(min_aA aright)  _aA a  A left(max_aA aright)","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"Product inequality:","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"left(min_aA aright)^A  _aA a  left(max_aA aright)^A","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"The following bounds for the number of paths and the number of decision stages show how the number of states, nodes, and arcs affects the size of the model.","category":"page"},{"location":"decision-programming/computational-complexity/#Number-of-Paths","page":"Computational Complexity","title":"Number of Paths","text":"","category":"section"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We define the number of paths as","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"𝐒=_iCD S_i","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"From the definition of the influence diagram, we have the path length of n=CD Then, we have the bounds for the number of paths as","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"left(min_iCD S_iright)^n  𝐒  left(max_iCD S_iright)^n","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We assume non-trivial influence diagram such that S_i2 for all iCD. That is, each decision or chance node has at least two states. Therefore, the number of paths is always exponential to the path length of n","category":"page"},{"location":"decision-programming/computational-complexity/#Number-of-Decision-Stages","page":"Computational Complexity","title":"Number of Decision Stages","text":"","category":"section"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We define the number of decision stages as","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"_iD𝐒_I(i) S_i = _iD S_i _jI(i)S_j = _iD _jI(i)iS_j","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"From the definition of the information set, for all iD we have I(i)iCD with size 1I(i)i=I(i)+1mn where m denotes the upper bound of influence other nodes have on any decision node. Also, we have the number of decision nodes 0Dn Thus, we have the bounds","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"0  _iD𝐒_I(i) S_i  D left(max_iCD S_jright)^m","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"In the worst case, m=n, a decision node is influenced by every other chance and decision node. However, in most practical cases, we have m  n where decision nodes are influenced only by a limited number of other chance and decision nodes, making models easier to solve.","category":"page"},{"location":"examples/n-monitoring/#N-Monitoring","page":"N-Monitoring","title":"N-Monitoring","text":"","category":"section"},{"location":"examples/n-monitoring/#Description","page":"N-Monitoring","title":"Description","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The N-monitoring problem is described in [1], sections 4.1 and 6.1.","category":"page"},{"location":"examples/n-monitoring/#Influence-Diagram","page":"N-Monitoring","title":"Influence Diagram","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"(Image: )","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The incluence diagram of generalized N-monitoring problem where N1 and indices k=1N The nodes are associated with states as follows. Load state L=high low denotes the load, report states R_k=high low report the load state to the action states A_k=yes no which decide whether to fortificate failure state F=failure success Finally, the utility at target T depends on the whether F fails and the fortification costs.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"We draw the magnitude and cost of fortification c_kU(01) from a uniform distribution. Fortification is defined","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"f(A_k=yes) = c_k","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"f(A_k=no) = 0","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probability that the load is high. We draw xU(01) from uniform distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(L=high)=x","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probabilities of the report states correspond to the load state. We draw the values xU(01) and yU(01) from uniform distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(R_k=highL=high)=maxxx-1","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(R_k=lowL=low)=maxyy-1","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probabilities of failure which are decresead by fortifications. We draw the values zU(01) and wU(01) from uniform distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(F=failureA_NA_1L=high)=fracmaxz 1-zexp(_k=1N f(A_k))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(F=failureA_NA_1L=low)=fracminw 1-wexp(_k=1N f(A_k))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Utility from consequences at target T from failure state F","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Y(F=failure) = 0","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Y(F=success) = 100","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Utility from consequences at target T from action states A_k","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Y(A_k)=-f(A_k)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Total utility at target T","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Y(FA_NA_1)=Y(F)+_k=1N Y(A_k)","category":"page"},{"location":"examples/n-monitoring/#References","page":"N-Monitoring","title":"References","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"decision-programming/influence-diagram/#Influence-Diagram","page":"Influence Diagram","title":"Influence Diagram","text":"","category":"section"},{"location":"decision-programming/influence-diagram/#Introduction","page":"Influence Diagram","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Based on [1], sections 3.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The paper [2] explains details about influence diagrams.","category":"page"},{"location":"decision-programming/influence-diagram/#Definition","page":"Influence Diagram","title":"Definition","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(Image: )","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the influence diagram as a directed, acyclic graph such that part of its nodes have a finite number of states associated with them","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"G=(CDVAS)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The sets of nodes consists of chance nodes C decision nodes D and value nodes V. We index the nodes such that CD=1n and V=n+1n+V where n=C+D The set of arcs consists of pairs of nodes such that","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"A(ij)1ijNiV","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"where N=C+D+V The condition enforces that the graph is directed and acyclic, and there are no arcs from value nodes to other nodes.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Each chance and decision node jCD is associates with a finite number of states S_j We use integers from one to number of states S_j to encode individual states","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"S_j=1S_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the information set of node jN to be its predecessor nodes","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"I(j)=i(ij)A","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Practically, the information set is an edge list to reverse direction in the graph.","category":"page"},{"location":"decision-programming/influence-diagram/#Paths","page":"Influence Diagram","title":"Paths","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Paths in influence diagrams represent realizations of states for chance and decision nodes. Formally, a path is a sequence of states","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐬=(s_1 s_2 s_n)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"where each state s_iS_i for all chance and decision nodes iCD","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define a subpath of 𝐬 is a subsequence","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(𝐬_i_1 𝐬_i_2  𝐬_i_k)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"where 1i_1i_2i_kn and kn","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The information path of node jN on path 𝐬 is a subpath defined as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐬_I(j)=(𝐬_i  iI(j))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the set of all paths as a product set of all states","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐒=_jCD S_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The set of information paths of node jN is the product set of the states in its information set","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐒_I(j)=_iI(j) S_i","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We denote elements of the sets using notation s_jS_j, 𝐬𝐒, and 𝐬_I(j)𝐒_I(j)","category":"page"},{"location":"decision-programming/influence-diagram/#Probabilities","page":"Influence Diagram","title":"Probabilities","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"For each chance node jC, we denote the probability of state s_j given information path 𝐬_I(j) as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"ℙ(X_j=s_jX_I(j)=𝐬_I(j))=ℙ(s_j𝐬_I(j))0 1","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"with","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"_s_jS_j ℙ(s_j𝐬_I(j)) = 1","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Implementation wise, we can think probabilities as functions of information paths concatenated with state X_j  𝐒_I(j)S_j  0 1 where _s_jS_j X_j(𝐬_I(j)s_j)=1","category":"page"},{"location":"decision-programming/influence-diagram/#Decision-Strategy","page":"Influence Diagram","title":"Decision Strategy","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"For each decision node jD a local decision strategy maps an information path 𝐬_I(j) to a state s_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Z_j𝐒_I(j)S_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Decision strategy Z contains one local decision strategy for each decision node. Set of all decision strategies is denoted ℤ","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"A decision stategy Zℤ is compatible with the path 𝐬𝐒 if and only if Z_j(𝐬_I(j))=s_j forall Z_jZ and jD","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"An active path is path 𝐬𝐒 that is compatible with decision strategy Z We denote the set of all active paths using 𝐒^Z Since each decision strategy Z_j chooses only one state out of all of its states, the number of active paths is","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐒^Z=𝐒prod_jDS_j=prod_jCS_j","category":"page"},{"location":"decision-programming/influence-diagram/#Path-Probability","page":"Influence Diagram","title":"Path Probability","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the path probability (upper bound) as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"p(𝐬) = _jC ℙ(𝐬_j𝐬_I(j))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The path probability ℙ(𝐬Z) equals p(𝐬) if the path 𝐬 is compatible with the decision strategy Z. Otherwise, the path cannot occur and the probability is zero.","category":"page"},{"location":"decision-programming/influence-diagram/#Consequences","page":"Influence Diagram","title":"Consequences","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"For each value node jV, we define the consequence given information path 𝐬_I(j) as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Y_j𝐒_I(j)ℂ","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"where ℂ is the set of consequences. In the code, the consequences are implicit, and we map information paths directly to the utility values.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The utility function maps consequences to real-valued utilities","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Uℂℝ","category":"page"},{"location":"decision-programming/influence-diagram/#Path-Utility","page":"Influence Diagram","title":"Path Utility","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The path utility is defined as the sum of utilities for consequences of value nodes jV with information paths I(j)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"mathcalU(𝐬) = _jV U(Y_j(𝐬_I(j)))","category":"page"},{"location":"decision-programming/influence-diagram/#Path-Distribution","page":"Influence Diagram","title":"Path Distribution","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"A path distribution is a pair","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(ℙ(𝐬Z) mathcalU(𝐬))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"that comprises of path probability function and path utility function over paths 𝐬𝐒 conditional to the decision strategy Z","category":"page"},{"location":"decision-programming/influence-diagram/#References","page":"Influence Diagram","title":"References","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"[2]: Bielza, C., Gómez, M., & Shenoy, P. P. (2011). A review of representation issues and modeling challenges with influence diagrams. Omega, 39(3), 227–241. https://doi.org/10.1016/j.omega.2010.07.003","category":"page"},{"location":"#DecisionProgramming.jl","page":"Home","title":"DecisionProgramming.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"DecisionProgramming.jl is a Julia package for solving multi-stage decision problems under uncertainty, modeled using influence diagrams, and leveraging the power of mixed-integer linear programming. Solving multi-stage decision problems under uncertainty consists of the following three steps.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the first step, we model the decision problem using an influence diagram with associated probabilities, consequences, and path utility function.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the second step, we create a decision model with an objective for the influence diagram. We solve the model to obtain an optimal decision strategy. We can create and solve multiple models with different objectives for the same influence diagram to receive various optimal decision strategies.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the third step, we analyze the resulting decision strategies for the influence diagram. In particular, we are interested in utility distribution and its associated statistics and risk measures.","category":"page"},{"location":"","page":"Home","title":"Home","text":"DecisionProgramming.jl provides the necessary functionality for expressing and solving decision problems but does not explain how to design influence diagrams. The rest of this documentation will describe the mathematical and programmatic details, touch on the computational challenges, and provide concrete examples of solving decision problems.","category":"page"},{"location":"","page":"Home","title":"Home","text":"DecisionProgramming.jl is developed in the Systems Analysis Laboratory at Aalto University by Ahti Salo,  Fabricio Oliveira, Juho Andelmin, Olli Herala, and Jaan Tollander de Balsch.","category":"page"},{"location":"examples/pig-breeding/#Pig-Breeding","page":"Pig Breeding","title":"Pig Breeding","text":"","category":"section"},{"location":"examples/pig-breeding/#Description","page":"Pig Breeding","title":"Description","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The pig breeding problem as described in [1].","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"A pig breeder is growing pigs for a period of four months and subsequently selling them. During this period the pig may or may not develop a certain disease. If the pig has the disease at the time it must be sold, the pig must be sold for slaughtering, and its expected market price is then 300 DKK (Danish kroner). If it is disease free, its expected market price as a breeding animal is 1000 DKKOnce a month, a veterinary doctor sees the pig and makes a test for presence of the disease. If the pig is ill, the test will indicate this with probability 0.80, and if the pig is healthy, the test will indicate this with probability 0.90. At each monthly visit, the doctor may or may not treat the pig for the disease by injecting a certain drug. The cost of an injection is 100 DKK.A pig has the disease in the first month with probability 0.10. A healthy pig develops the disease in the subsequent month with probability 0.20 without injection, whereas a healthy and treated pig develops the disease with probability 0.10, so the injection has some preventive effect. An untreated pig that is unhealthy will remain so in the subsequent month with probability 0.90, whereas the similar probability is 0.50 for an unhealthy pig that is treated. Thus spontaneous cure is possible, but treatment is beneficial on average.","category":"page"},{"location":"examples/pig-breeding/#Influence-Diagram","page":"Pig Breeding","title":"Influence Diagram","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"(Image: )","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The influence diagram for the the generalized N-month pig breeding. The nodes are associated with the following states. Health states h_k=illhealthy represents the health of the pig at month k=1N. Test states t_k=positivenegative represents the result from testing the pig at month k=1N-1. Treat state d_k=treat pass represents the decision to treat the pig with an injection at month k=1N-1. The dashed arcs represent the no-forgetting principle and we can toggle them on and off in the formulation.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The probabilities that test indicates pig's health correctly at month k=1N-1.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(t_k = positive  h_k = ill) = 08","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(t_k = negative  h_k = healthy) = 09","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The probability that pig is ill in the first month.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_1 = ill)=01","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The probability that the pig is ill in the subsequent months k=2N given the treatment decision in and state of health in the previous month.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = pass h_k-1 = healthy)=02","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = treat h_k-1 = healthy)=01","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = pass h_k-1 = ill)=09","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = treat h_k-1 = ill)=05","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The cost of treatment decision for the pig at month k=1N-1","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(d_k=treat) = -100","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(d_k=pass) = 0","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The price of given the pig health at month N","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(h_N=ill) = 300","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(h_N=healthy) = 1000","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Total utility","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(h_Nd_N-1d_1)=Y(h_n)+_k=1N Y(d_k)","category":"page"},{"location":"examples/pig-breeding/#References","page":"Pig Breeding","title":"References","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"[1]: Lauritzen, S. L., & Nilsson, D. (2001). Representing and solving decision problems with limited information. Management Science, 47(9), 1235–1251. https://doi.org/10.1287/mnsc.47.9.1235.9779","category":"page"},{"location":"examples/used-car-buyer/#Used-Car-Buyer","page":"Used Car Buyer","title":"Used Car Buyer","text":"","category":"section"},{"location":"examples/used-car-buyer/#Description","page":"Used Car Buyer","title":"Description","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"To illustrate the basic functionality of Decision Programming, we implement a version of the used car buyer problem in [1]. In this problem, Joe is buying a used car. The price of the car is 1000 USD (US dollars) and its value is 1100 USD. Joe's base profit on the car is thus 100 USD. However, Joe knows that the car is a \"lemon\", meaning that it has defects in 6 major systems, with a 20% probability. With the remaining 80% probability, the car is a \"peach\", and it has a defect in only one of the systems.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The repair costs for a peach are only 40 USD, decreasing Joe's profit to 60  USD. However, the costs for a lemon are 200 USD, resulting in a total loss of 100 USD. We can now formulate an influence diagram of Joe's initial problem. The influence diagram is presented in the figure below. In an influence diagram, circle nodes such as O are called chance nodes, representing uncertainty. Node O is a chance node representing the state of the car, lemon or peach. Square nodes such as A are decision nodes, representing decisions. Node A represents the decision to buy or not to buy the car. The diamond-shaped value node V denotes the utility calculation in the problem. For Joe, the utility function is the expected monetary value. The arrows or arcs show connections between nodes. The two arcs in this diagram point to the value node, meaning that the monetary value depends on state of the car and the purchase decision.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"(Image: \\label{used-car-buyer-1})","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The optimal strategy for this problem can easily be determined. If Joe decides not to buy the car, his profit is certainly 0. If he buys the car, there is a 20% probability of a loss of 100 USD and an 80% probability of a profit of 60 USD. The expected profit for buying the car is thus 28 USD, which is clearly higher than the zero profit of not buying. Thus, Joe should buy the car.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We now add two new features to the problem. A stranger approaches Joe, offering to tell Joe whether the car is a lemon or a peach, for a price of 25 USD. Additionally, the car dealer offers a guarantee plan which costs 60 USD and covers 50% of the repair costs. Joe notes that this is not a very good deal and the dealer includes an anti-lemon feature: if the total repair cost exceeds 100 USD, the repairs are fully covered by the guarantee. The new influence diagram is presented below. The decision node T denotes the decision to accept or decline the stranger's offer, and R is the outcome of the test. New value nodes V_1 and V_2 are introduced to represent costs of testing and the base profit from purchasing the car. Additionally, the decision node A now also has the possibility of choosing to buy with a guarantee.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"(Image: \\label{used-car-buyer-2})","category":"page"},{"location":"examples/used-car-buyer/#The-model","page":"Used Car Buyer","title":"The model","text":"","category":"section"},{"location":"examples/used-car-buyer/#Influence-diagram","page":"Used Car Buyer","title":"Influence diagram","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"using Printf, Random, Logging, Parameters, JuMP, Gurobi\nusing DecisionProgramming\n\n\nconst O = 1     # Chance node: lemon or peach\nconst T = 2     # Decision node: pay stranger for advice\nconst R = 3     # Chance node: observation of state of the car\nconst A = 4     # Decision node: purchase alternative\nconst O_states = [\"lemon\", \"peach\"]\nconst T_states = [\"no test\", \"test\"]\nconst R_states = [\"no test\", \"lemon\", \"peach\"]\nconst A_states = [\"buy without guarantee\", \"buy with guarantee\", \"don't buy\"]\n\nC = Vector{ChanceNode}()\nD = Vector{DecisionNode}()\nV = Vector{ValueNode}()\nS_j = Vector{State}(undef, 4)\nS_j[O] = length(O_states)\nS_j[T] = length(T_states)\nS_j[R] = length(R_states)\nS_j[A] = length(A_states)","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We start by defining the influence diagram structure. The decision and chance nodes, as well as their states are defined in the first block. Next, the influence diagram parameters consisting of the node sets and the state spaces of the nodes are defined.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"# Node O: no predecessors\nI_O = Vector{Node}()\nX_O = [0.2,0.8]\npush!(C, ChanceNode(O, I_O, S_j[O], X_O))\n\n# Node T: no predecessors\nI_T = Vector{Node}()\npush!(D, DecisionNode(T, I_T, S_j[T]))\n\n# Node R: dependent on nodes O and T\nI_R = [O,T]\nX_R = zeros(S_j[O], S_j[T], S_j[R])\nX_R[1, 1, :] = [1,0,0]\nX_R[1, 2, :] = [0,1,0]\nX_R[2, 1, :] = [1,0,0]\nX_R[2, 2, :] = [0,0,1]\npush!(C, ChanceNode(R, I_R, S_j[R], X_R))\n\n# Node A: dependent on node R\nI_A = [R]\npush!(D, DecisionNode(A, I_A, S_j[A]))\n\n# Cost of test\nI_V1 = [T]\nY_V1 = [0, -25]\npush!(V, ValueNode(5, I_V1, Y_V1))\n\n# Base profit of purchase alternatives\nI_V2 = [A]\nY_V2 = [100, 40, 0]\npush!(V, ValueNode(6, I_V2, Y_V2))\n\n# Repair costs\nI_V3 = [O,A]\nY_V3 = [-200 0 0; -40 -20 0]\npush!(V, ValueNode(7, I_V3, Y_V3))\n","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We continue by defining the probabilities associated with chance nodes and utilities (consequences) associated with value nodes. The rows of the consequence matrix Y_V3 correspond to the state of the car, while the columns correspond to the decision made in node A.","category":"page"},{"location":"examples/used-car-buyer/#Decision-model","page":"Used Car Buyer","title":"Decision model","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"@info(\"Defining InfluenceDiagram\")\nG = InfluenceDiagram(C, D, V)\n\n@info(\"Creating probabilities.\")\nX = Probabilities(G, C)\n\n@info(\"Creating consequences.\")\nY = Consequences(G, V)\n\n@info(\"Creating path probability.\")\nP = PathProbability(G, X)\n\n@info(\"Creating path utility.\")\nU = PathUtility(G, Y)\n\n@info(\"Defining DecisionModel\")\n@time model = DecisionModel(G, P)\n\n@info(\"Creating model objective.\")\n@time E = expected_value(model, G, U)\n@objective(model, Max, E)","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We then construct the decision model using the DecisionProgramming.jl package.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"@info(\"Starting the optimization process.\")\noptimizer = optimizer_with_attributes(\n    Gurobi.Optimizer,\n    \"IntFeasTol\"      => 1e-9,\n    \"LazyConstraints\" => 1,\n)\nset_optimizer(model, optimizer)\noptimize!(model)\n\n@info(\"Extracting results.\")\nZ = DecisionStrategy(model)\n\n@info(\"Printing decision strategy:\")\nprint_decision_strategy(G, Z)\nprintln()","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The model is solved. We get the following decision strategy:","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"┌────────┬────┬───┐\n│  Nodes │ () │ 2 │\n├────────┼────┼───┤\n│ States │ () │ 2 │\n└────────┴────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (3,) │ 4 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 3 │\n│ States │ (2,) │ 2 │\n│ States │ (3,) │ 1 │\n└────────┴──────┴───┘","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"To start explaining this output, let's take a look at the top table. On the right, we have the decision node 2. We defined earlier that the node T is node number 2. On the left, we have the information set of that decision node, which is empty. The strategy in the first decision node is to choose alternative 2, which we defined to be testing the car.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"In the bottom table, we have node number 4 (node A) and its predecessor, node number 3 (node R). The first row, where no test result is obtained, is invalid for this strategy since the car was tested. If the car is a lemon, Joe should buy the car with guarantee (alternative 2), and if it is a peach, buy the car without guarantee (alternative 1).","category":"page"},{"location":"examples/used-car-buyer/#Analyzing-the-results","page":"Used Car Buyer","title":"Analyzing the results","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"@info(\"Computing utility distribution.\")\n@time udist = UtilityDistribution(G, P, U, Z)\n\n@info(\"Printing utility distribution.\")\nprint_utility_distribution(udist)\n\n@info(\"Printing expected utility.\")\n@unpack u, p = udist\n@printf(\"Expected utility: %.1f\", sum(u[i]*p[i] for i in 1:length(u)))","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"From the utility distribution, we can see that Joe's profit with this strategy is 15 USD with a 20% probability (the car is a lemon) and 35 USD with a 80% probability (the car is a peach). The expected profit is thus 31 USD.","category":"page"},{"location":"examples/used-car-buyer/#References","page":"Used Car Buyer","title":"References","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"[1]: Howard, R. A. (1977). The used car buyer. Reading in Decision Analysis, 2nd Ed. Stanford Research Institute, Menlo Park, CA.","category":"page"}]
}
