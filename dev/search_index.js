var documenterSearchIndex = {"docs":
[{"location":"examples/multi-period-investment/#Multi-period-Investment","page":"Multi-period Investment","title":"Multi-period Investment","text":"","category":"section"},{"location":"examples/multi-period-investment/#Description","page":"Multi-period Investment","title":"Description","text":"","category":"section"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"[1], section 4.2","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"For instance, assume that the first-stage decisions specify which technology development projects will be started to generate patent-based intellectual property (P) for a platform. This intellectual property contributes subject to some uncertainties to the technical competitiveness (T) of the platform. In the second stage, it is possible to carry out application (A) development projects which, when completed, yield cash flows that depend on the market share of the platform. This market share (M) depends on the competitiveness of the platform and the number of developed applications. The aim is to maximize the cash flows from application projects less the cost of technology and application development projects.","category":"page"},{"location":"examples/multi-period-investment/#Formulation","page":"Multi-period Investment","title":"Formulation","text":"","category":"section"},{"location":"examples/multi-period-investment/#Projects","page":"Multi-period Investment","title":"Projects","text":"","category":"section"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"(Image: )","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"The influence diagram of an individual multi-period investment project.","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"There are i1n_T technology development projects and k1n_A application development projects.","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Decision states to develop patents","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"d_i^PD_i^P=q_1^P q_2^P q_2^P q_3^P  q_D^P^P q_D^P+1^P","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Chance states of technical competitiveness c_i^TC_i^T","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Decision states to develop applications","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"d_k^AD^A=q_1^A q_2^A q_2^A q_3^A  q_D^A^A q_D^A+1^A","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Chance states of market size c_k^MC_k^M","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Probability ℙ(c_i^Td_i^P)01","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Probability ℙ(c_k^Md_k^Ac_n_T^Tc_1^T)01","category":"page"},{"location":"examples/multi-period-investment/#Portfolio-Selection","page":"Multi-period Investment","title":"Portfolio Selection","text":"","category":"section"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Technology project i costs r_i^Tℝ^+ and generates p_i^Tℕ patents.","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Application project k costs r_k^Aℝ^+ and generates a_k^Aℕ applications. If completed, provides cash flow Y(c_k^M)ℝ^+","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Decision variables x^T(i)0 1 indicate which technologies are selected.","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Decision variables x^A(kc_n_T^Tc_1^T)0 1 indicate which applications are selected.","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Number of patents x^T = _i x^T(i) p_i^T","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Number of applications x^A = _k x^A(kc_n_T^Tc_1^T) a_k^A","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Constraints","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"x^T - y_i^P M  q_i^P  x^T + (1 - y_i^P) Mquad i","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"x^A - y_k^A M  q_k^A  x^A + (1 - y_k^A) Mquad  k","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"_i y_i^P=1","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"_k y_k^A=1","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"y_i^P0 1quad i","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"y_k^A0 1quad k","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"y_0^P=y_0^A=0","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"z(d_i^P)=y_i^P-y_i-1^Pquad i","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"z(d_k^Ac_n_T^Tc_1^T)=y_k^A-y_k-1^Aquad k","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Large constant M (value?)","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"Path utility","category":"page"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"mathcalU(s) =\n_k x^A(kc_n_T^Tc_1^T) (Y(c_k^M) - r_k^A) - _i x^T(i) r_i^T","category":"page"},{"location":"examples/multi-period-investment/#References","page":"Multi-period Investment","title":"References","text":"","category":"section"},{"location":"examples/multi-period-investment/","page":"Multi-period Investment","title":"Multi-period Investment","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"examples/n-monitoring/#N-Monitoring","page":"N-Monitoring","title":"N-Monitoring","text":"","category":"section"},{"location":"examples/n-monitoring/#Description","page":"N-Monitoring","title":"Description","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The N-monitoring problem is described in [1], sections 4.1 and 6.1.","category":"page"},{"location":"examples/n-monitoring/#Influence-Diagram","page":"N-Monitoring","title":"Influence Diagram","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"(Image: )","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The incluence diagram of generalized N-monitoring problem where N1 and indices k=1N The nodes are associated with states as follows. Load state L=high low denotes the load, report states R_k=high low report the load state to the action states A_k=yes no which decide whether to fortificate failure state F=failure success Finally, the utility at target T depends on the whether F fails and the fortification costs.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"We draw the magnitude and cost of fortification c_kU(01) from a uniform distribution. Fortification is defined","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"f(A_k=yes) = c_k","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"f(A_k=no) = 0","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"using Printf, Random, Logging, Parameters, JuMP, Gurobi\nusing DecisionProgramming\n\nRandom.seed!(13)\n\nconst N = 4\nconst L = [1]\nconst R_k = [k + 1 for k in 1:N]\nconst A_k = [(N + 1) + k for k in 1:N]\nconst F = [2*N + 2]\nconst T = [2*N + 3]\nconst L_states = [\"high\", \"low\"]\nconst R_k_states = [\"high\", \"low\"]\nconst A_k_states = [\"yes\", \"no\"]\nconst F_states = [\"failure\", \"success\"]\nconst c_k = rand(N)\nfortification(k, a) = [c_k[k], 0][a]\n\nS = States([\n    (length(L_states), L),\n    (length(R_k_states), R_k),\n    (length(A_k_states), A_k),\n    (length(F_states), F)\n])\nC = Vector{ChanceNode}()\nD = Vector{DecisionNode}()\nV = Vector{ValueNode}()\nX = Vector{Probabilities}()\nY = Vector{Consequences}()","category":"page"},{"location":"examples/n-monitoring/#Load-State-Probability","page":"N-Monitoring","title":"Load State Probability","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probability that the load is high. We draw xU(01) from uniform distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(L=high)=x","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for j in L\n    I_j = Vector{Node}()\n    X_j = zeros(S[I_j]..., S[j])\n    X_j[1] = rand()\n    X_j[2] = 1.0 - X_j[1]\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(X_j))\nend","category":"page"},{"location":"examples/n-monitoring/#Reporting-Probability","page":"N-Monitoring","title":"Reporting Probability","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probabilities of the report states correspond to the load state. We draw the values xU(01) and yU(01) from uniform distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(R_k=highL=high)=maxxx-1","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(R_k=lowL=low)=maxyy-1","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for j in R_k\n    I_j = L\n    x, y = rand(2)\n    X_j = zeros(S[I_j]..., S[j])\n    X_j[1, 1] = max(x, 1-x)\n    X_j[1, 2] = 1.0 - X_j[1, 1]\n    X_j[2, 2] = max(y, 1-y)\n    X_j[2, 1] = 1.0 - X_j[2, 2]\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(X_j))\nend","category":"page"},{"location":"examples/n-monitoring/#Decision-to-Fortify","page":"N-Monitoring","title":"Decision to Fortify","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for (i, j) in zip(R_k, A_k)\n    I_j = [i]\n    push!(D, DecisionNode(j, I_j))\nend","category":"page"},{"location":"examples/n-monitoring/#Probability-of-Failure","page":"N-Monitoring","title":"Probability of Failure","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probabilities of failure which are decresead by fortifications. We draw the values zU(01) and wU(01) from uniform distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(F=failureA_NA_1L=high)=fracmaxz 1-zexp(_k=1N f(A_k))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(F=failureA_NA_1L=low)=fracminw 1-wexp(_k=1N f(A_k))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for j in F\n    I_j = L ∪ A_k\n    x, y = rand(2)\n    X_j = zeros(S[I_j]..., S[j])\n    for s in paths(S[A_k])\n        d = exp(sum(fortification(k, a) for (k, a) in enumerate(s)))\n        X_j[1, s..., 1] = max(x, 1-x) / d\n        X_j[1, s..., 2] = 1.0 - X_j[1, s..., 1]\n        X_j[2, s..., 1] = min(y, 1-y) / d\n        X_j[2, s..., 2] = 1.0 - X_j[2, s..., 1]\n    end\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(X_j))\nend","category":"page"},{"location":"examples/n-monitoring/#Consequences","page":"N-Monitoring","title":"Consequences","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Utility from consequences at target T from failure state F","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"g(F=failure) = 0","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"g(F=success) = 100","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Utility from consequences at target T from action states A_k is -f(A_k)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Total cost","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Y(F A_N  A_1) = g(F) + (-f(A_N)) +  + (-f(A_1))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for j in T\n    I_j = A_k ∪ F\n    Y_j = zeros(S[I_j]...)\n    for s in paths(S[A_k])\n        cost = sum(-fortification(k, a) for (k, a) in enumerate(s))\n        Y_j[s..., 1] = cost + 0\n        Y_j[s..., 2] = cost + 100\n    end\n    push!(V, ValueNode(j, I_j))\n    push!(Y, Consequences(Y_j))\nend","category":"page"},{"location":"examples/n-monitoring/#Validating-Influence-Diagram","page":"N-Monitoring","title":"Validating Influence Diagram","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"validate_influence_diagram(S, C, D, V)\ns_c = sortperm([c.j for c in C])\ns_d = sortperm([d.j for d in D])\ns_v = sortperm([v.j for v in V])\nC = C[s_c]\nD = D[s_d]\nV = V[s_v]\nX = X[s_c]\nY = Y[s_v]","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"P = DefaultPathProbability(C, X)\nU = DefaultPathUtility(V, Y)","category":"page"},{"location":"examples/n-monitoring/#Decision-Model","page":"N-Monitoring","title":"Decision Model","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"U⁺ = PositivePathUtility(S, U)\nmodel = DecisionModel(S, D, P; positive_path_utility=true)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"probability_sum_cut(model, S, P)\nnumber_of_paths_cut(model, S, P)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"EV = expected_value(model, S, U⁺)\n@objective(model, Max, EV)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"optimizer = optimizer_with_attributes(\n    Gurobi.Optimizer,\n    \"IntFeasTol\"      => 1e-9,\n    \"LazyConstraints\" => 1,\n)\nset_optimizer(model, optimizer)\noptimize!(model)","category":"page"},{"location":"examples/n-monitoring/#Analyzing-Results","page":"N-Monitoring","title":"Analyzing Results","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Z = DecisionStrategy(model, D)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"julia> print_decision_strategy(S, Z)\n┌────────┬──────┬───┐\n│  Nodes │ (2,) │ 6 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 1 │\n└────────┴──────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (3,) │ 7 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 1 │\n└────────┴──────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (4,) │ 8 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 1 │\n└────────┴──────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (5,) │ 9 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 1 │\n└────────┴──────┴───┘","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"sprobs = StateProbabilities(S, P, Z)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"julia> print_state_probabilities(sprobs, L)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     1 │ 0.564449 │ 0.435551 │             │\n└───────┴──────────┴──────────┴─────────────┘\njulia> print_state_probabilities(sprobs, R_k)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     2 │ 0.515575 │ 0.484425 │             │\n│     3 │ 0.442444 │ 0.557556 │             │\n│     4 │ 0.543724 │ 0.456276 │             │\n│     5 │ 0.552515 │ 0.447485 │             │\n└───────┴──────────┴──────────┴─────────────┘\njulia> print_state_probabilities(sprobs, A_k)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     6 │ 1.000000 │ 0.000000 │             │\n│     7 │ 1.000000 │ 0.000000 │             │\n│     8 │ 1.000000 │ 0.000000 │             │\n│     9 │ 1.000000 │ 0.000000 │             │\n└───────┴──────────┴──────────┴─────────────┘\njulia> print_state_probabilities(sprobs, F)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│    10 │ 0.038697 │ 0.961303 │             │\n└───────┴──────────┴──────────┴─────────────┘","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"udist = UtilityDistribution(S, P, U, Z)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"julia> print_utility_distribution(udist)\n┌───────────┬─────────────┐\n│   Utility │ Probability │\n│   Float64 │     Float64 │\n├───────────┼─────────────┤\n│ -2.881344 │    0.038697 │\n│ 97.118656 │    0.961303 │\n└───────────┴─────────────┘","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"julia> print_statistics(udist)\n┌──────────┬────────────┐\n│     Name │ Statistics │\n│   String │    Float64 │\n├──────────┼────────────┤\n│     Mean │  93.248950 │\n│      Std │  19.287197 │\n│ Skewness │  -4.783515 │\n│ Kurtosis │  20.882012 │\n└──────────┴────────────┘","category":"page"},{"location":"examples/n-monitoring/#References","page":"N-Monitoring","title":"References","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"examples/pig-breeding/#Pig-Breeding","page":"Pig Breeding","title":"Pig Breeding","text":"","category":"section"},{"location":"examples/pig-breeding/#Description","page":"Pig Breeding","title":"Description","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The pig breeding problem as described in [1].","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"\"A pig breeder is growing pigs for a period of four months and subsequently selling them. During this period the pig may or may not develop a certain disease. If the pig has the disease at the time it must be sold, the pig must be sold for slaughtering, and its expected market price is then 300 DKK (Danish kroner). If it is disease free, its expected market price as a breeding animal is 1000 DKK","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Once a month, a veterinary doctor sees the pig and makes a test for presence of the disease. If the pig is ill, the test will indicate this with probability 0.80, and if the pig is healthy, the test will indicate this with probability 0.90. At each monthly visit, the doctor may or may not treat the pig for the disease by injecting a certain drug. The cost of an injection is 100 DKK.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"A pig has the disease in the first month with probability 0.10. A healthy pig develops the disease in the subsequent month with probability 0.20 without injection, whereas a healthy and treated pig develops the disease with probability 0.10, so the injection has some preventive effect. An untreated pig that is unhealthy will remain so in the subsequent month with probability 0.90, whereas the similar probability is 0.50 for an unhealthy pig that is treated. Thus spontaneous cure is possible, but treatment is beneficial on average.\"","category":"page"},{"location":"examples/pig-breeding/#Influence-Diagram","page":"Pig Breeding","title":"Influence Diagram","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"(Image: )","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The influence diagram for the the generalized N-month pig breeding. The nodes are associated with the following states. Health states h_k=illhealthy represent the health of the pig at month k=1N. Test states t_k=positivenegative represent the result from testing the pig at month k=1N-1. Treat states d_k=treat pass represent the decision to treat the pig with an injection at month k=1N-1.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The dashed arcs represent the no-forgetting principle and we can toggle them on and off in the formulation.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming, we start by defining the node indices and states, as follows:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"using Printf, Parameters, JuMP, Gurobi\nusing DecisionProgramming\n\nconst N = 4\nconst health = [3*k - 2 for k in 1:N]\nconst test = [3*k - 1 for k in 1:(N-1)]\nconst treat = [3*k for k in 1:(N-1)]\nconst cost = [(3*N - 2) + k for k in 1:(N-1)]\nconst price = [(3*N - 2) + N]\nconst health_states = [\"ill\", \"healthy\"]\nconst test_states = [\"positive\", \"negative\"]\nconst treat_states = [\"treat\", \"pass\"]\n\nS = States([\n    (length(health_states), health),\n    (length(test_states), test),\n    (length(treat_states), treat),\n])\nC = Vector{ChanceNode}()\nD = Vector{DecisionNode}()\nV = Vector{ValueNode}()\nX = Vector{Probabilities}()\nY = Vector{Consequences}()","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Next, we define the nodes with their information sets and corresponding probabilities or consequences.","category":"page"},{"location":"examples/pig-breeding/#Health-at-First-Month","page":"Pig Breeding","title":"Health at First Month","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The probability that pig is ill in the first month is","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_1 = ill)=01","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We obtain the complement probabilities for binary states by subtracting from one","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_1 = healthy)=1-ℙ(h_1 = ill)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming, we add the nodes and probabilities as follows:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for j in health[[1]]\n    I_j = Vector{Node}()\n    X_j = zeros(S[I_j]..., S[j])\n    X_j[1] = 0.1\n    X_j[2] = 1.0 - X_j[1]\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(X_j))\nend","category":"page"},{"location":"examples/pig-breeding/#Health-at-Subsequent-Months","page":"Pig Breeding","title":"Health at Subsequent Months","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The probability that the pig is ill in the subsequent months k=2N given the treatment decision in and state of health in the previous month, we have","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = pass h_k-1 = healthy)=02","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = treat h_k-1 = healthy)=01","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = pass h_k-1 = ill)=09","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = treat h_k-1 = ill)=05","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for (i, k, j) in zip(health[1:end-1], treat, health[2:end])\n    I_j = [i, k]\n    X_j = zeros(S[I_j]..., S[j])\n    X_j[2, 2, 1] = 0.2\n    X_j[2, 2, 2] = 1.0 - X_j[2, 2, 1]\n    X_j[2, 1, 1] = 0.1\n    X_j[2, 1, 2] = 1.0 - X_j[2, 1, 1]\n    X_j[1, 2, 1] = 0.9\n    X_j[1, 2, 2] = 1.0 - X_j[1, 2, 1]\n    X_j[1, 1, 1] = 0.5\n    X_j[1, 1, 2] = 1.0 - X_j[1, 1, 1]\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(X_j))\nend","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Note that the order of states indexing the probabilities is reversed compared to the mathematical definition.","category":"page"},{"location":"examples/pig-breeding/#Health-Test","page":"Pig Breeding","title":"Health Test","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The probabilities that test indicates pig's health correctly at month k=1N-1, we have","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(t_k = positive  h_k = ill) = 08","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(t_k = negative  h_k = healthy) = 09","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for (i, j) in zip(health, test)\n    I_j = [i]\n    X_j = zeros(S[I_j]..., S[j])\n    X_j[1, 1] = 0.8\n    X_j[1, 2] = 1.0 - X_j[1, 1]\n    X_j[2, 2] = 0.9\n    X_j[2, 1] = 1.0 - X_j[2, 2]\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(X_j))\nend","category":"page"},{"location":"examples/pig-breeding/#Decision-to-Treat","page":"Pig Breeding","title":"Decision to Treat","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programing, we add the decision nodes for decision to treat the pig as follows:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for (i, j) in zip(test, treat)\n    I_j = [i]\n    push!(D, DecisionNode(j, I_j))\nend","category":"page"},{"location":"examples/pig-breeding/#Cost-of-Treatment","page":"Pig Breeding","title":"Cost of Treatment","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The cost of treatment decision for the pig at month k=1N-1 is defined","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(d_k=treat) = -100","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(d_k=pass) = 0","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for (i, j) in zip(treat, cost)\n    I_j = [i]\n    Y_j = zeros(S[I_j]...)\n    Y_j[1] = -100\n    Y_j[2] = 0\n    push!(V, ValueNode(j, I_j))\n    push!(Y, Consequences(Y_j))\nend","category":"page"},{"location":"examples/pig-breeding/#Selling-Price","page":"Pig Breeding","title":"Selling Price","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The price of given the pig health at month N is defined","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(h_N=ill) = 300","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(h_N=healthy) = 1000","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for (i, j) in zip(health[end], price)\n    I_j = [i]\n    Y_j = zeros(S[I_j]...)\n    Y_j[1] = 300\n    Y_j[2] = 1000\n    push!(V, ValueNode(j, I_j))\n    push!(Y, Consequences(Y_j))\nend","category":"page"},{"location":"examples/pig-breeding/#Validating-Influence-Diagram","page":"Pig Breeding","title":"Validating Influence Diagram","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Finally, we need to validate the influence diagram and sort the nodes, probabilities and consequences in increasing order by the node indices.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"validate_influence_diagram(S, C, D, V)\ns_c = sortperm([c.j for c in C])\ns_d = sortperm([d.j for d in D])\ns_v = sortperm([v.j for v in V])\nC = C[s_c]\nD = D[s_d]\nV = V[s_v]\nX = X[s_c]\nY = Y[s_v]","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We define the path probability.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"P = DefaultPathProbability(C, X)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"As the path utility, we use the default, which is the sum of the consequences given the path.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"U = DefaultPathUtility(V, Y)","category":"page"},{"location":"examples/pig-breeding/#Decision-Model","page":"Pig Breeding","title":"Decision Model","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"U⁺ = PositivePathUtility(S, U)\nmodel = DecisionModel(S, D, P; positive_path_utility=true)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"number_of_paths_cut(model, S, P)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"EV = expected_value(model, S, U⁺)\n@objective(model, Max, EV)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"optimizer = optimizer_with_attributes(\n    Gurobi.Optimizer,\n    \"IntFeasTol\"      => 1e-9,\n    \"LazyConstraints\" => 1,\n)\nset_optimizer(model, optimizer)\noptimize!(model)","category":"page"},{"location":"examples/pig-breeding/#Analyzing-Results","page":"Pig Breeding","title":"Analyzing Results","text":"","category":"section"},{"location":"examples/pig-breeding/#Decision-Strategy","page":"Pig Breeding","title":"Decision Strategy","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Z = DecisionStrategy(model, D)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"julia> print_decision_strategy(S, Z)\n┌────────┬──────┬───┐\n│  Nodes │ (2,) │ 3 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 2 │\n│ States │ (2,) │ 2 │\n└────────┴──────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (5,) │ 6 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 2 │\n└────────┴──────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (8,) │ 9 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 2 │\n└────────┴──────┴───┘","category":"page"},{"location":"examples/pig-breeding/#State-Probabilities","page":"Pig Breeding","title":"State Probabilities","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"sprobs = StateProbabilities(S, P, Z)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"julia> print_state_probabilities(sprobs, health)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     1 │ 0.100000 │ 0.900000 │             │\n│     4 │ 0.270000 │ 0.730000 │             │\n│     7 │ 0.295300 │ 0.704700 │             │\n│    10 │ 0.305167 │ 0.694833 │             │\n└───────┴──────────┴──────────┴─────────────┘\njulia> print_state_probabilities(sprobs, test)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     2 │ 0.170000 │ 0.830000 │             │\n│     5 │ 0.289000 │ 0.711000 │             │\n│     8 │ 0.306710 │ 0.693290 │             │\n└───────┴──────────┴──────────┴─────────────┘\njulia> print_state_probabilities(sprobs, treat)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     3 │ 0.000000 │ 1.000000 │             │\n│     6 │ 0.289000 │ 0.711000 │             │\n│     9 │ 0.306710 │ 0.693290 │             │\n└───────┴──────────┴──────────┴─────────────┘","category":"page"},{"location":"examples/pig-breeding/#Utility-Distribution","page":"Pig Breeding","title":"Utility Distribution","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"udist = UtilityDistribution(S, P, U, Z)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"julia> print_utility_distribution(udist)\n┌─────────────┬─────────────┐\n│     Utility │ Probability │\n│     Float64 │     Float64 │\n├─────────────┼─────────────┤\n│  100.000000 │    0.047857 │\n│  200.000000 │    0.129330 │\n│  300.000000 │    0.127980 │\n│  800.000000 │    0.061753 │\n│  900.000000 │    0.247160 │\n│ 1000.000000 │    0.385920 │\n└─────────────┴─────────────┘","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"julia> print_statistics(udist)\n┌──────────┬────────────┐\n│     Name │ Statistics │\n│   String │    Float64 │\n├──────────┼────────────┤\n│     Mean │ 726.812100 │\n│      Std │ 338.460723 │\n│ Skewness │  -0.811628 │\n│ Kurtosis │  -1.173465 │\n└──────────┴────────────┘","category":"page"},{"location":"examples/pig-breeding/#References","page":"Pig Breeding","title":"References","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"[1]: Lauritzen, S. L., & Nilsson, D. (2001). Representing and solving decision problems with limited information. Management Science, 47(9), 1235–1251. https://doi.org/10.1287/mnsc.47.9.1235.9779","category":"page"},{"location":"decision-programming/computational-complexity/#Computational-Complexity","page":"Computational Complexity","title":"Computational Complexity","text":"","category":"section"},{"location":"decision-programming/computational-complexity/#Introduction","page":"Computational Complexity","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"Decision programming relies on mixed-integer linear programming, which is known to be an NP-complete problem. In this section, we analyze how the influence diagram affects the size of the mixed-integer linear model, determining whether it is tractable.","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We use the following inequalities for sum and product of non-negative elements A to derive the lower and upper bounds for the number of paths and the number of decision stages. Sum inequality:","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"A left(min_aA aright)  _aA a  A left(max_aA aright)","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"Product inequality:","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"left(min_aA aright)^A  _aA a  left(max_aA aright)^A","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"The following bounds for the number of paths and the number of decision stages show how the number of states, nodes, and arcs affects the size of the model.","category":"page"},{"location":"decision-programming/computational-complexity/#Number-of-Paths","page":"Computational Complexity","title":"Number of Paths","text":"","category":"section"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We define the number of paths as","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"𝐒=_iCD S_i","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"From the definition of the influence diagram, we have the path length of n=CD Then, we have the bounds for the number of paths as","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"left(min_iCD S_iright)^n  𝐒  left(max_iCD S_iright)^n","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We assume non-trivial influence diagram such that S_i2 for all iCD. That is, each decision or chance node has at least two states. Therefore, the number of paths is always exponential to the path length of n","category":"page"},{"location":"decision-programming/computational-complexity/#Number-of-Decision-Stages","page":"Computational Complexity","title":"Number of Decision Stages","text":"","category":"section"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We define the number of decision stages as","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"_iD𝐒_I(i) S_i = _iD S_i _jI(i)S_j = _iD _jI(i)iS_j","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"From the definition of the information set, for all iD we have I(i)iCD with size 1I(i)i=I(i)+1mn where m denotes the upper bound of influence other nodes have on any decision node. Also, we have the number of decision nodes 0Dn Thus, we have the bounds","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"0  _iD𝐒_I(i) S_i  D left(max_iCD S_jright)^m","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"In the worst case, m=n, a decision node is influenced by every other chance and decision node. However, in most practical cases, we have m  n where decision nodes are influenced only by a limited number of other chance and decision nodes, making models easier to solve.","category":"page"},{"location":"examples/contingent-portfolio-programming/#Contingent-Portfolio-Programming","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/#Description","page":"Contingent Portfolio Programming","title":"Description","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"[1], section 4.2","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"For instance, assume that the first-stage decisions specify which technology development projects will be started to generate patent-based intellectual property ( P ) for a platform. This intellectual property contributes subject to some uncertainties to the technical competitiveness ( T ) of the platform. In the second stage, it is possible to carry out application ( A ) development projects which, when completed, yield cash flows that depend on the market share of the platform. This market share ( M ) depends on the competitiveness of the platform and the number of developed applications. The aim is to maximize the cash flows from application projects less the cost of technology and application development projects.","category":"page"},{"location":"examples/contingent-portfolio-programming/#Formulation","page":"Contingent Portfolio Programming","title":"Formulation","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/#Projects","page":"Contingent Portfolio Programming","title":"Projects","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"(Image: )","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"The influence diagram of the contingent portfolio programming (CPP) problem. NOTE: the ID needs to be edited so that there's no i and k. Basically, the decision nodes represent decisions on which i and k to pick.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"There are n_T technology development projects and n_A application development projects.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Decision states to develop patents","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"d_i^PD_i^P=q_1^P q_2^P) q_2^P q_3^P)  q_D^P^P q_D^P+1^P)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Chance states of technical competitiveness c_j^TC_j^T","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Decision states to develop applications","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"d_k^AD^A=q_1^A q_2^A) q_2^A q_3^A)  q_D^A^A q_D^A+1^A)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Chance states of market size c_l^MC_l^M","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Probability of technical competitiveness c_j^T given the range d_i^P: ℙ(c_j^Td_i^P)01","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Probability of market share c_l^M given the technical competitiveness c_j^T and range d_k^A: ℙ(c_l^Mc_j^Td_k^A)01","category":"page"},{"location":"examples/contingent-portfolio-programming/#Portfolio-Selection","page":"Contingent Portfolio Programming","title":"Portfolio Selection","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Technology project t costs I_tℝ^+ and generates O_tℕ patents.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Application project a costs I_aℝ^+ and generates O_aℕ applications. If completed, provides cash flow V(ac_l^M)ℝ^+","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Decision variables x^T(t)0 1 indicate which technologies are selected.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Decision variables x^A(ad_i^Pc_j^T)0 1 indicate which applications are selected.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Number of patents x^T(t) = _i x_i^T(t) z(d_i^P)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Number of applications x^A(ad_i^Pc_j^T) = _k x_k^A(ad_i^Pc_j^T) z(d_k^Ad_i^Pc_j^T)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Constraints","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"_t x_i^T(t) le z(d_i^P)n_T quad forall i","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"_a x_k^A(ad_i^Pc_j^T) le z(d_i^P)n_A quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"_a x_k^A(ad_i^Pc_j^T) le z(d_k^Ad_i^Pc_j^T)n_A quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"q_i^P - (1-z(d_i^P))M le sum_t x_i^T(t)O_t le q_i+1^P + (1-z(d_i^P))M - 𝝐 quad forall i","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"q_k^A - (1-z(d_k^Ad_i^Pc_j^T))M le sum_a x_k^A(ad_i^Pc_j^T)O_a le q_k+1^A + (1-z(d_k^Ad_i^Pc_j^T))M - 𝝐 quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"x_i^T(t)0 1 quad forall i","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"x_k^A(ad_i^Pc_j^T)0 1 quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Large constant M (e.g. frac32textmaxsum_t O_tsum_a O_a)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Small constant varepsilon = frac12textminO_t O_a","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Path utility","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"mathcalU(s) = sum_a x_k^A(ad_i^Pc_j^T) (V(ac_l^M) - I_a) - _t x_i^T(t) I_t","category":"page"},{"location":"examples/contingent-portfolio-programming/#References","page":"Contingent Portfolio Programming","title":"References","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#Analyzing-Decision-Strategies","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/#Introduction","page":"Analyzing Decision Strategies","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We can analyze fixed decision strategies Z on an influence diagram G, such as ones resulting from the optimization, by generating the active paths 𝐒^Z","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#Active-Paths","page":"Analyzing Decision Strategies","title":"Active Paths","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We can generate active paths 𝐬𝐒^Z as follows.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"Initialize path 𝐬 of length n with undefined values.\nFill path with chance states 𝐬_jS_j for all jC\nIn increasing order of decision nodes jD, fill decision states by computing decision strategy 𝐬_j=Z_j(𝐬_I(j))","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The path probability for all active paths is equal to the upper bound","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(𝐬Z)=p(𝐬) quad 𝐬𝐒^Z","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We exclude inactive paths from the analysis because their path probabilities are zero.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#Utility-Distribution","page":"Analyzing Decision Strategies","title":"Utility Distribution","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We define unique path utility values as","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"mathcalU^=mathcalU(𝐬)𝐬𝐒^Z","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The probability mass function of the utility distribution associates each unique path utility to a probability as follows","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(X=u)=_𝐬𝐒^ZmathcalU(𝐬)=u p(𝐬)quad umathcalU^","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"From the utility distribution, we can calculate the cumulative distribution, statistics, and risk measures. The relevant statistics are expected value, standard deviation, skewness and kurtosis. Risk measures focus on the conditional value-at-risk (CVaR), also known as, expected shortfall.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#Measuring-Risk","page":"Analyzing Decision Strategies","title":"Measuring Risk","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"(Image: )","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We have a discrete probability distribution f(x)=ℙ(X=x)0 1 over the domain xΩ with _xΩℙ(X=x)=1 and its cumulative distribution function F(x) = _x^Ω x^xf(x^)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We present the concept of conditional value-at-risk, a risk measure of the conditional expected value of the tail of a probability distribution for a given threshold of α(0 1)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"First, we define the value-at-risk as","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"operatornameVaR(α) = x_α = infxΩ  F(x)  α","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"Then, we define the conditional value-at-risk as","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"operatornameCVaR(α)=left(_xx_α x  f(x) - left(_xx_α f(x) - αright) x_α right)  α","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"In the above figure, we have an example of discrete probability distribution with a positive expected value (green diamond) and its cumulative distribution. The red horizontal line represents the threshold α and the yellow diamond marks the value-at-risk x_α, that is, the smallest value x such that the cumulative probability is above α The red circles are the values x below that fall below or equal x_α and the orange diamond is the conditional value-at-risk.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#State-Probabilities","page":"Analyzing Decision Strategies","title":"State Probabilities","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We denote paths with fixed states where ϵ denotes an empty state using a recursive definition.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"beginaligned\n𝐒_ϵ = 𝐒^Z \n𝐒_ϵs_i = 𝐬𝐒_ϵ  𝐬_i=s_i \n𝐒_ϵs_is_j = 𝐬𝐒_ϵs_i  𝐬_j=s_jquad ji\nendaligned","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The probability of all paths sums to one","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(ϵ) = sum_𝐬𝐒_ϵ p(𝐬) = 1","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"State probabilities for each node iCD and state s_iS_i denote how likely the state occurs given all path probabilities","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(s_iϵ) = sum_𝐬𝐒_ϵs_i fracp(𝐬)ℙ(ϵ) = sum_𝐬𝐒_ϵs_i p(𝐬)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"An active state is a state with positive state probability ℙ(s_ic)0 given conditions c","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We can generalize the state probabilities as conditional probabilities using a recursive definition. Generalized state probabilities allow us to explore how fixing active states affect the probabilities of other states. First, we choose an active state s_i and fix its value. Fixing an inactive state would make all state probabilities zero. Then, we can compute the conditional state probabilities as follows.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(s_jϵs_i) = sum_𝐬𝐒_ϵs_is_j fracp(𝐬)ℙ(s_iϵ)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We can then repeat this process by choosing an active state from the new conditional state probabilities s_k that is different from previously chosen states kj","category":"page"},{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"DecisionProgramming.jl API reference.","category":"page"},{"location":"api/#influence_diagram.jl","page":"API Reference","title":"influence_diagram.jl","text":"","category":"section"},{"location":"api/#Nodes","page":"API Reference","title":"Nodes","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Node\nChanceNode\nDecisionNode\nValueNode\nState\nStates\nStates(::Vector{Tuple{State, Vector{Node}}})\nvalidate_influence_diagram","category":"page"},{"location":"api/#DecisionProgramming.Node","page":"API Reference","title":"DecisionProgramming.Node","text":"Node type. Alias for Int.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.ChanceNode","page":"API Reference","title":"DecisionProgramming.ChanceNode","text":"Chance node type.\n\nExamples\n\nc = ChanceNode(3, [1, 2])\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DecisionNode","page":"API Reference","title":"DecisionProgramming.DecisionNode","text":"Decision node type.\n\nExamples\n\nd = DecisionNode(2, [1])\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.ValueNode","page":"API Reference","title":"DecisionProgramming.ValueNode","text":"Value node type.\n\nExamples\n\nv = ValueNode(4, [1, 3])\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.State","page":"API Reference","title":"DecisionProgramming.State","text":"State type. Alias for Int.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.States","page":"API Reference","title":"DecisionProgramming.States","text":"States type. Works like Vector{State}.\n\nExamples\n\nS = States([2, 3, 2, 4])\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.States-Tuple{Array{Tuple{Int64,Array{Int64,1}},1}}","page":"API Reference","title":"DecisionProgramming.States","text":"Construct states from vector of (state, nodes) tuples.\n\nExamples\n\njulia> S = States([(2, [1, 3]), (3, [2, 4, 5])])\nStates([2, 3, 2, 3, 3])\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.validate_influence_diagram","page":"API Reference","title":"DecisionProgramming.validate_influence_diagram","text":"Validate influence diagram.\n\n\n\n\n\n","category":"function"},{"location":"api/#Paths","page":"API Reference","title":"Paths","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Path\npaths","category":"page"},{"location":"api/#DecisionProgramming.Path","page":"API Reference","title":"DecisionProgramming.Path","text":"Path type. Alias for NTuple{N, State} where N.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.paths","page":"API Reference","title":"DecisionProgramming.paths","text":"Iterate over paths in lexicographical order.\n\nExamples\n\njulia> states = States([2, 3])\njulia> collect(paths(states))[:]\n[(1, 1), (2, 1), (1, 2), (2, 2), (1, 3), (2, 3)]\n\n\n\n\n\nIterate over paths with fixed states in lexicographical order.\n\nExamples\n\njulia> states = States([2, 3])\njulia> collect(paths(states, fixed=Dict(1=>2)))[:]\n[(2, 1), (2, 2), (2, 3)]\n\n\n\n\n\n","category":"function"},{"location":"api/#Probabilities","page":"API Reference","title":"Probabilities","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Probabilities\nProbabilities(::Path)","category":"page"},{"location":"api/#DecisionProgramming.Probabilities","page":"API Reference","title":"DecisionProgramming.Probabilities","text":"Construct and validate stage probabilities.\n\nExamples\n\ndata = [0.5 0.5 ; 0.2 0.8]\nX = Probabilities(data)\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.Probabilities-Tuple{Tuple{Vararg{Int64,N}} where N}","page":"API Reference","title":"DecisionProgramming.Probabilities","text":"Return probabilities of information path s.\n\nExamples\n\njulia> s = (1, 2)\njulia> X(s)\n0.5\n\n\n\n\n\n","category":"method"},{"location":"api/#Path-Probability","page":"API Reference","title":"Path Probability","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"AbstractPathProbability\nDefaultPathProbability\nDefaultPathProbability(::Path)","category":"page"},{"location":"api/#DecisionProgramming.AbstractPathProbability","page":"API Reference","title":"DecisionProgramming.AbstractPathProbability","text":"Abstract path probability type.\n\nExamples\n\nstruct PathProbability <: AbstractPathProbability\n    C::Vector{ChanceNode}\n    # ...\nend\n\n(U::PathProbability)(s::Path) = ...\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DefaultPathProbability","page":"API Reference","title":"DecisionProgramming.DefaultPathProbability","text":"Path probability.\n\nExamples\n\nP = DefaultPathProbability(C, X)\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DefaultPathProbability-Tuple{Tuple{Vararg{Int64,N}} where N}","page":"API Reference","title":"DecisionProgramming.DefaultPathProbability","text":"Evalute path probability.\n\n\n\n\n\n","category":"method"},{"location":"api/#Consequences","page":"API Reference","title":"Consequences","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Consequences\nConsequences(::Path)","category":"page"},{"location":"api/#DecisionProgramming.Consequences","page":"API Reference","title":"DecisionProgramming.Consequences","text":"State utilities.\n\nExamples\n\nvals = [1.0 -2.0; 3.0 4.0]\nY = Consequences(vals)\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.Consequences-Tuple{Tuple{Vararg{Int64,N}} where N}","page":"API Reference","title":"DecisionProgramming.Consequences","text":"Return consequences of information path s.\n\nExamples\n\njulia> s = (1, 2)\njulia> Y(s)\n-2.0\n\n\n\n\n\n","category":"method"},{"location":"api/#Path-Utility","page":"API Reference","title":"Path Utility","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"AbstractPathUtility\nDefaultPathUtility\nDefaultPathUtility(::Path)","category":"page"},{"location":"api/#DecisionProgramming.AbstractPathUtility","page":"API Reference","title":"DecisionProgramming.AbstractPathUtility","text":"Abstract path utility type.\n\nExamples\n\nstruct PathUtility <: AbstractPathUtility\n    V::Vector{ValueNode}\n    # ...\nend\n\n(U::PathUtility)(s::Path) = ...\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DefaultPathUtility","page":"API Reference","title":"DecisionProgramming.DefaultPathUtility","text":"Default path utility.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DefaultPathUtility-Tuple{Tuple{Vararg{Int64,N}} where N}","page":"API Reference","title":"DecisionProgramming.DefaultPathUtility","text":"Evaluate default path utility.\n\n\n\n\n\n","category":"method"},{"location":"api/#decision_model.jl","page":"API Reference","title":"decision_model.jl","text":"","category":"section"},{"location":"api/#Decision-Model","page":"API Reference","title":"Decision Model","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"PositivePathUtility\nPositivePathUtility(::Path)\nvariables\nDecisionModel\nDecisionModel(::States, ::Vector{DecisionNode}, ::AbstractPathProbability; ::Bool)\nprobability_sum_cut(::DecisionModel, ::States, ::AbstractPathProbability)\nnumber_of_paths_cut(::DecisionModel, ::States, ::AbstractPathProbability; ::Float64)","category":"page"},{"location":"api/#DecisionProgramming.PositivePathUtility","page":"API Reference","title":"DecisionProgramming.PositivePathUtility","text":"Positive affine transformation of path utility.\n\nExamples\n\nU⁺ = PositivePathUtility(S, U)\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.PositivePathUtility-Tuple{Tuple{Vararg{Int64,N}} where N}","page":"API Reference","title":"DecisionProgramming.PositivePathUtility","text":"Evaluate positive affine transformation of the path utility.\n\nExamples\n\njulia> all(U⁺(s) ≥ 1 for s in paths(S))\ntrue\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.variables","page":"API Reference","title":"DecisionProgramming.variables","text":"Create a multidimensional array of JuMP variables.\n\nExamples\n\nmodel = Model()\nv1 = variables(model, [2, 3, 2])\nv2 = variables(model, [2, 3, 2]; binary=true)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.DecisionModel","page":"API Reference","title":"DecisionProgramming.DecisionModel","text":"DecisionModel type. Alias for JuMP.Model.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DecisionModel-Tuple{States,Array{DecisionNode,1},AbstractPathProbability}","page":"API Reference","title":"DecisionProgramming.DecisionModel","text":"Construct a DecisionModel from states, decision nodes and path probability.\n\nExamples\n\nmodel = DecisionModel(S, D, P; positive_path_utility=true)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.probability_sum_cut-Tuple{JuMP.Model,States,AbstractPathProbability}","page":"API Reference","title":"DecisionProgramming.probability_sum_cut","text":"Adds a probability sum cut to the model as a lazy constraint.\n\nExamples\n\nprobability_sum_cut(model, S, P)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.number_of_paths_cut-Tuple{JuMP.Model,States,AbstractPathProbability}","page":"API Reference","title":"DecisionProgramming.number_of_paths_cut","text":"Adds a number of paths cut to the model as a lazy constraint.\n\nExamples\n\natol = 0.9  # Tolerance to trigger the creation of the lazy cut\nnumber_of_paths_cut(model, S, P; atol=atol)\n\n\n\n\n\n","category":"method"},{"location":"api/#Objective-Functions","page":"API Reference","title":"Objective Functions","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"expected_value(::DecisionModel, ::States, ::AbstractPathUtility)\nconditional_value_at_risk(::DecisionModel, ::States, ::AbstractPathUtility, ::Float64)","category":"page"},{"location":"api/#DecisionProgramming.expected_value-Tuple{JuMP.Model,States,AbstractPathUtility}","page":"API Reference","title":"DecisionProgramming.expected_value","text":"Create an expected value objective.\n\nExamples\n\nEV = expected_value(model, S, U)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.conditional_value_at_risk-Tuple{JuMP.Model,States,AbstractPathUtility,Float64}","page":"API Reference","title":"DecisionProgramming.conditional_value_at_risk","text":"Create a conditional value-at-risk (CVaR) objective.\n\nExamples\n\nα = 0.05  # Parameter such that 0 ≤ α ≤ 1\nCVaR = conditional_value_at_risk(model, S, U, α)\n\n\n\n\n\n","category":"method"},{"location":"api/#Decision-Strategy","page":"API Reference","title":"Decision Strategy","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"LocalDecisionStrategy\nLocalDecisionStrategy(::Vector{VariableRef})\nLocalDecisionStrategy(::Path)\nDecisionStrategy\nDecisionStrategy(::DecisionModel, ::Vector{DecisionNode})","category":"page"},{"location":"api/#DecisionProgramming.LocalDecisionStrategy","page":"API Reference","title":"DecisionProgramming.LocalDecisionStrategy","text":"Decision strategy type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.LocalDecisionStrategy-Tuple{Array{VariableRef,1}}","page":"API Reference","title":"DecisionProgramming.LocalDecisionStrategy","text":"Construct decision strategy from variable refs.\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.DecisionStrategy","page":"API Reference","title":"DecisionProgramming.DecisionStrategy","text":"Global decision strategy type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DecisionStrategy-Tuple{JuMP.Model,Array{DecisionNode,1}}","page":"API Reference","title":"DecisionProgramming.DecisionStrategy","text":"Extract values for decision variables from solved decision model.\n\nExamples\n\nZ = GlobalDecisionStrategy(model, D)\n\n\n\n\n\n","category":"method"},{"location":"api/#analysis.jl","page":"API Reference","title":"analysis.jl","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"ActivePaths\nUtilityDistribution\nUtilityDistribution(::States, ::AbstractPathProbability, ::AbstractPathUtility, ::DecisionStrategy)\nStateProbabilities\nStateProbabilities(::States, ::AbstractPathProbability, ::DecisionStrategy)\nStateProbabilities(::States, ::AbstractPathProbability, ::DecisionStrategy, ::Node, ::State, ::StateProbabilities)\nvalue_at_risk(::Vector{Float64}, ::Vector{Float64}, ::Float64)\nconditional_value_at_risk(::Vector{Float64}, ::Vector{Float64}, ::Float64)","category":"page"},{"location":"api/#DecisionProgramming.ActivePaths","page":"API Reference","title":"DecisionProgramming.ActivePaths","text":"Interface for iterating over active paths given influence diagram and decision strategy.\n\nInitialize path s of length n\nFill chance states s[C] by generating subpaths paths(C)\nFill decision states s[D] by decision strategy Z and path s\n\nExamples\n\nfor s in ActivePaths(S, C, Z)\n    ...\nend\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.UtilityDistribution","page":"API Reference","title":"DecisionProgramming.UtilityDistribution","text":"UtilityDistribution type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.UtilityDistribution-Tuple{States,AbstractPathProbability,AbstractPathUtility,DecisionStrategy}","page":"API Reference","title":"DecisionProgramming.UtilityDistribution","text":"Constructs the probability mass function for path utilities on active paths.\n\nExamples\n\nUtilityDistribution(S, P, U, Z)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.StateProbabilities","page":"API Reference","title":"DecisionProgramming.StateProbabilities","text":"StateProbabilities type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.StateProbabilities-Tuple{States,AbstractPathProbability,DecisionStrategy}","page":"API Reference","title":"DecisionProgramming.StateProbabilities","text":"Associates each node with array of probabilities for each of its states occuring in active paths.\n\nExamples\n\nStateProbabilities(S, P, Z)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.StateProbabilities-Tuple{States,AbstractPathProbability,DecisionStrategy,Int64,Int64,StateProbabilities}","page":"API Reference","title":"DecisionProgramming.StateProbabilities","text":"Associates each node with array of conditional probabilities for each of its states occuring in active paths given fixed states and prior probability.\n\nExamples\n\n# Prior probabilities\nprev = StateProbabilities(S, P, Z)\n\n# Select node and fix its state\nnode = 1\nstate = 2\nStateProbabilities(S, P, Z, node, state, prev)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.value_at_risk-Tuple{Array{Float64,1},Array{Float64,1},Float64}","page":"API Reference","title":"DecisionProgramming.value_at_risk","text":"Value-at-risk.\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.conditional_value_at_risk-Tuple{Array{Float64,1},Array{Float64,1},Float64}","page":"API Reference","title":"DecisionProgramming.conditional_value_at_risk","text":"Conditional value-at-risk.\n\n\n\n\n\n","category":"method"},{"location":"api/#printing.jl","page":"API Reference","title":"printing.jl","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"print_decision_strategy\nprint_utility_distribution\nprint_state_probabilities\nprint_statistics\nprint_risk_measures","category":"page"},{"location":"api/#DecisionProgramming.print_decision_strategy","page":"API Reference","title":"DecisionProgramming.print_decision_strategy","text":"Print decision strategy.\n\nExamples\n\nprint_decision_strategy(S, Z)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_utility_distribution","page":"API Reference","title":"DecisionProgramming.print_utility_distribution","text":"Print utility distribution\n\nExamples\n\nudist = UtilityDistribution(S, P, U, Z)\nprint_utility_distribution(udist)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_state_probabilities","page":"API Reference","title":"DecisionProgramming.print_state_probabilities","text":"Print state probabilities with fixed states.\n\nExamples\n\nsprobs = StateProbabilities(S, P, U, Z)\nprint_state_probabilities(sprobs, [c.j for c in C])\nprint_state_probabilities(sprobs, [d.j for d in D])\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_statistics","page":"API Reference","title":"DecisionProgramming.print_statistics","text":"Print statistics.\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_risk_measures","page":"API Reference","title":"DecisionProgramming.print_risk_measures","text":"Print risk measures.\n\n\n\n\n\n","category":"function"},{"location":"api/#random.jl","page":"API Reference","title":"random.jl","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"random_diagram(::AbstractRNG, ::Int, ::Int, ::Int, ::Int)\nStates(::AbstractRNG, ::Vector{State}, ::Int)\nProbabilities(::AbstractRNG, ::ChanceNode, ::States)\nConsequences(::AbstractRNG, ::ValueNode, ::States; ::Float64, ::Float64)\nLocalDecisionStrategy(::AbstractRNG, ::DecisionNode, ::States)","category":"page"},{"location":"api/#DecisionProgramming.random_diagram-Tuple{AbstractRNG,Int64,Int64,Int64,Int64}","page":"API Reference","title":"DecisionProgramming.random_diagram","text":"Generate random decision diagram with n_C chance nodes, n_D decision nodes, and n_V value nodes. Parameter n_I is the upper bound on the size of the information set.\n\nExamples\n\nrng = MersenneTwister(3)\nrandom_diagram(rng, 5, 2, 3, 2)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.States-Tuple{AbstractRNG,Array{Int64,1},Int64}","page":"API Reference","title":"DecisionProgramming.States","text":"Generate n random states from states.\n\nExamples\n\nrng = MersenneTwister(3)\nS = States(rng, [2, 3], 10)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.Probabilities-Tuple{AbstractRNG,ChanceNode,States}","page":"API Reference","title":"DecisionProgramming.Probabilities","text":"Generate random probabilities for chance node c with S states.\n\nExamples\n\nrng = MersenneTwister(3)\nc = ChanceNode(2, [1])\nS = States([2, 2])\nProbabilities(rng, c, S)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.Consequences-Tuple{AbstractRNG,ValueNode,States}","page":"API Reference","title":"DecisionProgramming.Consequences","text":"Generate random consequences between low and high for value node v with S states.\n\nExamples\n\nrng = MersenneTwister(3)\nv = ValueNode(3, [1])\nS = States([2, 2])\nConsequences(rng, v, S; low=-1.0, high=1.0)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.LocalDecisionStrategy-Tuple{AbstractRNG,DecisionNode,States}","page":"API Reference","title":"DecisionProgramming.LocalDecisionStrategy","text":"Generate random decision strategy for decision node d with S states.\n\nExamples\n\nrng = MersenneTwister(3)\nd = DecisionNode(2, [1])\nS = States([2, 2])\nDecisionStrategy(rng, d, S)\n\n\n\n\n\n","category":"method"},{"location":"decision-programming/decision-model/#Decision-Model","page":"Decision Model","title":"Decision Model","text":"","category":"section"},{"location":"decision-programming/decision-model/#Introduction","page":"Decision Model","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Decision programming aims to find a decision strategy Z which optimizes some metric of the path distribution on an influence diagram such as expected value or risk. The decision model is a mixed-integer linear programming formulation of this optimization problem. The model that is presented here, is based on [1], sections 3 and 5. We recommend reading it for motivation, details, and proofs of the formulation.","category":"page"},{"location":"decision-programming/decision-model/#Objective","page":"Decision Model","title":"Objective","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"The mixed-integer linear program optimizes the objective function f, that is a measure of the path distribution, over all decision strategies as follows","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"undersetZℤtextmaximizequad\nf((ℙ(𝐬Z) mathcalU(𝐬))  𝐬𝐒) tag1","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Common measures include expected value and risk metrics. The main consideration regarding the measures is that we can linearize them, and thus solve the model efficiently.","category":"page"},{"location":"decision-programming/decision-model/#Variables","page":"Decision Model","title":"Variables","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Decision variables z(s_j𝐬_I(j)) are equivalent to the decision strategies Z such that Z_j(𝐬_I(j))=s_j if and only if z(s_j𝐬_I(j))=1 and z(s_j^𝐬_I(j))=0 for all s_j^s_j Constraint (2) defines the decisions to be binary variables and the constraint (3) limits decisions to one per information path.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"z(s_j𝐬_I(j))  01quad jD s_jS_j 𝐬_I(j)𝐒_I(j) tag2","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_s_jS_j z(s_j𝐬_I(j))=1quad jD 𝐬_I(j)𝐒_I(j) tag3","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Path probability variables π(𝐬) are equivalent to the path probabilities ℙ(𝐬Z) where decision variables z define the decision strategy Z. The constraint (4) defines the lower and upper bound to the probability, constraint (5) defines that the probability equals zero if path is not compatible with the decision strategy, and constraint (6) defines that probability equals path probability if the path is compatible with the decision strategy.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"0π(𝐬)p(𝐬)quad 𝐬𝐒 tag4","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"π(𝐬)  z(𝐬_j𝐬_I(j))quad jD 𝐬𝐒 tag5","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"π(𝐬)  p(𝐬) + _jD z(𝐬_j𝐬_I(j)) - Dquad 𝐬𝐒 tag6","category":"page"},{"location":"decision-programming/decision-model/#Positive-Path-Utility","page":"Decision Model","title":"Positive Path Utility","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can omit the constraint (6) from the model if we use a positive path utility function mathcalU^+ which is an affine transformation of path utility function mathcalU As an example, we can subtract the minimum of the original utility function and then add one as follows.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"mathcalU^+(𝐬) = mathcalU(𝐬) - min_𝐬𝐒 mathcalU(𝐬) + 1","category":"page"},{"location":"decision-programming/decision-model/#Lazy-Constraints","page":"Decision Model","title":"Lazy Constraints","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Valid equalities are equalities that can be be derived from the problem structure. They can help in computing the optimal decision strategies, but adding them directly may slow down the overall solution process. By adding valid equalities during the solution process as lazy constraints, the MILP solver can prune nodes of the branch-and-bound tree more efficiently. We have the following valid equalities.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can exploit the fact that the path probabilities sum to one by using the probability sum cut defined as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_𝐬𝐒π(𝐬)=1 tag7","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"For problems where the number of active paths 𝐒^Z is known, we can exploit it by using the number of active paths cut defined as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_𝐬𝐒 fracπ(𝐬)p(𝐬)=𝐒^Z tag8","category":"page"},{"location":"decision-programming/decision-model/#Expected-Value","page":"Decision Model","title":"Expected Value","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We define the expected value as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameE(Z) = _𝐬𝐒 π(𝐬) mathcalU(𝐬) tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"However, the expected value objective does not account for risk caused by the variablity in the path distribution.","category":"page"},{"location":"decision-programming/decision-model/#Conditional-Value-at-Risk","page":"Decision Model","title":"Conditional Value-at-Risk","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Given a probability level α(0 1 and decision strategy Z we denote value-at-risk operatornameVaR_α(Z) and conditional value-at-risk operatornameCVaR_α(Z)","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Pre-computed parameters","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"u^+=maxmathcalU(𝐬)𝐬𝐒","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"u^-=minmathcalU(𝐬)𝐬𝐒","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"M=u^+-u^-","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"ϵ=frac12 minmathcalU(𝐬)-mathcalU(𝐬^)  mathcalU(𝐬)-mathcalU(𝐬^)  0 𝐬 𝐬^𝐒","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Objective","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"min η","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Constraints","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"η-mathcalU(𝐬)M λ(𝐬)quad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"η-mathcalU(𝐬)(M+ϵ) λ(𝐬) - Mquad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"η-mathcalU(𝐬)(M+ϵ) barλ(𝐬) - ϵquad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"η-mathcalU(𝐬)M (barλ(𝐬) - 1)quad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"barρ(𝐬)  barλ(𝐬)quad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"π(𝐬) - (1 - λ(𝐬))  ρ(𝐬)  λ(𝐬)quad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"ρ(𝐬)  barρ(𝐬)  π(𝐬)quad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_𝐬𝐒barρ(𝐬) = α tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"barλ(𝐬) λ(𝐬)0 1quad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"barρ(𝐬)ρ(𝐬)0 1quad 𝐬𝐒 tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"ηu^- u^+ tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Solution","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameVaR_α(Z)=η tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameCVaR_α(Z)=frac1α_𝐬𝐒barρ(𝐬) mathcalU(𝐬)tag","category":"page"},{"location":"decision-programming/decision-model/#Mixed-Objective","page":"Decision Model","title":"Mixed Objective","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can formulate","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"w operatornameE(Z) + (1-w) operatornameCVaR_α(Z) tag","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"where w(0 1) is the trade-off between maximization of","category":"page"},{"location":"decision-programming/decision-model/#References","page":"Decision Model","title":"References","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"decision-programming/influence-diagram/#Influence-Diagram","page":"Influence Diagram","title":"Influence Diagram","text":"","category":"section"},{"location":"decision-programming/influence-diagram/#Introduction","page":"Influence Diagram","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Based on [1], sections 3.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The paper [2] explains details about influence diagrams.","category":"page"},{"location":"decision-programming/influence-diagram/#Definition","page":"Influence Diagram","title":"Definition","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the influence diagram as a directed, acyclic graph","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"G=(CDVIS)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The nodes N=CDV consists of chance nodes C decision nodes D and value nodes V. We index the chance and decision nodes such that CD=1n and values nodes such that V=n+1n+V where n=C+D","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the information set I of node jN as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"I(j)iCDij","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The condition enforces that the graph is directed and acyclic, and there are no arcs from value nodes to other nodes. Practically, the information set is an edge list to reverse direction in the graph.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We refer to S as the state space. Each chance and decision node jCD is associates with a finite number of states S_j that we encode using integers 1S_j from one to number of states S_j","category":"page"},{"location":"decision-programming/influence-diagram/#Root-and-Leaf-Nodes","page":"Influence Diagram","title":"Root and Leaf Nodes","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"In the subdiagram of G which consists of the chance and decision nodes jCD we call node j a root node if its information set if empty, that is, I(j)=","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Similarly, we call node j a leaf node if it is not in any information set, that is, jI(i) for all iCD Each leaf node must be in at least one of the information sets of value nodes. That is, for each leaf node j exists a value node iV such that jI(i) Otherwise, the node j is redundant.","category":"page"},{"location":"decision-programming/influence-diagram/#Visualization","page":"Influence Diagram","title":"Visualization","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"To visualize influence diagrams, we define the different node types and how to order the nodes. There are two ways to order directed acyclic graphs, linear and depth-wise. We use diagrams.net for drawing influence diagrams.","category":"page"},{"location":"decision-programming/influence-diagram/#Node-Types","page":"Influence Diagram","title":"Node Types","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(Image: )","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We use a circle to represent chance nodes, square to represent decision nodes and diamond to represent value nodes. The symbol i represents the node's index and symbol S_i the states of the chance or decision node.","category":"page"},{"location":"decision-programming/influence-diagram/#Linear-Order","page":"Influence Diagram","title":"Linear Order","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(Image: )","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We can order the nodes in increasing linear order based on indices.","category":"page"},{"location":"decision-programming/influence-diagram/#Depth-wise-Order","page":"Influence Diagram","title":"Depth-wise Order","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(Image: )","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the depth of a node jN as follows. Root nodes have a depth of one","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"operatornamedepth(j)=1quad I(j)=","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Other nodes have a depth of one greater than the maximum depth of its predecessors","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"operatornamedepth(j)=max_iI(j) operatornamedepth(i) + 1quad I(j)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We can group the nodes by their depth and then order them by increasing depth and increasing indices order within that depth. Compared to linear order, the depth-wise order is more concise. It displays more information about the influence relationships, because nodes can only be influenced by nodes with smaller depth.","category":"page"},{"location":"decision-programming/influence-diagram/#Paths","page":"Influence Diagram","title":"Paths","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Paths in influence diagrams represent realizations of states for chance and decision nodes. Formally, a path is a sequence of states","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐬=(s_1 s_2 s_n)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"where each state s_iS_i for all chance and decision nodes iCD","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define a subpath of 𝐬 is a subsequence","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(𝐬_i_1 𝐬_i_2  𝐬_i_k)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"where 1i_1i_2i_kn and kn","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The information path of node jN on path 𝐬 is a subpath defined as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐬_I(j)=(𝐬_i  iI(j))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the set of all paths as a product set of all states","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐒=_jCD S_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The set of information paths of node jN is the product set of the states in its information set","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐒_I(j)=_iI(j) S_i","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We denote elements of the sets using notation s_jS_j, 𝐬𝐒, and 𝐬_I(j)𝐒_I(j)","category":"page"},{"location":"decision-programming/influence-diagram/#Probabilities","page":"Influence Diagram","title":"Probabilities","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"For each chance node jC, we denote the probability of state s_j given information path 𝐬_I(j) as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"ℙ(X_j=s_jX_I(j)=𝐬_I(j))=ℙ(s_j𝐬_I(j))0 1","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"with","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"_s_jS_j ℙ(s_j𝐬_I(j)) = 1","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Implementation wise, we can think probabilities as functions of information paths concatenated with state X_j  𝐒_I(j)S_j  0 1 where _s_jS_j X_j(𝐬_I(j)s_j)=1","category":"page"},{"location":"decision-programming/influence-diagram/#Decision-Strategy","page":"Influence Diagram","title":"Decision Strategy","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"For each decision node jD a local decision strategy maps an information path 𝐬_I(j) to a state s_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Z_j𝐒_I(j)S_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Decision strategy Z contains one local decision strategy for each decision node. Set of all decision strategies is denoted ℤ","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"A decision stategy Zℤ is compatible with the path 𝐬𝐒 if and only if Z_j(𝐬_I(j))=s_j forall Z_jZ and jD","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"An active path is path 𝐬𝐒 that is compatible with decision strategy Z We denote the set of all active paths using 𝐒^Z Since each decision strategy Z_j chooses only one state out of all of its states, the number of active paths is","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐒^Z=𝐒prod_jDS_j=prod_jCS_j","category":"page"},{"location":"decision-programming/influence-diagram/#Path-Probability","page":"Influence Diagram","title":"Path Probability","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the path probability (upper bound) as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"p(𝐬) = _jC ℙ(𝐬_j𝐬_I(j))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The path probability ℙ(𝐬Z) equals p(𝐬) if the path 𝐬 is compatible with the decision strategy Z. Otherwise, the path cannot occur, and the probability is zero.","category":"page"},{"location":"decision-programming/influence-diagram/#Consequences","page":"Influence Diagram","title":"Consequences","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"For each value node jV, we define the consequence given information path 𝐬_I(j) as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Y_j𝐒_I(j)ℂ","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"where ℂ is the set of real-valued consequences.","category":"page"},{"location":"decision-programming/influence-diagram/#Path-Utility","page":"Influence Diagram","title":"Path Utility","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The utility function is a function that maps consequences to real-valued utility","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Uℂ^Vℝ","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The path utility is defined as the utility function acting on the consequences of value nodes given their information paths","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"mathcalU(𝐬) = U(Y_j(𝐬_I(j))  jV)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The default path utility is the sum of consequences","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"mathcalU(𝐬) = _jV Y_j(𝐬_I(j))","category":"page"},{"location":"decision-programming/influence-diagram/#Path-Distribution","page":"Influence Diagram","title":"Path Distribution","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"A path distribution is a pair","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(ℙ(𝐬Z) mathcalU(𝐬))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"that comprises of path probability function and path utility function over paths 𝐬𝐒 conditional to the decision strategy Z","category":"page"},{"location":"decision-programming/influence-diagram/#Properties","page":"Influence Diagram","title":"Properties","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"In this section, we define common properties for influence diagrams. The paper [2] discusses many of these properties.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Discrete influence diagram refers to countable state space. Otherwise, the influence diagram is continuous. We can discretize continuous influence diagrams using discrete bins.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Two nodes are sequential if there exists a directed path from one node to the other in the influence diagram. Otherwise, the nodes are parallel. Sequential nodes often model time dimension.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Repeated subdiagram refers to a recurring pattern within an influence diagram. Often, influence diagrams do not have a unique structure, but they consist of a repeated pattern due to the underlying problem's properties.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Limited-memory influence diagram refers to an influence diagram where an upper bound limits the size of the information set for decision nodes. It is a desired attribute because it affects the decision model size, as discussed in the Computational Complexity section.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Isolated subdiagrams refer to an influence diagram that consists of multiple unconnected diagrams, that is, there are no undirected connections between the diagrams. Therefore, one isolated subdiagram's decisions affect decisions on the other isolated subdiagrams only through the utility function.","category":"page"},{"location":"decision-programming/influence-diagram/#References","page":"Influence Diagram","title":"References","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"[2]: Bielza, C., Gómez, M., & Shenoy, P. P. (2011). A review of representation issues and modeling challenges with influence diagrams. Omega, 39(3), 227–241. https://doi.org/10.1016/j.omega.2010.07.003","category":"page"},{"location":"examples/used-car-buyer/#Used-Car-Buyer","page":"Used Car Buyer","title":"Used Car Buyer","text":"","category":"section"},{"location":"examples/used-car-buyer/#Description","page":"Used Car Buyer","title":"Description","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"To illustrate the basic functionality of Decision Programming, we implement a version of the used car buyer problem in [1]. In this problem, Joe is buying a used car. The car's price is 1000 USD (US dollars), and its value is 1100 USD. Joe's base profit on the car is thus 100 USD. However, Joe knows that the car is a \"lemon\", meaning that it has defects in 6 major systems, with a 20% probability. With the remaining 80% probability, the car is a \"peach\", and it has a defect in only one of the systems.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The repair costs for a peach are only 40 USD, decreasing Joe's profit to 60  USD. However, the costs for a lemon are 200 USD, resulting in a total loss of 100 USD. We can now formulate an influence diagram of Joe's initial problem. We present the influence diagram in the figure below. In an influence diagram, circle nodes such as O are called chance nodes, representing uncertainty. Node O is a chance node representing the state of the car, lemon or peach. Square nodes such as A are decision nodes, representing decisions. Node A represents the decision to buy or not to buy the car. The diamond-shaped value node V denotes the utility calculation in the problem. For Joe, the utility function is the expected monetary value. The arrows or arcs show connections between nodes. The two arcs in this diagram point to the value node, meaning that the monetary value depends on the state of the car and the purchase decision.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"(Image: \\label{used-car-buyer-1})","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We can easily determine the optimal strategy for this problem. If Joe decides not to buy the car, his profit is zero. If he buys the car, with 20% probability he loses 100 USD and with an 80% probability he profits 60 USD. Therefore, the expected profit for buying the car is 28 USD, which is higher than the zero profit of not buying. Thus, Joe should buy the car.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We now add two new features to the problem. A stranger approaches Joe and offers to tell Joe whether the car is a lemon or a peach for 25 USD. Additionally, the car dealer offers a guarantee plan which costs 60 USD and covers 50% of the repair costs. Joe notes that this is not a very good deal, and the dealer includes an anti-lemon feature: if the total repair cost exceeds 100 USD, the quarantee will fully cover the repairs.","category":"page"},{"location":"examples/used-car-buyer/#Influence-diagram","page":"Used Car Buyer","title":"Influence diagram","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"(Image: \\label{used-car-buyer-2})","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We present the new influence diagram above. The decision node T denotes the decision to accept or decline the stranger's offer, and R is the outcome of the test. We introduce new value nodes V_1 and V_2 to represent the testing costs and the base profit from purchasing the car. Additionally, the decision node A now can choose to buy with a guarantee.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"using Printf, Random, Logging, Parameters, JuMP, Gurobi\nusing DecisionProgramming\n\nconst O = 1  # Chance node: lemon or peach\nconst T = 2  # Decision node: pay stranger for advice\nconst R = 3  # Chance node: observation of state of the car\nconst A = 4  # Decision node: purchase alternative\nconst O_states = [\"lemon\", \"peach\"]\nconst T_states = [\"no test\", \"test\"]\nconst R_states = [\"no test\", \"lemon\", \"peach\"]\nconst A_states = [\"buy without guarantee\", \"buy with guarantee\", \"don't buy\"]\n\nS = States([\n    (length(O_states), [O]),\n    (length(T_states), [T]),\n    (length(R_states), [R]),\n    (length(A_states), [A]),\n])\nC = Vector{ChanceNode}()\nD = Vector{DecisionNode}()\nV = Vector{ValueNode}()\nX = Vector{Probabilities}()\nY = Vector{Consequences}()","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We start by defining the influence diagram structure. The decision and chance nodes, as well as their states, are defined in the first block. Next, the influence diagram parameters consisting of the node sets and the state spaces of the nodes are defined.","category":"page"},{"location":"examples/used-car-buyer/#Car's-State","page":"Used Car Buyer","title":"Car's State","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_O = Vector{Node}()\nX_O = [0.2, 0.8]\npush!(C, ChanceNode(O, I_O))\npush!(X, Probabilities(X_O))","category":"page"},{"location":"examples/used-car-buyer/#Stranger's-Offer-Decision","page":"Used Car Buyer","title":"Stranger's Offer Decision","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_T = Vector{Node}()\npush!(D, DecisionNode(T, I_T))","category":"page"},{"location":"examples/used-car-buyer/#Test's-Outcome","page":"Used Car Buyer","title":"Test's Outcome","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_R = [O, T]\nX_R = zeros(S[O], S[T], S[R])\nX_R[1, 1, :] = [1,0,0]\nX_R[1, 2, :] = [0,1,0]\nX_R[2, 1, :] = [1,0,0]\nX_R[2, 2, :] = [0,0,1]\npush!(C, ChanceNode(R, I_R))\npush!(X, Probabilities(X_R))","category":"page"},{"location":"examples/used-car-buyer/#Purchace-Decision","page":"Used Car Buyer","title":"Purchace Decision","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_A = [R]\npush!(D, DecisionNode(A, I_A))","category":"page"},{"location":"examples/used-car-buyer/#Testing-Cost","page":"Used Car Buyer","title":"Testing Cost","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_V1 = [T]\nY_V1 = [0.0, -25.0]\npush!(V, ValueNode(5, I_V1))\npush!(Y, Consequences(Y_V1))","category":"page"},{"location":"examples/used-car-buyer/#Base-Profit-of-Purchase","page":"Used Car Buyer","title":"Base Profit of Purchase","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_V2 = [A]\nY_V2 = [100.0, 40.0, 0.0]\npush!(V, ValueNode(6, I_V2))\npush!(Y, Consequences(Y_V2))","category":"page"},{"location":"examples/used-car-buyer/#Repairing-Cost","page":"Used Car Buyer","title":"Repairing Cost","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_V3 = [O, A]\nY_V3 = [-200.0 0.0 0.0;\n        -40.0 -20.0 0.0]\npush!(V, ValueNode(7, I_V3))\npush!(Y, Consequences(Y_V3))","category":"page"},{"location":"examples/used-car-buyer/#Validating-Influence-Diagram","page":"Used Car Buyer","title":"Validating Influence Diagram","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Validate influence diagram and sort nodes, probabilities and consequences","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"validate_influence_diagram(S, C, D, V)\ns_c = sortperm([c.j for c in C])\ns_d = sortperm([d.j for d in D])\ns_v = sortperm([v.j for v in V])\nC = C[s_c]\nD = D[s_d]\nV = V[s_v]\nX = X[s_c]\nY = Y[s_v]","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We continue by defining the probabilities associated with chance nodes and utilities (consequences) associated with value nodes. The rows of the consequence matrix Y_V3 correspond to the state of the car, while the columns correspond to the decision made in node A.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"P = DefaultPathProbability(C, X)\nU = DefaultPathUtility(V, Y)","category":"page"},{"location":"examples/used-car-buyer/#Decision-Model","page":"Used Car Buyer","title":"Decision Model","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We then construct the decision model using the DecisionProgramming.jl package.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"model = DecisionModel(S, D, P)\nEV = expected_value(model, S, U)\n@objective(model, Max, EV)","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We can perform the optimization using an optimizer such as Gurobi.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"optimizer = optimizer_with_attributes(\n    Gurobi.Optimizer,\n    \"IntFeasTol\"      => 1e-9,\n    \"LazyConstraints\" => 1,\n)\nset_optimizer(model, optimizer)\noptimize!(model)","category":"page"},{"location":"examples/used-car-buyer/#Analyzing-Results","page":"Used Car Buyer","title":"Analyzing Results","text":"","category":"section"},{"location":"examples/used-car-buyer/#Decision-Strategy","page":"Used Car Buyer","title":"Decision Strategy","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Once the model is solved, we obtain the following decision strategy:","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Z = DecisionStrategy(model, D)","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"julia> print_decision_strategy(S, Z)\n┌────────┬────┬───┐\n│  Nodes │ () │ 2 │\n├────────┼────┼───┤\n│ States │ () │ 2 │\n└────────┴────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (3,) │ 4 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 3 │\n│ States │ (2,) │ 2 │\n│ States │ (3,) │ 1 │\n└────────┴──────┴───┘","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"To start explaining this output, let's take a look at the top table. On the right, we have the decision node 2. We defined earlier that the node T is node number 2. On the left, we have the information set of that decision node, which is empty. The strategy in the first decision node is to choose alternative 2, which we defined to be testing the car.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"In the bottom table, we have node number 4 (node A) and its predecessor, node number 3 (node R). The first row, where we obtain no test result, is invalid for this strategy since we tested the car. If the car is a lemon, Joe should buy the car with a guarantee (alternative 2), and if it is a peach, buy the car without guarantee (alternative 1).","category":"page"},{"location":"examples/used-car-buyer/#Utility-Distribution","page":"Used Car Buyer","title":"Utility Distribution","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"udist = UtilityDistribution(S, P, U, Z)","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"julia> print_utility_distribution(udist)\n┌───────────┬─────────────┐\n│   Utility │ Probability │\n│   Float64 │     Float64 │\n├───────────┼─────────────┤\n│ 15.000000 │    0.200000 │\n│ 35.000000 │    0.800000 │\n└───────────┴─────────────┘","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"From the utility distribution, we can see that Joe's profit with this strategy is 15 USD, with a 20% probability (the car is a lemon) and 35 USD with an 80% probability (the car is a peach).","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"julia> print_statistics(udist)\n┌──────────┬────────────┐\n│     Name │ Statistics │\n│   String │    Float64 │\n├──────────┼────────────┤\n│     Mean │  31.000000 │\n│      Std │   8.000000 │\n│ Skewness │  -1.500000 │\n│ Kurtosis │   0.250000 │\n└──────────┴────────────┘","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The expected profit is thus 31 USD.","category":"page"},{"location":"examples/used-car-buyer/#References","page":"Used Car Buyer","title":"References","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"[1]: Howard, R. A. (1977). The used car buyer. Reading in Decision Analysis, 2nd Ed. Stanford Research Institute, Menlo Park, CA.","category":"page"},{"location":"#DecisionProgramming.jl","page":"Home","title":"DecisionProgramming.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"DecisionProgramming.jl is a Julia package for solving multi-stage decision problems under uncertainty, modeled using influence diagrams, and leveraging the power of mixed-integer linear programming. Solving multi-stage decision problems under uncertainty consists of the following three steps.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the first step, we model the decision problem using an influence diagram with associated probabilities, consequences, and path utility function.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the second step, we create a decision model with an objective for the influence diagram. We solve the model to obtain an optimal decision strategy. We can create and solve multiple models with different objectives for the same influence diagram to receive various optimal decision strategies.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the third step, we analyze the resulting decision strategies for the influence diagram. In particular, we are interested in utility distribution and its associated statistics and risk measures.","category":"page"},{"location":"","page":"Home","title":"Home","text":"DecisionProgramming.jl provides the necessary functionality for expressing and solving decision problems but does not explain how to design influence diagrams. The rest of this documentation will describe the mathematical and programmatic details, touch on the computational challenges, and provide concrete examples of solving decision problems.","category":"page"},{"location":"","page":"Home","title":"Home","text":"DecisionProgramming.jl is developed in the Systems Analysis Laboratory at Aalto University by Ahti Salo,  Fabricio Oliveira, Juho Andelmin, Olli Herala, and Jaan Tollander de Balsch.","category":"page"}]
}
