var documenterSearchIndex = {"docs":
[{"location":"decision-programming/decision-model/#decision-model","page":"Decision Model","title":"Decision Model","text":"","category":"section"},{"location":"decision-programming/decision-model/#Introduction","page":"Decision Model","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Decision programming aims to find an optimal decision strategy Z from all decision strategies ℤ by maximizing an objective function f on the path distribution of an influence diagram","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"undersetZℤtextmaximizequad f((ℙ(𝐬Z) mathcalU(𝐬))  𝐬𝐒) tag1","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Decision model refers to the mixed-integer linear programming formulation of this optimization problem. This page explains how to express decision strategy, path probability, path utility, and the objective in the mixed-integer linear form. We also present standard objective functions, including expected value and risk measures.  We based the decision model on [1], sections 3 and 5. We recommend reading the references for motivation, details, and proofs of the formulation.","category":"page"},{"location":"decision-programming/decision-model/#Decision-Variables","page":"Decision Model","title":"Decision Variables","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Decision variables z(s_j𝐬_I(j)) are equivalent to the decision strategies Z such that Z_j(𝐬_I(j))=s_j if and only if z(s_j𝐬_I(j))=1 and z(s_j^𝐬_I(j))=0 for all s_j^S_js_j Constraint (2) defines the decisions to be binary variables and the constraint (3) limits decisions to one per information path.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"z(s_j𝐬_I(j))  01quad jD s_jS_j 𝐬_I(j)𝐒_I(j) tag2","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_s_jS_j z(s_j𝐬_I(j))=1quad jD 𝐬_I(j)𝐒_I(j) tag3","category":"page"},{"location":"decision-programming/decision-model/#Path-Probability-Variables","page":"Decision Model","title":"Path Probability Variables","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Path probability variables π(𝐬) are equivalent to the path probabilities ℙ(𝐬Z) where decision variables z define the decision strategy Z. The constraint (4) defines the lower and upper bound to the probability, constraint (5) defines that the probability equals zero if path is not compatible with the decision strategy, and constraint (6) defines that probability equals path probability if the path is compatible with the decision strategy.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"0π(𝐬)p(𝐬)quad 𝐬𝐒 tag4","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"π(𝐬)  z(𝐬_j𝐬_I(j))quad jD 𝐬𝐒 tag5","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"π(𝐬)  p(𝐬) + _jD z(𝐬_j𝐬_I(j)) - Dquad 𝐬𝐒 tag6","category":"page"},{"location":"decision-programming/decision-model/#Positive-Path-Utility","page":"Decision Model","title":"Positive Path Utility","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can omit the constraint (6) from the model if we use a positive path utility function mathcalU^+ which is an affine transformation of path utility function mathcalU As an example, we can subtract the minimum of the original utility function and then add one as follows.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"mathcalU^+(𝐬) = mathcalU(𝐬) - min_𝐬𝐒 mathcalU(𝐬) + 1 tag7","category":"page"},{"location":"decision-programming/decision-model/#Lazy-Constraints","page":"Decision Model","title":"Lazy Constraints","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Valid equalities are equalities that can be be derived from the problem structure. They can help in computing the optimal decision strategies, but adding them directly may slow down the overall solution process. By adding valid equalities during the solution process as lazy constraints, the MILP solver can prune nodes of the branch-and-bound tree more efficiently. We have the following valid equalities.","category":"page"},{"location":"decision-programming/decision-model/#Probability-Cut","page":"Decision Model","title":"Probability Cut","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can exploit the fact that the path probabilities sum to one by using the probability cut defined as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_𝐬𝐒π(𝐬)=1 tag8","category":"page"},{"location":"decision-programming/decision-model/#Active-Paths-Cut","page":"Decision Model","title":"Active Paths Cut","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"For problems where the number of active paths is constant, we can exploit it by using the active paths cut defined as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_𝐬𝐒 fracπ(𝐬)p(𝐬)=𝐒^+(Z) tag9","category":"page"},{"location":"decision-programming/decision-model/#Expected-Value","page":"Decision Model","title":"Expected Value","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We define the expected value objective as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameE(Z) = _𝐬𝐒 π(𝐬) mathcalU(𝐬) tag10","category":"page"},{"location":"decision-programming/decision-model/#Conditional-Value-at-Risk","page":"Decision Model","title":"Conditional Value-at-Risk","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"The section Measuring Risk explains and visualizes the relationships between the formulation of expected value, value-at-risk and conditional value-at-risk for discrete probability distribution.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Given decision strategy Z we define the cumulative distribution of path probability variables as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"F_Z(t) = _𝐬𝐒mathcalU(𝐬)t π(𝐬)","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Given a probability level α(0 1 we define the value-at-risk as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameVaR_α(Z)=u_α=sup mathcalU(𝐬)𝐬𝐒 F_Z(mathcalU(𝐬))α","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Then, we have the paths that have path utility less than and equal to the value-at-risk as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"𝐒_α^=𝐬𝐒mathcalU(𝐬)u_α","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"𝐒_α^==𝐬𝐒mathcalU(𝐬)=u_α","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We define conditional value-at-risk as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameCVaR_α(Z)=frac1αleft(_𝐬𝐒_α^ π(𝐬) mathcalU(𝐬) + _𝐬𝐒_α^= left(α - _𝐬𝐒_α^ π(𝐬) right) mathcalU(𝐬) right)","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can form the conditional value-at-risk as an optimization problem. We have the following pre-computed parameters.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Lower and upper bound of the value-at-risk","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameVaR_0(Z)=u^-=minmathcalU(𝐬)𝐬𝐒 tag11","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameVaR_1(Z)=u^+=maxmathcalU(𝐬)𝐬𝐒 tag12","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Largest difference between path utilities","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"M=u^+-u^- tag13","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Half of the smallest positive difference between path utilities","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"ϵ=frac12 minmathcalU(𝐬)-mathcalU(𝐬^)  mathcalU(𝐬)-mathcalU(𝐬^)  0 𝐬 𝐬^𝐒 tag14","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"The objective is to minimize the variable η whose optimal value is equal to the value-at-risk, that is, operatornameVaR_α(Z)=min η","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We define the constraints as follows:","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"η-mathcalU(𝐬)M λ(𝐬)quad 𝐬𝐒 tag14","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"η-mathcalU(𝐬)(M+ϵ) λ(𝐬) - Mquad 𝐬𝐒 tag15","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"η-mathcalU(𝐬)(M+ϵ) barλ(𝐬) - ϵquad 𝐬𝐒 tag16","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"η-mathcalU(𝐬)M (barλ(𝐬) - 1)quad 𝐬𝐒 tag17","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"barρ(𝐬)  barλ(𝐬)quad 𝐬𝐒 tag18","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"π(𝐬) - (1 - λ(𝐬))  ρ(𝐬)  λ(𝐬)quad 𝐬𝐒 tag19","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"ρ(𝐬)  barρ(𝐬)  π(𝐬)quad 𝐬𝐒 tag20","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_𝐬𝐒barρ(𝐬) = α tag21","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"barλ(𝐬) λ(𝐬)0 1quad 𝐬𝐒 tag22","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"barρ(𝐬)ρ(𝐬)0 1quad 𝐬𝐒 tag23","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"ηu^- u^+ tag24","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can express the conditional value-at-risk objective as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameCVaR_α(Z)=frac1α_𝐬𝐒barρ(𝐬) mathcalU(𝐬)tag25","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"The values of conditional value-at-risk are limited to the interval between the lower bound of value-at-risk and the expected value","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameVaR_0(Z)operatornameCVaR_α(Z)E(Z)","category":"page"},{"location":"decision-programming/decision-model/#Mixed-Objective","page":"Decision Model","title":"Mixed Objective","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can combine expected value and conditional value-at-risk using a convex combination at a fixed probability level α(0 1 as follows","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"w operatornameE(Z) + (1-w) operatornameCVaR_α(Z) tag26","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"where the parameter w0 1 expresses the decision maker's risk tolerance.","category":"page"},{"location":"decision-programming/decision-model/#References","page":"Decision Model","title":"References","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#analyzing-decision-strategies","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/#Introduction","page":"Analyzing Decision Strategies","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"This section focuses on how we can analyze fixed decision strategies Z on an influence diagram G, such as ones resulting from the optimization. We can rule out all incompatible paths from the analysis because their path probability is zero, by only generating the compatible paths 𝐬𝐒(Z) However, compatible paths may still contain inactive paths if the influence diagram contains inactive chance states. The other property of compatible paths is that their path probability is equal to the upper bound p(𝐬)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#Generating-Compatible-Paths","page":"Analyzing Decision Strategies","title":"Generating Compatible Paths","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We can generate compatible paths 𝐬𝐒(Z) as follows.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"Initialize path 𝐬 of length n with undefined values.\nFill path with chance states 𝐬_jS_j for all jC\nIn increasing order of decision nodes jD, fill decision states by computing decision strategy 𝐬_j=Z_j(𝐬_I(j))","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#Utility-Distribution","page":"Analyzing Decision Strategies","title":"Utility Distribution","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We define unique path utility values as","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"mathcalU^=mathcalU(𝐬)𝐬𝐒(Z)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The probability mass function of the utility distribution associates each unique path utility to a probability as follows","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(X=u)=_𝐬𝐒(Z)mathcalU(𝐬)=u p(𝐬)quad umathcalU^","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"From the utility distribution, we can calculate the cumulative distribution, statistics, and risk measures. The relevant statistics are expected value, standard deviation, skewness and kurtosis. Risk measures focus on the conditional value-at-risk (CVaR), also known as, expected shortfall.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#Measuring-Risk","page":"Analyzing Decision Strategies","title":"Measuring Risk","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"(Image: )","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We have a discrete probability distribution f(x)=ℙ(X=x)0 1 over the domain xΩ with _xΩℙ(X=x)=1 and its cumulative distribution function F(x) = _x^Ωx^xf(x^) We define the expected value as","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"E(X)=_xΩ x  f(x)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We present the concept of conditional value-at-risk, a risk measure of the conditional expected value of the tail of a probability distribution for a given probability level of α0 1 First, we define the value-at-risk as","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"operatornameVaR_α(X) = x_α = minxΩ  F(x)  α","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"It is the smallest value x such that the cumulative probability is equal or above α Then, we define the conditional value-at-risk as","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"operatornameCVaR_α(X)=textcolordarkorangefrac1α left(textcolordarkred_xx_α x  f(x) textcolordarkblue- left(_xx_α f(x) - αright) x_α right)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The red part measures the conditional expected value of the tail distribution. The blue part corrects the expected value by subtracting the amount of expected value that is between probability level α and F(x_α) and orange part divides by the total probability.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"Value-at-risk and conditional value-at-risk are monotonically increasing functions. Therefore, the lower bound is the value at α=0 and the upper bound is the value at α=1 For value-at-risk, we have","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"operatornameVaR_0(X) = min xΩ","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"operatornameVaR_1(X) = max xΩ","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"For conditional value-at-risk, we have","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"lim_α0 operatornameCVaR_α(X) = operatornameVaR_0(X)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"operatornameCVaR_1(X) = E(X)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The above figure demonstrates these values on a discrete probability distribution.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#State-Probabilities","page":"Analyzing Decision Strategies","title":"State Probabilities","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We denote paths with fixed states where ϵ denotes an empty state using a recursive definition.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"beginaligned\n𝐒_ϵ = 𝐒(Z) \n𝐒_ϵs_i = 𝐬𝐒_ϵ  𝐬_i=s_i \n𝐒_ϵs_is_j = 𝐬𝐒_ϵs_i  𝐬_j=s_jquad ji\nendaligned","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The probability of all paths sums to one","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(ϵ) = sum_𝐬𝐒_ϵ p(𝐬) = 1","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"State probabilities for each node iCD and state s_iS_i denote how likely the state occurs given all path probabilities","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(s_iϵ) = sum_𝐬𝐒_ϵs_i fracp(𝐬)ℙ(ϵ) = sum_𝐬𝐒_ϵs_i p(𝐬)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"An active state is a state with positive state probability ℙ(s_ic)0 given conditions c","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We can generalize the state probabilities as conditional probabilities using a recursive definition. Generalized state probabilities allow us to explore how fixing active states affect the probabilities of other states. First, we choose an active state s_i and fix its value. Fixing an inactive state would make all state probabilities zero. Then, we can compute the conditional state probabilities as follows.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(s_jϵs_i) = sum_𝐬𝐒_ϵs_is_j fracp(𝐬)ℙ(s_iϵ)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We can then repeat this process by choosing an active state from the new conditional state probabilities s_k that is different from previously chosen states kj","category":"page"},{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"DecisionProgramming.jl API reference.","category":"page"},{"location":"api/#influence_diagram.jl","page":"API Reference","title":"influence_diagram.jl","text":"","category":"section"},{"location":"api/#Nodes","page":"API Reference","title":"Nodes","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Node\nChanceNode\nDecisionNode\nValueNode\nState\nStates\nStates(::Vector{Tuple{State, Vector{Node}}})\nvalidate_influence_diagram","category":"page"},{"location":"api/#DecisionProgramming.Node","page":"API Reference","title":"DecisionProgramming.Node","text":"Node type. Alias for Int.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.ChanceNode","page":"API Reference","title":"DecisionProgramming.ChanceNode","text":"Chance node type.\n\nExamples\n\nc = ChanceNode(3, [1, 2])\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DecisionNode","page":"API Reference","title":"DecisionProgramming.DecisionNode","text":"Decision node type.\n\nExamples\n\nd = DecisionNode(2, [1])\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.ValueNode","page":"API Reference","title":"DecisionProgramming.ValueNode","text":"Value node type.\n\nExamples\n\nv = ValueNode(4, [1, 3])\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.State","page":"API Reference","title":"DecisionProgramming.State","text":"State type. Alias for Int.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.States","page":"API Reference","title":"DecisionProgramming.States","text":"States type. Works like Vector{State}.\n\nExamples\n\nS = States([2, 3, 2, 4])\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.States-Tuple{Array{Tuple{Int64,Array{Int64,1}},1}}","page":"API Reference","title":"DecisionProgramming.States","text":"Construct states from vector of (state, nodes) tuples.\n\nExamples\n\njulia> S = States([(2, [1, 3]), (3, [2, 4, 5])])\nStates([2, 3, 2, 3, 3])\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.validate_influence_diagram","page":"API Reference","title":"DecisionProgramming.validate_influence_diagram","text":"Validate influence diagram.\n\n\n\n\n\n","category":"function"},{"location":"api/#Paths","page":"API Reference","title":"Paths","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Path\npaths","category":"page"},{"location":"api/#DecisionProgramming.Path","page":"API Reference","title":"DecisionProgramming.Path","text":"Path type. Alias for NTuple{N, State} where N.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.paths","page":"API Reference","title":"DecisionProgramming.paths","text":"Iterate over paths in lexicographical order.\n\nExamples\n\njulia> states = States([2, 3])\njulia> vec(collect(paths(states)))\n[(1, 1), (2, 1), (1, 2), (2, 2), (1, 3), (2, 3)]\n\n\n\n\n\nIterate over paths with fixed states in lexicographical order.\n\nExamples\n\njulia> states = States([2, 3])\njulia> vec(collect(paths(states, Dict(1=>2))))\n[(2, 1), (2, 2), (2, 3)]\n\n\n\n\n\n","category":"function"},{"location":"api/#Probabilities","page":"API Reference","title":"Probabilities","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Probabilities","category":"page"},{"location":"api/#DecisionProgramming.Probabilities","page":"API Reference","title":"DecisionProgramming.Probabilities","text":"Construct and validate stage probabilities.\n\nExamples\n\njulia> data = [0.5 0.5 ; 0.2 0.8]\njulia> X = Probabilities(2, data)\njulia> s = (1, 2)\njulia> X(s)\n0.5\n\n\n\n\n\n","category":"type"},{"location":"api/#Path-Probability","page":"API Reference","title":"Path Probability","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"AbstractPathProbability\nDefaultPathProbability","category":"page"},{"location":"api/#DecisionProgramming.AbstractPathProbability","page":"API Reference","title":"DecisionProgramming.AbstractPathProbability","text":"Abstract path probability type.\n\nExamples\n\nstruct PathProbability <: AbstractPathProbability\n    C::Vector{ChanceNode}\n    # ...\nend\n\n(U::PathProbability)(s::Path) = ...\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DefaultPathProbability","page":"API Reference","title":"DecisionProgramming.DefaultPathProbability","text":"Path probability.\n\nExamples\n\nP = DefaultPathProbability(C, X)\ns = (1, 2)\nP(s)\n\n\n\n\n\n","category":"type"},{"location":"api/#Consequences","page":"API Reference","title":"Consequences","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Consequences","category":"page"},{"location":"api/#DecisionProgramming.Consequences","page":"API Reference","title":"DecisionProgramming.Consequences","text":"State utilities.\n\nExamples\n\njulia> vals = [1.0 -2.0; 3.0 4.0]\njulia> Y = Consequences(3, vals)\njulia> s = (1, 2)\njulia> Y(s)\n-2.0\n\n\n\n\n\n","category":"type"},{"location":"api/#Path-Utility","page":"API Reference","title":"Path Utility","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"AbstractPathUtility\nDefaultPathUtility","category":"page"},{"location":"api/#DecisionProgramming.AbstractPathUtility","page":"API Reference","title":"DecisionProgramming.AbstractPathUtility","text":"Abstract path utility type.\n\nExamples\n\nstruct PathUtility <: AbstractPathUtility\n    V::Vector{ValueNode}\n    # ...\nend\n\n(U::PathUtility)(s::Path) = ...\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DefaultPathUtility","page":"API Reference","title":"DecisionProgramming.DefaultPathUtility","text":"Default path utility.\n\nExamples\n\nU = DefaultPathUtility(V, Y)\ns = (1, 2)\nU(s)\n\n\n\n\n\n","category":"type"},{"location":"api/#Decision-Strategy","page":"API Reference","title":"Decision Strategy","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"LocalDecisionStrategy\nDecisionStrategy","category":"page"},{"location":"api/#DecisionProgramming.LocalDecisionStrategy","page":"API Reference","title":"DecisionProgramming.LocalDecisionStrategy","text":"Local decision strategy type.\n\nExamples\n\nZ = LocalDecisionStrategy(1, data)\nZ(s_I)\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DecisionStrategy","page":"API Reference","title":"DecisionProgramming.DecisionStrategy","text":"Decision strategy type.\n\n\n\n\n\n","category":"type"},{"location":"api/#decision_model.jl","page":"API Reference","title":"decision_model.jl","text":"","category":"section"},{"location":"api/#Decision-Model","page":"API Reference","title":"Decision Model","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"PositivePathUtility\nPositivePathUtility(::Path)\nvariables\ndecision_variables\npath_probability_variables\nprobability_cut(::Model, ::Array{VariableRef}, ::States, ::AbstractPathProbability)\nactive_paths_cut(::Model, ::Array{VariableRef}, ::States, ::AbstractPathProbability; ::Float64)","category":"page"},{"location":"api/#DecisionProgramming.PositivePathUtility","page":"API Reference","title":"DecisionProgramming.PositivePathUtility","text":"Positive affine transformation of path utility.\n\nExamples\n\nU⁺ = PositivePathUtility(S, U)\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.PositivePathUtility-Tuple{Tuple{Vararg{Int64,N}} where N}","page":"API Reference","title":"DecisionProgramming.PositivePathUtility","text":"Evaluate positive affine transformation of the path utility.\n\nExamples\n\njulia> all(U⁺(s) ≥ 1 for s in paths(S))\ntrue\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.variables","page":"API Reference","title":"DecisionProgramming.variables","text":"Create a multidimensional array of JuMP variables.\n\nExamples\n\nmodel = Model()\nv1 = variables(model, [2, 3, 2])\nv2 = variables(model, [2, 3, 2]; binary=true)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.decision_variables","page":"API Reference","title":"DecisionProgramming.decision_variables","text":"Create decision variables and constraints.\n\nExamples\n\nz = decision_variables(model, S, D)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.path_probability_variables","page":"API Reference","title":"DecisionProgramming.path_probability_variables","text":"Create path probability variables and constraints.\n\nExamples\n\nπ_s = path_probability_variables(model, z, S, D, P)\nπ_s = path_probability_variables(model, z, S, D, P; hard_lower_bound=false))\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.probability_cut-Tuple{Model,Array{VariableRef,N} where N,States,AbstractPathProbability}","page":"API Reference","title":"DecisionProgramming.probability_cut","text":"Adds a probability cut to the model as a lazy constraint.\n\nExamples\n\nprobability_cut(model, π_s, S, P)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.active_paths_cut-Tuple{Model,Array{VariableRef,N} where N,States,AbstractPathProbability}","page":"API Reference","title":"DecisionProgramming.active_paths_cut","text":"Adds a active paths cut to the model as a lazy constraint.\n\nExamples\n\natol = 0.9  # Tolerance to trigger the creation of the lazy cut\nactive_paths_cut(model, π_s, S, P; atol=atol)\n\n\n\n\n\n","category":"method"},{"location":"api/#Objective-Functions","page":"API Reference","title":"Objective Functions","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"expected_value(::Model, ::Array{VariableRef}, ::States, ::AbstractPathUtility)\nconditional_value_at_risk(::Model, ::Array{VariableRef}, ::States, ::AbstractPathUtility, ::Float64)","category":"page"},{"location":"api/#DecisionProgramming.expected_value-Tuple{Model,Array{VariableRef,N} where N,States,AbstractPathUtility}","page":"API Reference","title":"DecisionProgramming.expected_value","text":"Create an expected value objective.\n\nExamples\n\nEV = expected_value(model, π_s, S, U)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.conditional_value_at_risk-Tuple{Model,Array{VariableRef,N} where N,States,AbstractPathUtility,Float64}","page":"API Reference","title":"DecisionProgramming.conditional_value_at_risk","text":"Create a conditional value-at-risk (CVaR) objective.\n\nExamples\n\nα = 0.05  # Parameter such that 0 ≤ α ≤ 1\nCVaR = conditional_value_at_risk(model, π_s, S, U, α)\n\n\n\n\n\n","category":"method"},{"location":"api/#Decision-Strategy-from-Variables","page":"API Reference","title":"Decision Strategy from Variables","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"LocalDecisionStrategy(::Node, ::Vector{VariableRef})\nDecisionStrategy(::Vector{<:Array{VariableRef}}, ::Vector{DecisionNode})","category":"page"},{"location":"api/#DecisionProgramming.LocalDecisionStrategy-Tuple{Int64,Array{VariableRef,1}}","page":"API Reference","title":"DecisionProgramming.LocalDecisionStrategy","text":"Construct decision strategy from variable refs.\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.DecisionStrategy-Tuple{Array{#s3,1} where #s3<:(Array{VariableRef,N} where N),Array{DecisionNode,1}}","page":"API Reference","title":"DecisionProgramming.DecisionStrategy","text":"Extract values for decision variables from solved decision model.\n\nExamples\n\nZ = DecisionStrategy(z, D)\n\n\n\n\n\n","category":"method"},{"location":"api/#analysis.jl","page":"API Reference","title":"analysis.jl","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"CompatiblePaths\nUtilityDistribution\nUtilityDistribution(::States, ::AbstractPathProbability, ::AbstractPathUtility, ::DecisionStrategy)\nStateProbabilities\nStateProbabilities(::States, ::AbstractPathProbability, ::DecisionStrategy)\nStateProbabilities(::States, ::AbstractPathProbability, ::DecisionStrategy, ::Node, ::State, ::StateProbabilities)\nvalue_at_risk(::Vector{Float64}, ::Vector{Float64}, ::Float64)\nconditional_value_at_risk(::Vector{Float64}, ::Vector{Float64}, ::Float64)","category":"page"},{"location":"api/#DecisionProgramming.CompatiblePaths","page":"API Reference","title":"DecisionProgramming.CompatiblePaths","text":"Interface for iterating over active paths given influence diagram and decision strategy.\n\nInitialize path s of length n\nFill chance states s[C] by generating subpaths paths(C)\nFill decision states s[D] by decision strategy Z and path s\n\nExamples\n\nfor s in CompatiblePaths(S, C, Z)\n    ...\nend\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.UtilityDistribution","page":"API Reference","title":"DecisionProgramming.UtilityDistribution","text":"UtilityDistribution type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.UtilityDistribution-Tuple{States,AbstractPathProbability,AbstractPathUtility,DecisionStrategy}","page":"API Reference","title":"DecisionProgramming.UtilityDistribution","text":"Constructs the probability mass function for path utilities on active paths.\n\nExamples\n\nUtilityDistribution(S, P, U, Z)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.StateProbabilities","page":"API Reference","title":"DecisionProgramming.StateProbabilities","text":"StateProbabilities type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.StateProbabilities-Tuple{States,AbstractPathProbability,DecisionStrategy}","page":"API Reference","title":"DecisionProgramming.StateProbabilities","text":"Associates each node with array of probabilities for each of its states occuring in active paths.\n\nExamples\n\nStateProbabilities(S, P, Z)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.StateProbabilities-Tuple{States,AbstractPathProbability,DecisionStrategy,Int64,Int64,StateProbabilities}","page":"API Reference","title":"DecisionProgramming.StateProbabilities","text":"Associates each node with array of conditional probabilities for each of its states occuring in active paths given fixed states and prior probability.\n\nExamples\n\n# Prior probabilities\nprev = StateProbabilities(S, P, Z)\n\n# Select node and fix its state\nnode = 1\nstate = 2\nStateProbabilities(S, P, Z, node, state, prev)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.value_at_risk-Tuple{Array{Float64,1},Array{Float64,1},Float64}","page":"API Reference","title":"DecisionProgramming.value_at_risk","text":"Value-at-risk.\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.conditional_value_at_risk-Tuple{Array{Float64,1},Array{Float64,1},Float64}","page":"API Reference","title":"DecisionProgramming.conditional_value_at_risk","text":"Conditional value-at-risk.\n\n\n\n\n\n","category":"method"},{"location":"api/#printing.jl","page":"API Reference","title":"printing.jl","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"print_decision_strategy\nprint_utility_distribution\nprint_state_probabilities\nprint_statistics\nprint_risk_measures","category":"page"},{"location":"api/#DecisionProgramming.print_decision_strategy","page":"API Reference","title":"DecisionProgramming.print_decision_strategy","text":"Print decision strategy.\n\nExamples\n\nprint_decision_strategy(S, Z)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_utility_distribution","page":"API Reference","title":"DecisionProgramming.print_utility_distribution","text":"Print utility distribution\n\nExamples\n\nudist = UtilityDistribution(S, P, U, Z)\nprint_utility_distribution(udist)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_state_probabilities","page":"API Reference","title":"DecisionProgramming.print_state_probabilities","text":"Print state probabilities with fixed states.\n\nExamples\n\nsprobs = StateProbabilities(S, P, U, Z)\nprint_state_probabilities(sprobs, [c.j for c in C])\nprint_state_probabilities(sprobs, [d.j for d in D])\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_statistics","page":"API Reference","title":"DecisionProgramming.print_statistics","text":"Print statistics.\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_risk_measures","page":"API Reference","title":"DecisionProgramming.print_risk_measures","text":"Print risk measures.\n\n\n\n\n\n","category":"function"},{"location":"api/#random.jl","page":"API Reference","title":"random.jl","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"random_diagram(::AbstractRNG, ::Int, ::Int, ::Int, ::Int, ::Int)\nStates(::AbstractRNG, ::Vector{State}, ::Int)\nProbabilities(::AbstractRNG, ::ChanceNode, ::States)\nConsequences(::AbstractRNG, ::ValueNode, ::States; ::Float64, ::Float64)\nLocalDecisionStrategy(::AbstractRNG, ::DecisionNode, ::States)","category":"page"},{"location":"api/#DecisionProgramming.random_diagram-Tuple{AbstractRNG,Int64,Int64,Int64,Int64,Int64}","page":"API Reference","title":"DecisionProgramming.random_diagram","text":"Generate random decision diagram with n_C chance nodes, n_D decision nodes, and n_V value nodes. Parameter m_C and m_D are the upper bounds for the size of the information set.\n\nExamples\n\nrng = MersenneTwister(3)\nrandom_diagram(rng, 5, 2, 3, 2)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.States-Tuple{AbstractRNG,Array{Int64,1},Int64}","page":"API Reference","title":"DecisionProgramming.States","text":"Generate n random states from states.\n\nExamples\n\nrng = MersenneTwister(3)\nS = States(rng, [2, 3], 10)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.Probabilities-Tuple{AbstractRNG,ChanceNode,States}","page":"API Reference","title":"DecisionProgramming.Probabilities","text":"Generate random probabilities for chance node c with S states.\n\nExamples\n\nrng = MersenneTwister(3)\nc = ChanceNode(2, [1])\nS = States([2, 2])\nProbabilities(rng, c, S)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.Consequences-Tuple{AbstractRNG,ValueNode,States}","page":"API Reference","title":"DecisionProgramming.Consequences","text":"Generate random consequences between low and high for value node v with S states.\n\nExamples\n\nrng = MersenneTwister(3)\nv = ValueNode(3, [1])\nS = States([2, 2])\nConsequences(rng, v, S; low=-1.0, high=1.0)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.LocalDecisionStrategy-Tuple{AbstractRNG,DecisionNode,States}","page":"API Reference","title":"DecisionProgramming.LocalDecisionStrategy","text":"Generate random decision strategy for decision node d with S states.\n\nExamples\n\nrng = MersenneTwister(3)\nd = DecisionNode(2, [1])\nS = States([2, 2])\nDecisionStrategy(rng, d, S)\n\n\n\n\n\n","category":"method"},{"location":"examples/used-car-buyer/#Used-Car-Buyer","page":"Used Car Buyer","title":"Used Car Buyer","text":"","category":"section"},{"location":"examples/used-car-buyer/#Description","page":"Used Car Buyer","title":"Description","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"To illustrate the basic functionality of Decision Programming, we implement a version of the used car buyer problem in [1]. In this problem, Joe is buying a used car. The car's price is 1000 USD (US dollars), and its value is 1100 USD. Joe's base profit on the car is thus 100 USD. However, Joe knows that the car is a \"lemon\", meaning that it has defects in 6 major systems, with a 20% probability. With the remaining 80% probability, the car is a \"peach\", and it has a defect in only one of the systems.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The repair costs for a peach are only 40 USD, decreasing Joe's profit to 60  USD. However, the costs for a lemon are 200 USD, resulting in a total loss of 100 USD. We can now formulate an influence diagram of Joe's initial problem. We present the influence diagram in the figure below. In an influence diagram, circle nodes such as O are called chance nodes, representing uncertainty. Node O is a chance node representing the state of the car, lemon or peach. Square nodes such as A are decision nodes, representing decisions. Node A represents the decision to buy or not to buy the car. The diamond-shaped value node V denotes the utility calculation in the problem. For Joe, the utility function is the expected monetary value. The arrows or arcs show connections between nodes. The two arcs in this diagram point to the value node, meaning that the monetary value depends on the state of the car and the purchase decision.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"(Image: \\label{used-car-buyer-1})","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We can easily determine the optimal strategy for this problem. If Joe decides not to buy the car, his profit is zero. If he buys the car, with 20% probability he loses 100 USD and with an 80% probability he profits 60 USD. Therefore, the expected profit for buying the car is 28 USD, which is higher than the zero profit of not buying. Thus, Joe should buy the car.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We now add two new features to the problem. A stranger approaches Joe and offers to tell Joe whether the car is a lemon or a peach for 25 USD. Additionally, the car dealer offers a guarantee plan which costs 60 USD and covers 50% of the repair costs. Joe notes that this is not a very good deal, and the dealer includes an anti-lemon feature: if the total repair cost exceeds 100 USD, the quarantee will fully cover the repairs.","category":"page"},{"location":"examples/used-car-buyer/#Influence-diagram","page":"Used Car Buyer","title":"Influence diagram","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"(Image: \\label{used-car-buyer-2})","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We present the new influence diagram above. The decision node T denotes the decision to accept or decline the stranger's offer, and R is the outcome of the test. We introduce new value nodes V_1 and V_2 to represent the testing costs and the base profit from purchasing the car. Additionally, the decision node A now can choose to buy with a guarantee.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"using JuMP, Gurobi\nusing DecisionProgramming\n\nconst O = 1  # Chance node: lemon or peach\nconst T = 2  # Decision node: pay stranger for advice\nconst R = 3  # Chance node: observation of state of the car\nconst A = 4  # Decision node: purchase alternative\nconst O_states = [\"lemon\", \"peach\"]\nconst T_states = [\"no test\", \"test\"]\nconst R_states = [\"no test\", \"lemon\", \"peach\"]\nconst A_states = [\"buy without guarantee\", \"buy with guarantee\", \"don't buy\"]\n\nS = States([\n    (length(O_states), [O]),\n    (length(T_states), [T]),\n    (length(R_states), [R]),\n    (length(A_states), [A]),\n])\nC = Vector{ChanceNode}()\nD = Vector{DecisionNode}()\nV = Vector{ValueNode}()\nX = Vector{Probabilities}()\nY = Vector{Consequences}()","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We start by defining the influence diagram structure. The decision and chance nodes, as well as their states, are defined in the first block. Next, the influence diagram parameters consisting of the node sets, probabilities, consequences and the state spaces of the nodes are defined.","category":"page"},{"location":"examples/used-car-buyer/#Car's-State","page":"Used Car Buyer","title":"Car's State","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The chance node O is defined by its information set I(O) and probability distribution X_O. As seen in the influence diagram, the information set is empty and the node is a root node. The probability distribution is thus simply defined over the two states of O.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_O = Vector{Node}()\nX_O = [0.2, 0.8]\npush!(C, ChanceNode(O, I_O))\npush!(X, Probabilities(O, X_O))","category":"page"},{"location":"examples/used-car-buyer/#Stranger's-Offer-Decision","page":"Used Car Buyer","title":"Stranger's Offer Decision","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"A decision node is simply defined by its information state.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_T = Vector{Node}()\npush!(D, DecisionNode(T, I_T))","category":"page"},{"location":"examples/used-car-buyer/#Test's-Outcome","page":"Used Car Buyer","title":"Test's Outcome","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The second chance node, R, has nodes O and T in its information set, and the probabilities ℙ(s_j𝐬_I(j)) must thus be defined for all combinations of states in O, T and R.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_R = [O, T]\nX_R = zeros(S[O], S[T], S[R])\nX_R[1, 1, :] = [1,0,0]\nX_R[1, 2, :] = [0,1,0]\nX_R[2, 1, :] = [1,0,0]\nX_R[2, 2, :] = [0,0,1]\npush!(C, ChanceNode(R, I_R))\npush!(X, Probabilities(R, X_R))","category":"page"},{"location":"examples/used-car-buyer/#Purchace-Decision","page":"Used Car Buyer","title":"Purchace Decision","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_A = [R]\npush!(D, DecisionNode(A, I_A))","category":"page"},{"location":"examples/used-car-buyer/#Testing-Cost","page":"Used Car Buyer","title":"Testing Cost","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We continue by defining the utilities (consequences) associated with value nodes. The value nodes are defined similarly as the chance nodes, except that instead of probabilities, we define consequences Y_j(𝐬_I(j)). Value nodes can be named just like the other nodes, e.g. V1 = 5, but considering that the index of value nodes is not needed elsewhere (value nodes can't be in information sets), we choose to simply use the index number when creating the node.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_V1 = [T]\nY_V1 = [0.0, -25.0]\npush!(V, ValueNode(5, I_V1))\npush!(Y, Consequences(5, Y_V1))","category":"page"},{"location":"examples/used-car-buyer/#Base-Profit-of-Purchase","page":"Used Car Buyer","title":"Base Profit of Purchase","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_V2 = [A]\nY_V2 = [100.0, 40.0, 0.0]\npush!(V, ValueNode(6, I_V2))\npush!(Y, Consequences(6, Y_V2))","category":"page"},{"location":"examples/used-car-buyer/#Repairing-Cost","page":"Used Car Buyer","title":"Repairing Cost","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The rows of the consequence matrix Y_V3 correspond to the state of the car, while the columns correspond to the decision made in node A.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_V3 = [O, A]\nY_V3 = [-200.0 0.0 0.0;\n        -40.0 -20.0 0.0]\npush!(V, ValueNode(7, I_V3))\npush!(Y, Consequences(7, Y_V3))","category":"page"},{"location":"examples/used-car-buyer/#Validating-Influence-Diagram","page":"Used Car Buyer","title":"Validating Influence Diagram","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Validate influence diagram and sort nodes, probabilities and consequences","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"validate_influence_diagram(S, C, D, V)\nsort!.((C, D, V, X, Y), by = x -> x.j)","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Default path probabilities and utilities are defined as the joint probability of all chance events in the diagram and the sum of utilities in value nodes, respectively. In the Contingent Portfolio Programming example, we show how to use a user-defined custom path utility function.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"P = DefaultPathProbability(C, X)\nU = DefaultPathUtility(V, Y)","category":"page"},{"location":"examples/used-car-buyer/#Decision-Model","page":"Used Car Buyer","title":"Decision Model","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We then construct the decision model using the DecisionProgramming.jl package, using the expected value as the objective.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"model = Model()\nz = decision_variables(model, S, D)\nπ_s = path_probability_variables(model, z, S, D, P)\nEV = expected_value(model, π_s, S, U)\n@objective(model, Max, EV)","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We can perform the optimization using an optimizer such as Gurobi.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"optimizer = optimizer_with_attributes(\n    () -> Gurobi.Optimizer(Gurobi.Env()),\n    \"IntFeasTol\"      => 1e-9,\n    \"LazyConstraints\" => 1,\n)\nset_optimizer(model, optimizer)\noptimize!(model)","category":"page"},{"location":"examples/used-car-buyer/#Analyzing-Results","page":"Used Car Buyer","title":"Analyzing Results","text":"","category":"section"},{"location":"examples/used-car-buyer/#Decision-Strategy","page":"Used Car Buyer","title":"Decision Strategy","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Once the model is solved, we obtain the following decision strategy:","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Z = DecisionStrategy(z, D)","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"julia> print_decision_strategy(S, Z)\n┌────────┬────┬───┐\n│  Nodes │ () │ 2 │\n├────────┼────┼───┤\n│ States │ () │ 2 │\n└────────┴────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (3,) │ 4 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 3 │\n│ States │ (2,) │ 2 │\n│ States │ (3,) │ 1 │\n└────────┴──────┴───┘","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"To start explaining this output, let's take a look at the top table. On the right, we have the decision node 2. We defined earlier that the node T is node number 2. On the left, we have the information set of that decision node, which is empty. The strategy in the first decision node is to choose alternative 2, which we defined to be testing the car.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"In the bottom table, we have node number 4 (node A) and its predecessor, node number 3 (node R). The first row, where we obtain no test result, is invalid for this strategy since we tested the car. If the car is a lemon, Joe should buy the car with a guarantee (alternative 2), and if it is a peach, buy the car without guarantee (alternative 1).","category":"page"},{"location":"examples/used-car-buyer/#Utility-Distribution","page":"Used Car Buyer","title":"Utility Distribution","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"udist = UtilityDistribution(S, P, U, Z)","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"julia> print_utility_distribution(udist)\n┌───────────┬─────────────┐\n│   Utility │ Probability │\n│   Float64 │     Float64 │\n├───────────┼─────────────┤\n│ 15.000000 │    0.200000 │\n│ 35.000000 │    0.800000 │\n└───────────┴─────────────┘","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"From the utility distribution, we can see that Joe's profit with this strategy is 15 USD, with a 20% probability (the car is a lemon) and 35 USD with an 80% probability (the car is a peach).","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"julia> print_statistics(udist)\n┌──────────┬────────────┐\n│     Name │ Statistics │\n│   String │    Float64 │\n├──────────┼────────────┤\n│     Mean │  31.000000 │\n│      Std │   8.000000 │\n│ Skewness │  -1.500000 │\n│ Kurtosis │   0.250000 │\n└──────────┴────────────┘","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The expected profit is thus 31 USD.","category":"page"},{"location":"examples/used-car-buyer/#References","page":"Used Car Buyer","title":"References","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"[1]: Howard, R. A. (1977). The used car buyer. Reading in Decision Analysis, 2nd Ed. Stanford Research Institute, Menlo Park, CA.","category":"page"},{"location":"decision-programming/computational-complexity/#computational-complexity","page":"Computational Complexity","title":"Computational Complexity","text":"","category":"section"},{"location":"decision-programming/computational-complexity/#Introduction","page":"Computational Complexity","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"Decision programming relies on mixed-integer linear programming, which is known to be an NP-hard problem. In this section, we analyze how the influence diagram affects the size of the mixed-integer linear model, determining whether it is tractable.","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We use the following inequalities for sum and product of non-negative elements A to derive the lower and upper bounds for the number of paths and the number of decision variables. Sum inequality:","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"A left(min_aA aright)  _aA a  A left(max_aA aright)","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"Product inequality:","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"left(min_aA aright)^A  _aA a  left(max_aA aright)^A","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"The following bounds for the number of paths and the number of decision variables show how the number of states, nodes, and arcs affects the size of the model.","category":"page"},{"location":"decision-programming/computational-complexity/#Number-of-Paths","page":"Computational Complexity","title":"Number of Paths","text":"","category":"section"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We define the number of paths as","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"𝐒=_iCD S_i","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"From the definition of the influence diagram, we have the path length of n=CD Then, we have the bounds for the number of paths as","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"left(min_iCD S_iright)^n  𝐒  left(max_iCD S_iright)^n","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We assume that all nodes iCD are non-trivial. That is, each decision or chance node has at least two states S_i2 Then, the number of paths is exponential to the path length of n","category":"page"},{"location":"decision-programming/computational-complexity/#Number-of-Decision-Variables","page":"Computational Complexity","title":"Number of Decision Variables","text":"","category":"section"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We define the number of decision variables as","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"_iD𝐒_I(i) S_i = _iD S_i _jI(i)S_j = _iD _jI(i)iS_j","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"From the definition of the information set, for all iD we have I(i)iCD with size 1I(i)i=I(i)+1mn where m denotes the upper bound of influence other nodes have on any decision node. Also, we have the number of decision nodes 0Dn Thus, we have the bounds","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"0  _iD𝐒_I(i) S_i  D left(max_iCD S_jright)^m","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"In the worst case, m=n, a decision node is influenced by every other chance and decision node. However, in most practical cases, we have m  n where decision nodes are influenced only by a limited number of other chance and decision nodes, making models easier to solve.","category":"page"},{"location":"examples/n-monitoring/#N-Monitoring","page":"N-Monitoring","title":"N-Monitoring","text":"","category":"section"},{"location":"examples/n-monitoring/#Description","page":"N-Monitoring","title":"Description","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The N-monitoring problem is described in [1], sections 4.1 and 6.1.","category":"page"},{"location":"examples/n-monitoring/#Influence-Diagram","page":"N-Monitoring","title":"Influence Diagram","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"(Image: )","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The influence diagram of generalized N-monitoring problem where N1 and indices k=1N The nodes are associated with states as follows. Load state L=high low denotes the load on a structure, report states R_k=high low report the load state to the action states A_k=yes no which represent different decisions to fortify the structure. The failure state F=failure success represents whether or not the (fortified) structure fails under the load L. Finally, the utility at target T depends on the whether F fails and the fortification costs.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"We draw the cost of fortification c_kU(01) from a uniform distribution, and the magnitude of fortification is directly proportional to the cost. Fortification is defined as","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"f(A_k=yes) = c_k","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"f(A_k=no) = 0","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"using Logging, Random\nusing JuMP, Gurobi\nusing DecisionProgramming\n\nRandom.seed!(13)\n\nconst N = 4\nconst L = [1]\nconst R_k = [k + 1 for k in 1:N]\nconst A_k = [(N + 1) + k for k in 1:N]\nconst F = [2*N + 2]\nconst T = [2*N + 3]\nconst L_states = [\"high\", \"low\"]\nconst R_k_states = [\"high\", \"low\"]\nconst A_k_states = [\"yes\", \"no\"]\nconst F_states = [\"failure\", \"success\"]\nconst c_k = rand(N)\nconst b = 0.03\nfortification(k, a) = [c_k[k], 0][a]\n\nS = States([\n    (length(L_states), L),\n    (length(R_k_states), R_k),\n    (length(A_k_states), A_k),\n    (length(F_states), F)\n])\nC = Vector{ChanceNode}()\nD = Vector{DecisionNode}()\nV = Vector{ValueNode}()\nX = Vector{Probabilities}()\nY = Vector{Consequences}()","category":"page"},{"location":"examples/n-monitoring/#Load-State-Probability","page":"N-Monitoring","title":"Load State Probability","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probability that the load is high, ℙ(L=high), is drawn from a uniform distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(L=high)U(01)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for j in L\n    I_j = Vector{Node}()\n    X_j = zeros(S[I_j]..., S[j])\n    X_j[1] = rand()\n    X_j[2] = 1.0 - X_j[1]\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(j, X_j))\nend","category":"page"},{"location":"examples/n-monitoring/#Reporting-Probability","page":"N-Monitoring","title":"Reporting Probability","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probabilities of the report states correspond to the load state. We draw the values xU(01) and yU(01) from uniform distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(R_k=highL=high)=maxx1-x","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(R_k=lowL=low)=maxy1-y","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probability of a correct report is thus in the range [0.5,1]. (This reflects the fact that a probability under 50% would not even make sense, since we would notice that if the test suggests a high load, the load is more likely to be low, resulting in that a low report \"turns into\" a high report and vice versa.)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for j in R_k\n    I_j = L\n    x, y = rand(2)\n    X_j = zeros(S[I_j]..., S[j])\n    X_j[1, 1] = max(x, 1-x)\n    X_j[1, 2] = 1.0 - X_j[1, 1]\n    X_j[2, 2] = max(y, 1-y)\n    X_j[2, 1] = 1.0 - X_j[2, 2]\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(j, X_j))\nend","category":"page"},{"location":"examples/n-monitoring/#Decision-to-Fortify","page":"N-Monitoring","title":"Decision to Fortify","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Only the corresponding load report is known when making the fortification decision, thus I(A_k)=R_k.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for (i, j) in zip(R_k, A_k)\n    I_j = [i]\n    push!(D, DecisionNode(j, I_j))\nend","category":"page"},{"location":"examples/n-monitoring/#Probability-of-Failure","page":"N-Monitoring","title":"Probability of Failure","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probabilities of failure which are decresead by fortifications. We draw the values xU(01) and yU(01) from uniform distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(F=failureA_NA_1L=high)=fracmaxx 1-xexp(b _k=1N f(A_k))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(F=failureA_NA_1L=low)=fracminy 1-yexp(b _k=1N f(A_k))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for j in F\n    I_j = L ∪ A_k\n    x, y = rand(2)\n    X_j = zeros(S[I_j]..., S[j])\n    for s in paths(S[A_k])\n        d = exp(b * sum(fortification(k, a) for (k, a) in enumerate(s)))\n        X_j[1, s..., 1] = max(x, 1-x) / d\n        X_j[1, s..., 2] = 1.0 - X_j[1, s..., 1]\n        X_j[2, s..., 1] = min(y, 1-y) / d\n        X_j[2, s..., 2] = 1.0 - X_j[2, s..., 1]\n    end\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(j, X_j))\nend","category":"page"},{"location":"examples/n-monitoring/#Consequences","page":"N-Monitoring","title":"Consequences","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Utility from consequences at target T from failure state F","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"g(F=failure) = 0","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"g(F=success) = 100","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Utility from consequences at target T from action states A_k is","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"f(A_k=yes) = c_k","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"f(A_k=no) = 0","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Total cost","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Y(F A_N  A_1) = g(F) + (-f(A_N)) +  + (-f(A_1))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for j in T\n    I_j = A_k ∪ F\n    Y_j = zeros(S[I_j]...)\n    for s in paths(S[A_k])\n        cost = sum(-fortification(k, a) for (k, a) in enumerate(s))\n        Y_j[s..., 1] = cost + 0\n        Y_j[s..., 2] = cost + 100\n    end\n    push!(V, ValueNode(j, I_j))\n    push!(Y, Consequences(j, Y_j))\nend","category":"page"},{"location":"examples/n-monitoring/#Validating-Influence-Diagram","page":"N-Monitoring","title":"Validating Influence Diagram","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Finally, we need to validate the influence diagram and sort the nodes, probabilities and consequences in increasing order by the node indices.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"validate_influence_diagram(S, C, D, V)\nsort!.((C, D, V, X, Y), by = x -> x.j)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"We define the path probability.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"P = DefaultPathProbability(C, X)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"As the path utility, we use the default, which is the sum of the consequences given the path.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"U = DefaultPathUtility(V, Y)","category":"page"},{"location":"examples/n-monitoring/#Decision-Model","page":"N-Monitoring","title":"Decision Model","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"An affine transformation is applied to the path utility, making all utilities positive. See section on positive path utilities for details.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"U⁺ = PositivePathUtility(S, U)\nmodel = Model()\nz = decision_variables(model, S, D)\nπ_s = path_probability_variables(model, z, S, D, P; hard_lower_bound=false)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Two lazy constraints are also used to speed up the solution process.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"probability_cut(model, π_s, S, P)\nactive_paths_cut(model, π_s, S, P)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The expected utility is used as the objective and the problem is solved using Gurobi.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"EV = expected_value(model, π_s, S, U⁺)\n@objective(model, Max, EV)\n\noptimizer = optimizer_with_attributes(\n    () -> Gurobi.Optimizer(Gurobi.Env()),\n    \"IntFeasTol\"      => 1e-9,\n    \"LazyConstraints\" => 1,\n)\nset_optimizer(model, optimizer)\noptimize!(model)","category":"page"},{"location":"examples/n-monitoring/#Analyzing-Results","page":"N-Monitoring","title":"Analyzing Results","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The decision strategy shows us that the optimal strategy is to make all four fortifications regardless of the reports (state 1 in fortification nodes corresponds to the option \"yes\").","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Z = DecisionStrategy(z, D)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"julia> print_decision_strategy(S, Z)\n┌────────┬──────┬───┐\n│  Nodes │ (2,) │ 6 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 1 │\n└────────┴──────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (3,) │ 7 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 1 │\n└────────┴──────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (4,) │ 8 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 1 │\n└────────┴──────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (5,) │ 9 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 1 │\n└────────┴──────┴───┘","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The state probabilities for the strategy Z can also be obtained. These tell the probability of each state in each node, given the strategy Z.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"sprobs = StateProbabilities(S, P, Z)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"julia> print_state_probabilities(sprobs, L)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     1 │ 0.564449 │ 0.435551 │             │\n└───────┴──────────┴──────────┴─────────────┘\njulia> print_state_probabilities(sprobs, R_k)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     2 │ 0.515575 │ 0.484425 │             │\n│     3 │ 0.442444 │ 0.557556 │             │\n│     4 │ 0.543724 │ 0.456276 │             │\n│     5 │ 0.552515 │ 0.447485 │             │\n└───────┴──────────┴──────────┴─────────────┘\njulia> print_state_probabilities(sprobs, A_k)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     6 │ 1.000000 │ 0.000000 │             │\n│     7 │ 1.000000 │ 0.000000 │             │\n│     8 │ 1.000000 │ 0.000000 │             │\n│     9 │ 1.000000 │ 0.000000 │             │\n└───────┴──────────┴──────────┴─────────────┘\njulia> print_state_probabilities(sprobs, F)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│    10 │ 0.038697 │ 0.961303 │             │\n└───────┴──────────┴──────────┴─────────────┘","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"We can also print the utility distribution for the optimal strategy and some basic statistics for the distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"udist = UtilityDistribution(S, P, U, Z)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"julia> print_utility_distribution(udist)\n┌───────────┬─────────────┐\n│   Utility │ Probability │\n│   Float64 │     Float64 │\n├───────────┼─────────────┤\n│ -2.881344 │    0.038697 │\n│ 97.118656 │    0.961303 │\n└───────────┴─────────────┘","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"julia> print_statistics(udist)\n┌──────────┬────────────┐\n│     Name │ Statistics │\n│   String │    Float64 │\n├──────────┼────────────┤\n│     Mean │  93.248950 │\n│      Std │  19.287197 │\n│ Skewness │  -4.783515 │\n│ Kurtosis │  20.882012 │\n└──────────┴────────────┘","category":"page"},{"location":"examples/n-monitoring/#References","page":"N-Monitoring","title":"References","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"decision-programming/influence-diagram/#influence-diagram","page":"Influence Diagram","title":"Influence Diagram","text":"","category":"section"},{"location":"decision-programming/influence-diagram/#Introduction","page":"Influence Diagram","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Decision programming uses influence diagrams to model decision making problems under uncertainty. This section defines influence diagrams and discusses about their properties. It is based on the definitions in [1], [2], and [3].","category":"page"},{"location":"decision-programming/influence-diagram/#Definition","page":"Influence Diagram","title":"Definition","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the influence diagram as a directed, acyclic graph","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"G=(CDVIS)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The nodes N=CDV consists of chance nodes C decision nodes D and value nodes V. We index the chance and decision nodes such that CD=1n and values nodes such that V=n+1n+V where n=C+D","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the information set I of node jN as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"I(j)iCDij","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Practically, the information set is an edge list to reverse direction in the graph. The conditions enforce that the graph is acyclic, and there are no arcs from value nodes to other nodes.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We refer to S as the state space. Each chance and decision node jCD is associates with a finite number of states S_j that we encode using integers 1S_j from one to number of states S_j1 We refer to a node j as trivial if is has only one state, that is, S_j=1","category":"page"},{"location":"decision-programming/influence-diagram/#Root-and-Leaf-Nodes","page":"Influence Diagram","title":"Root and Leaf Nodes","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"In the subdiagram of G which consists of the chance and decision nodes jCD we call node j a root node if its information set if empty, that is, I(j)=","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Similarly, we call node j a leaf node if it is not in any information set, that is, jI(i) for all iCD Each leaf node must be in at least one of the information sets of value nodes. That is, for each leaf node j exists a value node iV such that jI(i) Otherwise, the node j is redundant.","category":"page"},{"location":"decision-programming/influence-diagram/#Visualization","page":"Influence Diagram","title":"Visualization","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"To visualize influence diagrams, we define the different node types and how to order the nodes. There are two ways to order directed acyclic graphs, linear and depth-wise. We use diagrams.net for drawing influence diagrams.","category":"page"},{"location":"decision-programming/influence-diagram/#Node-Types","page":"Influence Diagram","title":"Node Types","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(Image: )","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We use a circle to represent chance nodes, square to represent decision nodes and diamond to represent value nodes. The symbol i represents the node's index and symbol S_i the states of the chance or decision node.","category":"page"},{"location":"decision-programming/influence-diagram/#Linear-Order","page":"Influence Diagram","title":"Linear Order","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(Image: )","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We can order the nodes in increasing linear order based on indices.","category":"page"},{"location":"decision-programming/influence-diagram/#Depth-wise-Order","page":"Influence Diagram","title":"Depth-wise Order","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(Image: )","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the depth of a node jN as follows. Root nodes have a depth of one","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"operatornamedepth(j)=1quad I(j)=","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Other nodes have a depth of one greater than the maximum depth of its predecessors","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"operatornamedepth(j)=max_iI(j) operatornamedepth(i) + 1quad I(j)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We can group the nodes by their depth and then order them by increasing depth and increasing indices order within that depth. Compared to linear order, the depth-wise order is more concise. It displays more information about the influence relationships, because nodes can only be influenced by nodes with smaller depth.","category":"page"},{"location":"decision-programming/influence-diagram/#Paths","page":"Influence Diagram","title":"Paths","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Paths in influence diagrams represent realizations of states for chance and decision nodes. Formally, a path is a sequence of states","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐬=(s_1 s_2 s_n)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"where each state s_iS_i for all chance and decision nodes iCD","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define a subpath of 𝐬 is a subsequence","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(𝐬_i_1 𝐬_i_2  𝐬_i_k)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"where 1i_1i_2i_kn and kn","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The information path of node jN on path 𝐬 is a subpath defined as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐬_I(j)=(𝐬_i  iI(j))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the set of all paths as a product set of all states","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐒=_jCD S_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The set of information paths of node jN is the product set of the states in its information set","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐒_I(j)=_iI(j) S_i","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We denote elements of the sets using notation s_jS_j, 𝐬𝐒, and 𝐬_I(j)𝐒_I(j)","category":"page"},{"location":"decision-programming/influence-diagram/#Probabilities","page":"Influence Diagram","title":"Probabilities","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"For each chance node jC, we denote the probability of state s_j given information path 𝐬_I(j) as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"ℙ(X_j=s_jX_I(j)=𝐬_I(j))=ℙ(s_j𝐬_I(j))0 1","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"with","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"_s_jS_j ℙ(s_j𝐬_I(j)) = 1","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We refer to a chance state s_jS_j given information path 𝐬_I(j) as inactive if its probability is zero ℙ(s_j𝐬_I(j))=0","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Implementation wise, we can think probabilities as functions of information paths concatenated with state X_j  𝐒_I(j)S_j  0 1 where _s_jS_j X_j(𝐬_I(j)s_j)=1","category":"page"},{"location":"decision-programming/influence-diagram/#Decision-Strategy","page":"Influence Diagram","title":"Decision Strategy","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"For each decision node jD a local decision strategy maps an information path 𝐬_I(j) to a state s_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Z_j𝐒_I(j)S_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Decision strategy Z contains one local decision strategy for each decision node. Set of all decision strategies is denoted ℤ","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"A decision stategy Zℤ is compatible with the path 𝐬𝐒 if and only if Z_j(𝐬_I(j))=s_j forall Z_jZ and jD","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We denote the set of compatible paths as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐒(Z)=𝐬𝐒  Z text is compatible with  𝐬","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Since each decision strategy Z_j chooses only one of its states, the number of compatible paths is a constant","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐒(Z)=𝐒prod_jDS_j=prod_jCS_j","category":"page"},{"location":"decision-programming/influence-diagram/#Path-Probability","page":"Influence Diagram","title":"Path Probability","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the upper bound of path probability as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"p(𝐬) = _jC ℙ(𝐬_j𝐬_I(j))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Note that the upper bound is larger than zero p(𝐬)0 if there are zero inactive chance states on the path 𝐬 and equal to zero p(𝐬)=0 otherwise.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The path probability equals p(𝐬) if the path 𝐬 is compatible with the decision strategy Z. Otherwise, the path cannot occur, and the probability is zero.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"ℙ(𝐬Z)=\nbegincases\np(𝐬)  Z text is compatible with  𝐬 \n0  textotherwise\nendcases","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"An active path is a path 𝐬𝐒 that has positive path probability ℙ(𝐬Z)0 We refer to a path with path probability of zero as inactive path.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We denote the set of active paths given a decision strategy Z as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐒^+(Z)=𝐬𝐒  ℙ(𝐬Z)0","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"=𝐬𝐒(Z)  p(𝐬)0","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"By definition, the active paths is subset of compatible paths. Therefore, the number of active paths is bounded by the number of compatible paths","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐒^+(Z)𝐒(Z)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"If an influece diagram has zero inactive chance states the number of active paths is equal to the number of compatible paths","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐒^+(Z)=𝐒(Z)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Otherwise, the number of active paths is less than the number of compatible paths.","category":"page"},{"location":"decision-programming/influence-diagram/#Consequences","page":"Influence Diagram","title":"Consequences","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"For each value node jV, we define the consequence given information path 𝐬_I(j) as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Y_j𝐒_I(j)ℂ","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"where ℂ is the set of real-valued consequences.","category":"page"},{"location":"decision-programming/influence-diagram/#Path-Utility","page":"Influence Diagram","title":"Path Utility","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The utility function is a function that maps consequences to real-valued utility","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Uℂ^Vℝ","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The path utility is defined as the utility function acting on the consequences of value nodes given their information paths","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"mathcalU(𝐬) = U(Y_j(𝐬_I(j))  jV)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The default path utility is the sum of consequences","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"mathcalU(𝐬) = _jV Y_j(𝐬_I(j))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The utility function in this case corresponds to the sum of the elements.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The utility function affects the objectives discussed Decision Model page. We can choose the utility function such that the path utility function either returns:","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"a numerical value, which leads to a mixed-integer linear programming (MILP) formulation or\na linear function with real and integer-valued variables, which leads to a mixed-integer quadratic programming (MIQP) formulation.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Different formulations require a solver capable of solving them.","category":"page"},{"location":"decision-programming/influence-diagram/#Path-Distribution","page":"Influence Diagram","title":"Path Distribution","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"A path distribution is a pair","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(ℙ(𝐬Z) mathcalU(𝐬))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"that comprises of path probability function and path utility function over paths 𝐬𝐒 conditional to the decision strategy Z","category":"page"},{"location":"decision-programming/influence-diagram/#Properties","page":"Influence Diagram","title":"Properties","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"In this section, we define common properties for influence diagrams.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Discrete influence diagram refers to countable state space. Otherwise, the influence diagram is continuous. We can discretize continuous influence diagrams using discrete bins.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Influence diagram is symmetric if there is zero inactive chance states. Otherwise, it is assymetric.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Two nodes are sequential if there exists a directed path from one node to the other in the influence diagram. Otherwise, the nodes are parallel. Sequential nodes often model time dimension.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Repeated subdiagram refers to a recurring pattern within an influence diagram. Often, influence diagrams do not have a unique structure, but they consist of a repeated pattern due to the underlying problem's properties.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Limited-memory influence diagram refers to an influence diagram where an upper bound limits the size of the information set for decision nodes. That is, I(j)m for all jD where the limit m is less than CD Smaller limits of m are desirable because they reduce the decision model size, as discussed in the Computational Complexity page.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Isolated subdiagrams refer to an influence diagram that consists of multiple unconnected diagrams, that is, there are no undirected connections between the diagrams. Therefore, one isolated subdiagram's decisions affect decisions on the other isolated subdiagrams only through the utility function.","category":"page"},{"location":"decision-programming/influence-diagram/#References","page":"Influence Diagram","title":"References","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"[2]: Howard, R. A., & Matheson, J. E. (2005). Influence diagrams. Decision Analysis, 2(3), 127-143. https://doi.org/10.1287/deca.1050.0020","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"[3]: Shachter, R. D. (1986). Evaluating influence diagrams. Operations research, 34(6), 871-882. https://doi.org/10.1287/opre.34.6.871","category":"page"},{"location":"#DecisionProgramming.jl","page":"Home","title":"DecisionProgramming.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"DecisionProgramming.jl is a Julia package for solving multi-stage decision problems under uncertainty, modeled using influence diagrams, and leveraging the power of mixed-integer linear programming. Solving multi-stage decision problems under uncertainty consists of the following three steps.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the first step, we model the decision problem using an influence diagram with associated probabilities, consequences, and path utility function.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the second step, we create a decision model with an objective for the influence diagram. We solve the model to obtain an optimal decision strategy. We can create and solve multiple models with different objectives for the same influence diagram to receive various optimal decision strategies.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the third step, we analyze the resulting decision strategies for the influence diagram. In particular, we are interested in utility distribution and its associated statistics and risk measures.","category":"page"},{"location":"","page":"Home","title":"Home","text":"DecisionProgramming.jl provides the necessary functionality for expressing and solving decision problems but does not explain how to design influence diagrams. The rest of this documentation will describe the mathematical and programmatic details, touch on the computational challenges, and provide concrete examples of solving decision problems.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The examples start with a rather simple and easily approachable Used Car Buyer problem that can be also solved using more conventional methods such as decision trees. The following two examples illustrate the capabilities of the framework in problems where the no-forgetting assumption does not hold and solving the influence diagram with well-established techniques is thus impossible. In the Pig Breeding problem, only the most recent information is available when making each decision, thus breaking the no-forgetting assumption, while in the N-Monitoring problem, the decisions are made in parallel with no communication between the decision makers, also leading to the assumption not working. The final example is a more advanced one, demonstrating the versatility of the framework in adding decision variables and constraints.","category":"page"},{"location":"","page":"Home","title":"Home","text":"DecisionProgramming.jl is developed in the Systems Analysis Laboratory at Aalto University by Ahti Salo,  Fabricio Oliveira, Juho Andelmin, Olli Herrala, and Jaan Tollander de Balsch.","category":"page"},{"location":"examples/pig-breeding/#Pig-Breeding","page":"Pig Breeding","title":"Pig Breeding","text":"","category":"section"},{"location":"examples/pig-breeding/#Description","page":"Pig Breeding","title":"Description","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The pig breeding problem as described in [1].","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"\"A pig breeder is growing pigs for a period of four months and subsequently selling them. During this period the pig may or may not develop a certain disease. If the pig has the disease at the time it must be sold, the pig must be sold for slaughtering, and its expected market price is then 300 DKK (Danish kroner). If it is disease free, its expected market price as a breeding animal is 1000 DKK","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Once a month, a veterinary doctor sees the pig and makes a test for presence of the disease. If the pig is ill, the test will indicate this with probability 0.80, and if the pig is healthy, the test will indicate this with probability 0.90. At each monthly visit, the doctor may or may not treat the pig for the disease by injecting a certain drug. The cost of an injection is 100 DKK.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"A pig has the disease in the first month with probability 0.10. A healthy pig develops the disease in the subsequent month with probability 0.20 without injection, whereas a healthy and treated pig develops the disease with probability 0.10, so the injection has some preventive effect. An untreated pig that is unhealthy will remain so in the subsequent month with probability 0.90, whereas the similar probability is 0.50 for an unhealthy pig that is treated. Thus spontaneous cure is possible, but treatment is beneficial on average.\"","category":"page"},{"location":"examples/pig-breeding/#Influence-Diagram","page":"Pig Breeding","title":"Influence Diagram","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"(Image: )","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The influence diagram for the the generalized N-month pig breeding. The nodes are associated with the following states. Health states h_k=illhealthy represent the health of the pig at month k=1N. Test states t_k=positivenegative represent the result from testing the pig at month k=1N-1. Treat states d_k=treat pass represent the decision to treat the pig with an injection at month k=1N-1.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The dashed arcs represent the no-forgetting principle and we can toggle them on and off in the formulation.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming, we start by defining the node indices and states, as follows:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"using JuMP, Gurobi\nusing DecisionProgramming\n\nconst N = 4\nconst health = [3*k - 2 for k in 1:N]\nconst test = [3*k - 1 for k in 1:(N-1)]\nconst treat = [3*k for k in 1:(N-1)]\nconst cost = [(3*N - 2) + k for k in 1:(N-1)]\nconst price = [(3*N - 2) + N]\nconst health_states = [\"ill\", \"healthy\"]\nconst test_states = [\"positive\", \"negative\"]\nconst treat_states = [\"treat\", \"pass\"]\n\nS = States([\n    (length(health_states), health),\n    (length(test_states), test),\n    (length(treat_states), treat),\n])\nC = Vector{ChanceNode}()\nD = Vector{DecisionNode}()\nV = Vector{ValueNode}()\nX = Vector{Probabilities}()\nY = Vector{Consequences}()","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Next, we define the nodes with their information sets and corresponding probabilities or consequences.","category":"page"},{"location":"examples/pig-breeding/#Health-at-First-Month","page":"Pig Breeding","title":"Health at First Month","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"As seen in the influence diagram, the node h_1 has no arcs into it, making it a root node. Therefore, the information set I(h_1) is empty.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The probability that pig is ill in the first month is","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_1 = ill)=01","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We obtain the complement probabilities for binary states by subtracting from one","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_1 = healthy)=1-ℙ(h_1 = ill)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming, we add the nodes and probabilities as follows:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for j in health[[1]]\n    I_j = Vector{Node}()\n    X_j = zeros(S[I_j]..., S[j])\n    X_j[1] = 0.1\n    X_j[2] = 1.0 - X_j[1]\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(j, X_j))\nend","category":"page"},{"location":"examples/pig-breeding/#Health-at-Subsequent-Months","page":"Pig Breeding","title":"Health at Subsequent Months","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The probability that the pig is ill in the subsequent months k=2N depends on the treatment decision and state of health in the previous month k-1. The nodes h_k-1 and d_k-1 are thus in the information set I(h_k), meaning that the probability distribution of h_k is conditional on these nodes:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = pass h_k-1 = healthy)=02","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = treat h_k-1 = healthy)=01","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = pass h_k-1 = ill)=09","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = treat h_k-1 = ill)=05","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for (i, k, j) in zip(health[1:end-1], treat, health[2:end])\n    I_j = [i, k]\n    X_j = zeros(S[I_j]..., S[j])\n    X_j[2, 2, 1] = 0.2\n    X_j[2, 2, 2] = 1.0 - X_j[2, 2, 1]\n    X_j[2, 1, 1] = 0.1\n    X_j[2, 1, 2] = 1.0 - X_j[2, 1, 1]\n    X_j[1, 2, 1] = 0.9\n    X_j[1, 2, 2] = 1.0 - X_j[1, 2, 1]\n    X_j[1, 1, 1] = 0.5\n    X_j[1, 1, 2] = 1.0 - X_j[1, 1, 1]\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(j, X_j))\nend","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Note that the order of states indexing the probabilities is reversed compared to the mathematical definition.","category":"page"},{"location":"examples/pig-breeding/#Health-Test","page":"Pig Breeding","title":"Health Test","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"For the probabilities that the test indicates a pig's health correctly at month k=1N-1, we have","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(t_k = positive  h_k = ill) = 08","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(t_k = negative  h_k = healthy) = 09","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for (i, j) in zip(health, test)\n    I_j = [i]\n    X_j = zeros(S[I_j]..., S[j])\n    X_j[1, 1] = 0.8\n    X_j[1, 2] = 1.0 - X_j[1, 1]\n    X_j[2, 2] = 0.9\n    X_j[2, 1] = 1.0 - X_j[2, 2]\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(j, X_j))\nend","category":"page"},{"location":"examples/pig-breeding/#Decision-to-Treat","page":"Pig Breeding","title":"Decision to Treat","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programing, we add the decision nodes for decision to treat the pig as follows:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for (i, j) in zip(test, treat)\n    I_j = [i]\n    push!(D, DecisionNode(j, I_j))\nend","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The no-forgetting assumption does not hold, and the information set I(d_k) only comprises the previous test result.","category":"page"},{"location":"examples/pig-breeding/#Cost-of-Treatment","page":"Pig Breeding","title":"Cost of Treatment","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The cost of treatment decision for the pig at month k=1N-1 is defined","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(d_k=treat) = -100","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(d_k=pass) = 0","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for (i, j) in zip(treat, cost)\n    I_j = [i]\n    Y_j = zeros(S[I_j]...)\n    Y_j[1] = -100\n    Y_j[2] = 0\n    push!(V, ValueNode(j, I_j))\n    push!(Y, Consequences(j, Y_j))\nend","category":"page"},{"location":"examples/pig-breeding/#Selling-Price","page":"Pig Breeding","title":"Selling Price","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The price of given the pig health at month N is defined","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(h_N=ill) = 300","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(h_N=healthy) = 1000","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for (i, j) in zip(health[end], price)\n    I_j = [i]\n    Y_j = zeros(S[I_j]...)\n    Y_j[1] = 300\n    Y_j[2] = 1000\n    push!(V, ValueNode(j, I_j))\n    push!(Y, Consequences(j, Y_j))\nend","category":"page"},{"location":"examples/pig-breeding/#Validating-Influence-Diagram","page":"Pig Breeding","title":"Validating Influence Diagram","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Finally, we need to validate the influence diagram and sort the nodes, probabilities and consequences in increasing order by the node indices.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"validate_influence_diagram(S, C, D, V)\nsort!.((C, D, V, X, Y), by = x -> x.j)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We define the path probability.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"P = DefaultPathProbability(C, X)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"As the path utility, we use the default, which is the sum of the consequences given the path.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"U = DefaultPathUtility(V, Y)","category":"page"},{"location":"examples/pig-breeding/#Decision-Model","page":"Pig Breeding","title":"Decision Model","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We apply an affine transformation to the utility function, making all path utilities positive. The purpose of this is discussed in the theoretical section of this documentation.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"U⁺ = PositivePathUtility(S, U)\nmodel = Model()\nz = decision_variables(model, S, D)\nπ_s = path_probability_variables(model, z, S, D, P; hard_lower_bound=false)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We also demonstrate one of the lazy constraints defined in the same section.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"active_paths_cut(model, π_s, S, P)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We create the objective function","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"EV = expected_value(model, π_s, S, U⁺)\n@objective(model, Max, EV)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"and set up the solver and solve the problem.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"optimizer = optimizer_with_attributes(\n    () -> Gurobi.Optimizer(Gurobi.Env()),\n    \"IntFeasTol\"      => 1e-9,\n    \"LazyConstraints\" => 1,\n)\nset_optimizer(model, optimizer)\noptimize!(model)","category":"page"},{"location":"examples/pig-breeding/#Analyzing-Results","page":"Pig Breeding","title":"Analyzing Results","text":"","category":"section"},{"location":"examples/pig-breeding/#Decision-Strategy","page":"Pig Breeding","title":"Decision Strategy","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We obtain the optimal decision strategy:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Z = DecisionStrategy(z, D)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"julia> print_decision_strategy(S, Z)\n┌────────┬──────┬───┐\n│  Nodes │ (2,) │ 3 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 2 │\n│ States │ (2,) │ 2 │\n└────────┴──────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (5,) │ 6 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 2 │\n└────────┴──────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (8,) │ 9 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 2 │\n└────────┴──────┴───┘","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The optimal strategy is as follows. In the first period, state 2 (no treatment) is chosen in node 3 (d_1) regardless of the state of node 2 (t_1). In other words, the pig is not treated in the first month. In the two subsequent months, state 1 (treat) is chosen if the corresponding test result is 1 (positive).","category":"page"},{"location":"examples/pig-breeding/#State-Probabilities","page":"Pig Breeding","title":"State Probabilities","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The state probabilities for the strategy Z can also be obtained. These tell the probability of each state in each node, given the strategy Z.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"sprobs = StateProbabilities(S, P, Z)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"julia> print_state_probabilities(sprobs, health)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     1 │ 0.100000 │ 0.900000 │             │\n│     4 │ 0.270000 │ 0.730000 │             │\n│     7 │ 0.295300 │ 0.704700 │             │\n│    10 │ 0.305167 │ 0.694833 │             │\n└───────┴──────────┴──────────┴─────────────┘\njulia> print_state_probabilities(sprobs, test)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     2 │ 0.170000 │ 0.830000 │             │\n│     5 │ 0.289000 │ 0.711000 │             │\n│     8 │ 0.306710 │ 0.693290 │             │\n└───────┴──────────┴──────────┴─────────────┘\njulia> print_state_probabilities(sprobs, treat)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     3 │ 0.000000 │ 1.000000 │             │\n│     6 │ 0.289000 │ 0.711000 │             │\n│     9 │ 0.306710 │ 0.693290 │             │\n└───────┴──────────┴──────────┴─────────────┘","category":"page"},{"location":"examples/pig-breeding/#Utility-Distribution","page":"Pig Breeding","title":"Utility Distribution","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We can also print the utility distribution for the optimal strategy. The selling prices for a healthy and an ill pig are 1000DKK and 300DKK, respectively, while the cost of treatment is 100DKK. We can see that the probability of the pig being ill in the end is the sum of three first probabilities, approximately 30.5%. This matches the probability of state 1 in node 10 in the state probabilities shown above.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"udist = UtilityDistribution(S, P, U, Z)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"julia> print_utility_distribution(udist)\n┌─────────────┬─────────────┐\n│     Utility │ Probability │\n│     Float64 │     Float64 │\n├─────────────┼─────────────┤\n│  100.000000 │    0.047857 │\n│  200.000000 │    0.129330 │\n│  300.000000 │    0.127980 │\n│  800.000000 │    0.061753 │\n│  900.000000 │    0.247160 │\n│ 1000.000000 │    0.385920 │\n└─────────────┴─────────────┘","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Finally, we print some statistics for the utility distribution. The expected value of the utility is 727DKK, the same as in [1].","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"julia> print_statistics(udist)\n┌──────────┬────────────┐\n│     Name │ Statistics │\n│   String │    Float64 │\n├──────────┼────────────┤\n│     Mean │ 726.812100 │\n│      Std │ 338.460723 │\n│ Skewness │  -0.811628 │\n│ Kurtosis │  -1.173465 │\n└──────────┴────────────┘","category":"page"},{"location":"examples/pig-breeding/#References","page":"Pig Breeding","title":"References","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"[1]: Lauritzen, S. L., & Nilsson, D. (2001). Representing and solving decision problems with limited information. Management Science, 47(9), 1235–1251. https://doi.org/10.1287/mnsc.47.9.1235.9779","category":"page"},{"location":"examples/contingent-portfolio-programming/#Contingent-Portfolio-Programming","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/#Description","page":"Contingent Portfolio Programming","title":"Description","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"[1], section 4.2","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"For instance, assume that the first-stage decisions specify which technology development projects will be started to generate patent-based intellectual property ( P ) for a platform. This intellectual property contributes subject to some uncertainties to the technical competitiveness ( T ) of the platform. In the second stage, it is possible to carry out application ( A ) development projects which, when completed, yield cash flows that depend on the market share of the platform. This market share ( M ) depends on the competitiveness of the platform and the number of developed applications. The aim is to maximize the cash flows from application projects less the cost of technology and application development projects.","category":"page"},{"location":"examples/contingent-portfolio-programming/#Influence-Diagram:-Projects","page":"Contingent Portfolio Programming","title":"Influence Diagram: Projects","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"(Image: )","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"The influence diagram of the contingent portfolio programming (CPP) problem.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"There are n_T technology development projects and n_A application development projects.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Decision states to develop patents","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"d_i^PD_i^P=q_1^P q_2^P) q_2^P q_3^P)  q_D^P^P q_D^P+1^P)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Chance states of technical competitiveness c_j^TC_j^T","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Decision states to develop applications","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"d_k^AD^A=q_1^A q_2^A) q_2^A q_3^A)  q_D^A^A q_D^A+1^A)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Chance states of market size c_l^MC_l^M","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"using Logging, Random\nusing JuMP, Gurobi\nusing DecisionProgramming\n\nRandom.seed!(42)\n\nconst dᴾ = 1    # Decision node: range for number of patents\nconst cᵀ = 2    # Chance node:   technical competitiveness\nconst dᴬ = 3    # Decision node: range for number of applications\nconst cᴹ = 4    # Chance node:   market share\nconst DP_states = [\"0-3 patents\", \"3-6 patents\", \"6-9 patents\"]\nconst CT_states = [\"low\", \"medium\", \"high\"]\nconst DA_states = [\"0-5 applications\", \"5-10 applications\", \"10-15 applications\"]\nconst CM_states = [\"low\", \"medium\", \"high\"]\n\nS = States([\n    (length(DP_states), [dᴾ]),\n    (length(CT_states), [cᵀ]),\n    (length(DA_states), [dᴬ]),\n    (length(CM_states), [cᴹ]),\n])\nC = Vector{ChanceNode}()\nD = Vector{DecisionNode}()\nV = Vector{ValueNode}()\nX = Vector{Probabilities}()\nY = Vector{Consequences}()","category":"page"},{"location":"examples/contingent-portfolio-programming/#Decision-on-range-of-number-of-patents","page":"Contingent Portfolio Programming","title":"Decision on range of number of patents","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"I_DP = Vector{Node}()\npush!(D, DecisionNode(dᴾ, I_DP))","category":"page"},{"location":"examples/contingent-portfolio-programming/#Technical-competitiveness-probability","page":"Contingent Portfolio Programming","title":"Technical competitiveness probability","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Probability of technical competitiveness c_j^T given the range d_i^P: ℙ(c_j^Td_i^P)01. A high number of patents increases probability of high competitiveness and a low number correspondingly increases the probability of low competitiveness.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"I_CT = [dᴾ]\nX_CT = zeros(S[dᴾ], S[cᵀ])\nX_CT[1, :] = [1/2, 1/3, 1/6]\nX_CT[2, :] = [1/3, 1/3, 1/3]\nX_CT[3, :] = [1/6, 1/3, 1/2]\npush!(C, ChanceNode(cᵀ, I_CT))\npush!(X, Probabilities(cᵀ, X_CT))","category":"page"},{"location":"examples/contingent-portfolio-programming/#Decision-on-range-of-number-of-applications","page":"Contingent Portfolio Programming","title":"Decision on range of number of applications","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"I_DA = [dᴾ, cᵀ]\npush!(D, DecisionNode(dᴬ, I_DA))","category":"page"},{"location":"examples/contingent-portfolio-programming/#Market-share-probability","page":"Contingent Portfolio Programming","title":"Market share probability","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Probability of market share c_l^M given the technical competitiveness c_j^T and range d_k^A: ℙ(c_l^Mc_j^Td_k^A)01. Higher competitiveness and number of application projects both increase the probability of high market share.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"I_CM = [cᵀ, dᴬ]\nX_CM = zeros(S[cᵀ], S[dᴬ], S[cᴹ])\nX_CM[1, 1, :] = [2/3, 1/4, 1/12]\nX_CM[1, 2, :] = [1/2, 1/3, 1/6]\nX_CM[1, 3, :] = [1/3, 1/3, 1/3]\nX_CM[2, 1, :] = [1/2, 1/3, 1/6]\nX_CM[2, 2, :] = [1/3, 1/3, 1/3]\nX_CM[2, 3, :] = [1/6, 1/3, 1/2]\nX_CM[3, 1, :] = [1/3, 1/3, 1/3]\nX_CM[3, 2, :] = [1/6, 1/3, 1/2]\nX_CM[3, 3, :] = [1/12, 1/4, 2/3]\npush!(C, ChanceNode(cᴹ, I_CM))\npush!(X, Probabilities(cᴹ, X_CM))","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"We add a dummy value node to avoid problems with the influence diagram validation. Without this, the final chance node would be seen as redundant.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"push!(V, ValueNode(5, [cᴹ]))\npush!(Y,Consequences(5, zeros(S[cᴹ])))","category":"page"},{"location":"examples/contingent-portfolio-programming/#Validating-the-Influence-Diagram","page":"Contingent Portfolio Programming","title":"Validating the Influence Diagram","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"validate_influence_diagram(S, C, D, V)\nsort!.((C, D, V, X, Y), by = x -> x.j)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"P = DefaultPathProbability(C, X)","category":"page"},{"location":"examples/contingent-portfolio-programming/#Decision-Model:-Portfolio-Selection","page":"Contingent Portfolio Programming","title":"Decision Model: Portfolio Selection","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"model = Model()\nz = decision_variables(model, S, D)\nπ_s = path_probability_variables(model, z, S, D, P)","category":"page"},{"location":"examples/contingent-portfolio-programming/#Creating-problem-specific-variables","page":"Contingent Portfolio Programming","title":"Creating problem specific variables","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"We recommend reading Section 4.2. in [1] for motivation and details of the formulation.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Technology project t costs I_tℝ^+ and generates O_tℕ patents.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Application project a costs I_aℝ^+ and generates O_aℕ applications. If completed, provides cash flow V(ac_l^M)ℝ^+","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"n_T = 5                     # number of technology projects\nn_A = 5                     # number of application projects\nI_t = rand(n_T)*0.1         # costs of technology projects\nO_t = rand(1:3,n_T)         # number of patents for each tech project\nI_a = rand(n_T)*2           # costs of application projects\nO_a = rand(2:4,n_T)         # number of applications for each appl. project\n\nV_A = rand(S[cᴹ], n_A).+0.5 # Value of an application\nV_A[1, :] .+= -0.5          # Low market share: less value\nV_A[3, :] .+= 0.5           # High market share: more value","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Decision variables x^T(t)0 1 indicate which technologies are selected.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Decision variables x^A(ad_i^Pc_j^T)0 1 indicate which applications are selected.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"x_T = variables(model, [S[dᴾ]...,n_T]; binary=true)\nx_A = variables(model, [S[dᴾ]...,S[cᵀ]...,S[dᴬ]..., n_A]; binary=true)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Number of patents x^T(t) = _i x_i^T(t) z(d_i^P)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Number of applications x^A(ad_i^Pc_j^T) = _k x_k^A(ad_i^Pc_j^T) z(d_k^Ad_i^Pc_j^T)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Helpful variables:","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Large constant M (e.g. frac32textmaxsum_t O_tsum_a O_a)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Small constant varepsilon = frac12textminO_t O_a","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"M = 20                      # a large constant\nε = 0.5*minimum([O_t O_a])  # a helper variable, allows using ≤ instead of < in constraints (28b) and (29b)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Limits q_i^P and q_k^A of the intervals","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"q_P = [0, 3, 6, 9]          # limits of the technology intervals\nq_A = [0, 5, 10, 15]        # limits of the application intervals","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Shorthand for the decision variables z","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"z_dP = z[1]\nz_dA = z[2]","category":"page"},{"location":"examples/contingent-portfolio-programming/#Creating-problem-specific-constraints","page":"Contingent Portfolio Programming","title":"Creating problem specific constraints","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"_t x_i^T(t) le z(d_i^P)n_T quad forall i","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:3],\n    sum(x_T[i,t] for t in 1:n_T) <= z_dP[i]*n_T)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"_a x_k^A(ad_i^Pc_j^T) le z(d_i^P)n_A quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:3, j=1:3, k=1:3],\n    sum(x_A[i,j,k,a] for a in 1:n_A) <= z_dP[i]*n_A)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"_a x_k^A(ad_i^Pc_j^T) le z(d_k^Ad_i^Pc_j^T)n_A quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:3, j=1:3, k=1:3],\n    sum(x_A[i,j,k,a] for a in 1:n_A) <= z_dA[i,j,k]*n_A)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"q_i^P - (1-z(d_i^P))M le sum_t x_i^T(t)O_t le q_i+1^P + (1-z(d_i^P))M - varepsilon quad forall i","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:3],\n    q_P[i] - (1 - z_dP[i])*M <= sum(x_T[i,t]*O_t[t] for t in 1:n_T))\n@constraint(model, [i=1:3],\n    sum(x_T[i,t]*O_t[t] for t in 1:n_T) <= q_P[i+1] + (1 - z_dP[i])*M - ε)\n","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"q_k^A - (1-z(d_k^Ad_i^Pc_j^T))M le sum_a x_k^A(ad_i^Pc_j^T)O_a le q_k+1^A + (1-z(d_k^Ad_i^Pc_j^T))M - varepsilon quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:3, j=1:3, k=1:3],\n    q_A[k] - (1 - z_dA[i,j,k])*M <= sum(x_A[i,j,k,a]*O_a[a] for a in 1:n_A))\n@constraint(model, [i=1:3, j=1:3, k=1:3],\n    sum(x_A[i,j,k,a]*O_a[a] for a in 1:n_A) <= q_A[k+1] + (1 - z_dA[i,j,k])*M - ε)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"We can also model dependencies between the technology and application projects, e.g. application project a can be completed only if technology project t has been completed. This is done by adding constraints","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"x_k^A(ad_i^Pc_j^T) le x_i^T(t) quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"As an example, we state that application projects 1 and 2 require technology project 1, and application project 2 also requires technology project 2.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:3, j=1:3, k=1:3], x_A[i,j,k,1] <= x_T[i,1])\n@constraint(model, [i=1:3, j=1:3, k=1:3], x_A[i,j,k,2] <= x_T[i,1])\n@constraint(model, [i=1:3, j=1:3, k=1:3], x_A[i,j,k,2] <= x_T[i,2])","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"x_i^T(t)0 1 quad forall i","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"x_k^A(ad_i^Pc_j^T)0 1 quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/#Path-Utility","page":"Contingent Portfolio Programming","title":"Path Utility","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"mathcalU(s) = sum_a x_k^A(ad_i^Pc_j^T) (V(ac_l^M) - I_a) - _t x_i^T(t) I_t","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"struct PathUtility <: AbstractPathUtility\n    expr\nend\n(U::PathUtility)(s::Path) = value.(U.expr[s])\n\nU = PathUtility(@expression(model, [s = paths(S)],\n    sum(x_A[s[1:3]..., a]*(V_A[s[4],a] - I_a[a]) for a in 1:n_A) -\n    sum(x_T[s[1],t]*I_t[t] for t in 1:n_T)))\n\nEV = @expression(model, sum(π_s[s...] * U.expr[s] for s in paths(S)))\n@objective(model, Max, EV)","category":"page"},{"location":"examples/contingent-portfolio-programming/#Solving-the-Model","page":"Contingent Portfolio Programming","title":"Solving the Model","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"optimizer = optimizer_with_attributes(\n    () -> Gurobi.Optimizer(Gurobi.Env()),\n    \"IntFeasTol\"      => 1e-9,\n    \"LazyConstraints\" => 1,\n)\nset_optimizer(model, optimizer)\noptimize!(model)","category":"page"},{"location":"examples/contingent-portfolio-programming/#Analyzing-results","page":"Contingent Portfolio Programming","title":"Analyzing results","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"The optimal decision strategy and the utility distribution are printed. The strategy is to make 6-9 patents (state 3 in node 1) and 5-10 applications if the competitiveness is low, 10-15 otherwise. The expected utility for this strategy is 0.41.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Z = DecisionStrategy(z, D)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"julia> print_decision_strategy(S, Z)\n┌────────┬────┬───┐\n│  Nodes │ () │ 1 │\n├────────┼────┼───┤\n│ States │ () │ 3 │\n└────────┴────┴───┘\n┌────────┬────────┬───┐\n│  Nodes │ (1, 2) │ 3 │\n├────────┼────────┼───┤\n│ States │ (1, 1) │ 1 │\n│ States │ (2, 1) │ 1 │\n│ States │ (3, 1) │ 2 │\n│ States │ (1, 2) │ 1 │\n│ States │ (2, 2) │ 1 │\n│ States │ (3, 2) │ 3 │\n│ States │ (1, 3) │ 1 │\n│ States │ (2, 3) │ 1 │\n│ States │ (3, 3) │ 3 │\n│   ⋮    │   ⋮    │ ⋮ │\n└────────┴────────┴───┘","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"udist = UtilityDistribution(S, P, U, Z)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"julia> print_utility_distribution(udist)\n┌───────────┬─────────────┐\n│   Utility │ Probability │\n│   Float64 │     Float64 │\n├───────────┼─────────────┤\n│ -2.164246 │    0.097222 │\n│ -0.759404 │    0.083333 │\n│ -0.077398 │    0.236111 │\n│  0.258058 │    0.055556 │\n│  0.505004 │    0.027778 │\n│  1.342020 │    0.500000 │\n└───────────┴─────────────┘","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"julia> print_statistics(udist)\n┌──────────┬────────────┐\n│     Name │ Statistics │\n│   String │    Float64 │\n├──────────┼────────────┤\n│     Mean │   0.407403 │\n│      Std │   1.118111 │\n│ Skewness │  -1.004935 │\n│ Kurtosis │   0.071940 │\n└──────────┴────────────┘","category":"page"},{"location":"examples/contingent-portfolio-programming/#References","page":"Contingent Portfolio Programming","title":"References","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"}]
}
