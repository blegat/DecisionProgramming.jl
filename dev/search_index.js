var documenterSearchIndex = {"docs":
[{"location":"examples/n-monitoring/#N-Monitoring","page":"N-Monitoring","title":"N-Monitoring","text":"","category":"section"},{"location":"examples/n-monitoring/#Description","page":"N-Monitoring","title":"Description","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The N-monitoring problem is described in [1], sections 4.1 and 6.1.","category":"page"},{"location":"examples/n-monitoring/#Influence-Diagram","page":"N-Monitoring","title":"Influence Diagram","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"(Image: )","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The influence diagram of generalized N-monitoring problem where N1 and indices k=1N The nodes are associated with states as follows. Load state L=high low denotes the load on a structure, report states R_k=high low report the load state to the action states A_k=yes no which represent different decisions to fortify the structure. The failure state F=failure success represents whether or not the (fortified) structure fails under the load L. Finally, the utility at target T depends on the whether F fails and the fortification costs.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"We draw the cost of fortification c_kU(01) from a uniform distribution, and the magnitude of fortification is directly proportional to the cost. Fortification is defined as","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"f(A_k=yes) = c_k","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"f(A_k=no) = 0","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"using Logging, Random\nusing JuMP, Gurobi\nusing DecisionProgramming\n\nRandom.seed!(13)\n\nconst N = 4\nconst L = [1]\nconst R_k = [k + 1 for k in 1:N]\nconst A_k = [(N + 1) + k for k in 1:N]\nconst F = [2*N + 2]\nconst T = [2*N + 3]\nconst L_states = [\"high\", \"low\"]\nconst R_k_states = [\"high\", \"low\"]\nconst A_k_states = [\"yes\", \"no\"]\nconst F_states = [\"failure\", \"success\"]\nconst c_k = rand(N)\nconst b = 0.03\nfortification(k, a) = [c_k[k], 0][a]\n\nS = States([\n    (length(L_states), L),\n    (length(R_k_states), R_k),\n    (length(A_k_states), A_k),\n    (length(F_states), F)\n])\nC = Vector{ChanceNode}()\nD = Vector{DecisionNode}()\nV = Vector{ValueNode}()\nX = Vector{Probabilities}()\nY = Vector{Consequences}()","category":"page"},{"location":"examples/n-monitoring/#Load-State-Probability","page":"N-Monitoring","title":"Load State Probability","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probability that the load is high, ℙ(L=high), is drawn from a uniform distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(L=high)U(01)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for j in L\n    I_j = Vector{Node}()\n    X_j = zeros(S[I_j]..., S[j])\n    X_j[1] = rand()\n    X_j[2] = 1.0 - X_j[1]\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(j, X_j))\nend","category":"page"},{"location":"examples/n-monitoring/#Reporting-Probability","page":"N-Monitoring","title":"Reporting Probability","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probabilities of the report states correspond to the load state. We draw the values xU(01) and yU(01) from uniform distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(R_k=highL=high)=maxx1-x","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(R_k=lowL=low)=maxy1-y","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probability of a correct report is thus in the range [0.5,1]. (This reflects the fact that a probability under 50% would not even make sense, since we would notice that if the test suggests a high load, the load is more likely to be low, resulting in that a low report \"turns into\" a high report and vice versa.)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for j in R_k\n    I_j = L\n    x, y = rand(2)\n    X_j = zeros(S[I_j]..., S[j])\n    X_j[1, 1] = max(x, 1-x)\n    X_j[1, 2] = 1.0 - X_j[1, 1]\n    X_j[2, 2] = max(y, 1-y)\n    X_j[2, 1] = 1.0 - X_j[2, 2]\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(j, X_j))\nend","category":"page"},{"location":"examples/n-monitoring/#Decision-to-Fortify","page":"N-Monitoring","title":"Decision to Fortify","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Only the corresponding load report is known when making the fortification decision, thus I(A_k)=R_k.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for (i, j) in zip(R_k, A_k)\n    I_j = [i]\n    push!(D, DecisionNode(j, I_j))\nend","category":"page"},{"location":"examples/n-monitoring/#Probability-of-Failure","page":"N-Monitoring","title":"Probability of Failure","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The probabilities of failure which are decresead by fortifications. We draw the values xU(01) and yU(01) from uniform distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(F=failureA_NA_1L=high)=fracmaxx 1-xexp(b _k=1N f(A_k))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"ℙ(F=failureA_NA_1L=low)=fracminy 1-yexp(b _k=1N f(A_k))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for j in F\n    I_j = L ∪ A_k\n    x, y = rand(2)\n    X_j = zeros(S[I_j]..., S[j])\n    for s in paths(S[A_k])\n        d = exp(b * sum(fortification(k, a) for (k, a) in enumerate(s)))\n        X_j[1, s..., 1] = max(x, 1-x) / d\n        X_j[1, s..., 2] = 1.0 - X_j[1, s..., 1]\n        X_j[2, s..., 1] = min(y, 1-y) / d\n        X_j[2, s..., 2] = 1.0 - X_j[2, s..., 1]\n    end\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(j, X_j))\nend","category":"page"},{"location":"examples/n-monitoring/#Consequences","page":"N-Monitoring","title":"Consequences","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Utility from consequences at target T from failure state F","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"g(F=failure) = 0","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"g(F=success) = 100","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Utility from consequences at target T from action states A_k is","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"f(A_k=yes) = c_k","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"f(A_k=no) = 0","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Total cost","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Y(F A_N  A_1) = g(F) + (-f(A_N)) +  + (-f(A_1))","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"for j in T\n    I_j = A_k ∪ F\n    Y_j = zeros(S[I_j]...)\n    for s in paths(S[A_k])\n        cost = sum(-fortification(k, a) for (k, a) in enumerate(s))\n        Y_j[s..., 1] = cost + 0\n        Y_j[s..., 2] = cost + 100\n    end\n    push!(V, ValueNode(j, I_j))\n    push!(Y, Consequences(j, Y_j))\nend","category":"page"},{"location":"examples/n-monitoring/#Validating-Influence-Diagram","page":"N-Monitoring","title":"Validating Influence Diagram","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Finally, we need to validate the influence diagram and sort the nodes, probabilities and consequences in increasing order by the node indices.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"validate_influence_diagram(S, C, D, V)\nsort!.((C, D, V, X, Y), by = x -> x.j)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"We define the path probability.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"P = DefaultPathProbability(C, X)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"As the path utility, we use the default, which is the sum of the consequences given the path.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"U = DefaultPathUtility(V, Y)","category":"page"},{"location":"examples/n-monitoring/#Decision-Model","page":"N-Monitoring","title":"Decision Model","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"An affine transformation is applied to the path utility, making all utilities positive. See section on positive path utilities for details.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"U⁺ = PositivePathUtility(S, U)\nmodel = Model()\nz = DecisionVariables(model, S, D)\nπ_s = PathProbabilityVariables(model, z, S, P; hard_lower_bound=false)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Two lazy constraints are also used to speed up the solution process.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"probability_cut(model, π_s, P)\nactive_paths_cut(model, π_s, S, P)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The expected utility is used as the objective and the problem is solved using Gurobi.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"EV = expected_value(model, π_s, U⁺)\n@objective(model, Max, EV)\n\noptimizer = optimizer_with_attributes(\n    () -> Gurobi.Optimizer(Gurobi.Env()),\n    \"IntFeasTol\"      => 1e-9,\n    \"LazyConstraints\" => 1,\n)\nset_optimizer(model, optimizer)\noptimize!(model)","category":"page"},{"location":"examples/n-monitoring/#Analyzing-Results","page":"N-Monitoring","title":"Analyzing Results","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The decision strategy shows us that the optimal strategy is to make all four fortifications regardless of the reports (state 1 in fortification nodes corresponds to the option \"yes\").","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"Z = DecisionStrategy(z)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"julia> print_decision_strategy(S, Z)\n┌────────┬──────┬───┐\n│  Nodes │ (2,) │ 6 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 1 │\n└────────┴──────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (3,) │ 7 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 1 │\n└────────┴──────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (4,) │ 8 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 1 │\n└────────┴──────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (5,) │ 9 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 1 │\n└────────┴──────┴───┘","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"The state probabilities for the strategy Z can also be obtained. These tell the probability of each state in each node, given the strategy Z.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"sprobs = StateProbabilities(S, P, Z)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"julia> print_state_probabilities(sprobs, L)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     1 │ 0.564449 │ 0.435551 │             │\n└───────┴──────────┴──────────┴─────────────┘\njulia> print_state_probabilities(sprobs, R_k)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     2 │ 0.515575 │ 0.484425 │             │\n│     3 │ 0.442444 │ 0.557556 │             │\n│     4 │ 0.543724 │ 0.456276 │             │\n│     5 │ 0.552515 │ 0.447485 │             │\n└───────┴──────────┴──────────┴─────────────┘\njulia> print_state_probabilities(sprobs, A_k)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     6 │ 1.000000 │ 0.000000 │             │\n│     7 │ 1.000000 │ 0.000000 │             │\n│     8 │ 1.000000 │ 0.000000 │             │\n│     9 │ 1.000000 │ 0.000000 │             │\n└───────┴──────────┴──────────┴─────────────┘\njulia> print_state_probabilities(sprobs, F)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│    10 │ 0.038697 │ 0.961303 │             │\n└───────┴──────────┴──────────┴─────────────┘","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"We can also print the utility distribution for the optimal strategy and some basic statistics for the distribution.","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"udist = UtilityDistribution(S, P, U, Z)","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"julia> print_utility_distribution(udist)\n┌───────────┬─────────────┐\n│   Utility │ Probability │\n│   Float64 │     Float64 │\n├───────────┼─────────────┤\n│ -2.881344 │    0.038697 │\n│ 97.118656 │    0.961303 │\n└───────────┴─────────────┘","category":"page"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"julia> print_statistics(udist)\n┌──────────┬────────────┐\n│     Name │ Statistics │\n│   String │    Float64 │\n├──────────┼────────────┤\n│     Mean │  93.248950 │\n│      Std │  19.287197 │\n│ Skewness │  -4.783515 │\n│ Kurtosis │  20.882012 │\n└──────────┴────────────┘","category":"page"},{"location":"examples/n-monitoring/#References","page":"N-Monitoring","title":"References","text":"","category":"section"},{"location":"examples/n-monitoring/","page":"N-Monitoring","title":"N-Monitoring","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"examples/pig-breeding/#Pig-Breeding","page":"Pig Breeding","title":"Pig Breeding","text":"","category":"section"},{"location":"examples/pig-breeding/#Description","page":"Pig Breeding","title":"Description","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The pig breeding problem as described in [1].","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"\"A pig breeder is growing pigs for a period of four months and subsequently selling them. During this period the pig may or may not develop a certain disease. If the pig has the disease at the time it must be sold, the pig must be sold for slaughtering, and its expected market price is then 300 DKK (Danish kroner). If it is disease free, its expected market price as a breeding animal is 1000 DKK","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Once a month, a veterinary doctor sees the pig and makes a test for presence of the disease. If the pig is ill, the test will indicate this with probability 0.80, and if the pig is healthy, the test will indicate this with probability 0.90. At each monthly visit, the doctor may or may not treat the pig for the disease by injecting a certain drug. The cost of an injection is 100 DKK.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"A pig has the disease in the first month with probability 0.10. A healthy pig develops the disease in the subsequent month with probability 0.20 without injection, whereas a healthy and treated pig develops the disease with probability 0.10, so the injection has some preventive effect. An untreated pig that is unhealthy will remain so in the subsequent month with probability 0.90, whereas the similar probability is 0.50 for an unhealthy pig that is treated. Thus spontaneous cure is possible, but treatment is beneficial on average.\"","category":"page"},{"location":"examples/pig-breeding/#Influence-Diagram","page":"Pig Breeding","title":"Influence Diagram","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"(Image: )","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The influence diagram for the the generalized N-month pig breeding. The nodes are associated with the following states. Health states h_k=illhealthy represent the health of the pig at month k=1N. Test states t_k=positivenegative represent the result from testing the pig at month k=1N-1. Treat states d_k=treat pass represent the decision to treat the pig with an injection at month k=1N-1.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The dashed arcs represent the no-forgetting principle and we can toggle them on and off in the formulation.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming, we start by defining the node indices and states, as follows:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"using JuMP, Gurobi\nusing DecisionProgramming\n\nconst N = 4\nconst health = [3*k - 2 for k in 1:N]\nconst test = [3*k - 1 for k in 1:(N-1)]\nconst treat = [3*k for k in 1:(N-1)]\nconst cost = [(3*N - 2) + k for k in 1:(N-1)]\nconst price = [(3*N - 2) + N]\nconst health_states = [\"ill\", \"healthy\"]\nconst test_states = [\"positive\", \"negative\"]\nconst treat_states = [\"treat\", \"pass\"]\n\nS = States([\n    (length(health_states), health),\n    (length(test_states), test),\n    (length(treat_states), treat),\n])\nC = Vector{ChanceNode}()\nD = Vector{DecisionNode}()\nV = Vector{ValueNode}()\nX = Vector{Probabilities}()\nY = Vector{Consequences}()","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Next, we define the nodes with their information sets and corresponding probabilities or consequences.","category":"page"},{"location":"examples/pig-breeding/#Health-at-First-Month","page":"Pig Breeding","title":"Health at First Month","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"As seen in the influence diagram, the node h_1 has no arcs into it, making it a root node. Therefore, the information set I(h_1) is empty.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The probability that pig is ill in the first month is","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_1 = ill)=01","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We obtain the complement probabilities for binary states by subtracting from one","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_1 = healthy)=1-ℙ(h_1 = ill)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming, we add the nodes and probabilities as follows:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for j in health[[1]]\n    I_j = Vector{Node}()\n    X_j = zeros(S[I_j]..., S[j])\n    X_j[1] = 0.1\n    X_j[2] = 1.0 - X_j[1]\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(j, X_j))\nend","category":"page"},{"location":"examples/pig-breeding/#Health-at-Subsequent-Months","page":"Pig Breeding","title":"Health at Subsequent Months","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The probability that the pig is ill in the subsequent months k=2N depends on the treatment decision and state of health in the previous month k-1. The nodes h_k-1 and d_k-1 are thus in the information set I(h_k), meaning that the probability distribution of h_k is conditional on these nodes:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = pass h_k-1 = healthy)=02","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = treat h_k-1 = healthy)=01","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = pass h_k-1 = ill)=09","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(h_k = ill  d_k-1 = treat h_k-1 = ill)=05","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for (i, k, j) in zip(health[1:end-1], treat, health[2:end])\n    I_j = [i, k]\n    X_j = zeros(S[I_j]..., S[j])\n    X_j[2, 2, 1] = 0.2\n    X_j[2, 2, 2] = 1.0 - X_j[2, 2, 1]\n    X_j[2, 1, 1] = 0.1\n    X_j[2, 1, 2] = 1.0 - X_j[2, 1, 1]\n    X_j[1, 2, 1] = 0.9\n    X_j[1, 2, 2] = 1.0 - X_j[1, 2, 1]\n    X_j[1, 1, 1] = 0.5\n    X_j[1, 1, 2] = 1.0 - X_j[1, 1, 1]\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(j, X_j))\nend","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Note that the order of states indexing the probabilities is reversed compared to the mathematical definition.","category":"page"},{"location":"examples/pig-breeding/#Health-Test","page":"Pig Breeding","title":"Health Test","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"For the probabilities that the test indicates a pig's health correctly at month k=1N-1, we have","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(t_k = positive  h_k = ill) = 08","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"ℙ(t_k = negative  h_k = healthy) = 09","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for (i, j) in zip(health, test)\n    I_j = [i]\n    X_j = zeros(S[I_j]..., S[j])\n    X_j[1, 1] = 0.8\n    X_j[1, 2] = 1.0 - X_j[1, 1]\n    X_j[2, 2] = 0.9\n    X_j[2, 1] = 1.0 - X_j[2, 2]\n    push!(C, ChanceNode(j, I_j))\n    push!(X, Probabilities(j, X_j))\nend","category":"page"},{"location":"examples/pig-breeding/#Decision-to-Treat","page":"Pig Breeding","title":"Decision to Treat","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programing, we add the decision nodes for decision to treat the pig as follows:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for (i, j) in zip(test, treat)\n    I_j = [i]\n    push!(D, DecisionNode(j, I_j))\nend","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The no-forgetting assumption does not hold, and the information set I(d_k) only comprises the previous test result.","category":"page"},{"location":"examples/pig-breeding/#Cost-of-Treatment","page":"Pig Breeding","title":"Cost of Treatment","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The cost of treatment decision for the pig at month k=1N-1 is defined","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(d_k=treat) = -100","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(d_k=pass) = 0","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for (i, j) in zip(treat, cost)\n    I_j = [i]\n    Y_j = zeros(S[I_j]...)\n    Y_j[1] = -100\n    Y_j[2] = 0\n    push!(V, ValueNode(j, I_j))\n    push!(Y, Consequences(j, Y_j))\nend","category":"page"},{"location":"examples/pig-breeding/#Selling-Price","page":"Pig Breeding","title":"Selling Price","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The price of given the pig health at month N is defined","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(h_N=ill) = 300","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Y(h_N=healthy) = 1000","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"In decision programming:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"for (i, j) in zip(health[end], price)\n    I_j = [i]\n    Y_j = zeros(S[I_j]...)\n    Y_j[1] = 300\n    Y_j[2] = 1000\n    push!(V, ValueNode(j, I_j))\n    push!(Y, Consequences(j, Y_j))\nend","category":"page"},{"location":"examples/pig-breeding/#Validating-Influence-Diagram","page":"Pig Breeding","title":"Validating Influence Diagram","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Finally, we need to validate the influence diagram and sort the nodes, probabilities and consequences in increasing order by the node indices.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"validate_influence_diagram(S, C, D, V)\nsort!.((C, D, V, X, Y), by = x -> x.j)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We define the path probability.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"P = DefaultPathProbability(C, X)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"As the path utility, we use the default, which is the sum of the consequences given the path.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"U = DefaultPathUtility(V, Y)","category":"page"},{"location":"examples/pig-breeding/#Decision-Model","page":"Pig Breeding","title":"Decision Model","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We apply an affine transformation to the utility function, making all path utilities positive. The purpose of this is discussed in the theoretical section of this documentation.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"U⁺ = PositivePathUtility(S, U)\nmodel = Model()\nz = DecisionVariables(model, S, D)\nπ_s = PathProbabilityVariables(model, z, S, P; hard_lower_bound=false)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We also demonstrate one of the lazy constraints defined in the same section.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"active_paths_cut(model, π_s, S, P)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We create the objective function","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"EV = expected_value(model, π_s, U⁺)\n@objective(model, Max, EV)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"and set up the solver and solve the problem.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"optimizer = optimizer_with_attributes(\n    () -> Gurobi.Optimizer(Gurobi.Env()),\n    \"IntFeasTol\"      => 1e-9,\n    \"LazyConstraints\" => 1,\n)\nset_optimizer(model, optimizer)\noptimize!(model)","category":"page"},{"location":"examples/pig-breeding/#Analyzing-Results","page":"Pig Breeding","title":"Analyzing Results","text":"","category":"section"},{"location":"examples/pig-breeding/#Decision-Strategy","page":"Pig Breeding","title":"Decision Strategy","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We obtain the optimal decision strategy:","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Z = DecisionStrategy(z)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"julia> print_decision_strategy(S, Z)\n┌────────┬──────┬───┐\n│  Nodes │ (2,) │ 3 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 2 │\n│ States │ (2,) │ 2 │\n└────────┴──────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (5,) │ 6 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 2 │\n└────────┴──────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (8,) │ 9 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 1 │\n│ States │ (2,) │ 2 │\n└────────┴──────┴───┘","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The optimal strategy is as follows. In the first period, state 2 (no treatment) is chosen in node 3 (d_1) regardless of the state of node 2 (t_1). In other words, the pig is not treated in the first month. In the two subsequent months, state 1 (treat) is chosen if the corresponding test result is 1 (positive).","category":"page"},{"location":"examples/pig-breeding/#State-Probabilities","page":"Pig Breeding","title":"State Probabilities","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"The state probabilities for the strategy Z can also be obtained. These tell the probability of each state in each node, given the strategy Z.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"sprobs = StateProbabilities(S, P, Z)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"julia> print_state_probabilities(sprobs, health)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     1 │ 0.100000 │ 0.900000 │             │\n│     4 │ 0.270000 │ 0.730000 │             │\n│     7 │ 0.295300 │ 0.704700 │             │\n│    10 │ 0.305167 │ 0.694833 │             │\n└───────┴──────────┴──────────┴─────────────┘\njulia> print_state_probabilities(sprobs, test)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     2 │ 0.170000 │ 0.830000 │             │\n│     5 │ 0.289000 │ 0.711000 │             │\n│     8 │ 0.306710 │ 0.693290 │             │\n└───────┴──────────┴──────────┴─────────────┘\njulia> print_state_probabilities(sprobs, treat)\n┌───────┬──────────┬──────────┬─────────────┐\n│  Node │  State 1 │  State 2 │ Fixed state │\n│ Int64 │  Float64 │  Float64 │      String │\n├───────┼──────────┼──────────┼─────────────┤\n│     3 │ 0.000000 │ 1.000000 │             │\n│     6 │ 0.289000 │ 0.711000 │             │\n│     9 │ 0.306710 │ 0.693290 │             │\n└───────┴──────────┴──────────┴─────────────┘","category":"page"},{"location":"examples/pig-breeding/#Utility-Distribution","page":"Pig Breeding","title":"Utility Distribution","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"We can also print the utility distribution for the optimal strategy. The selling prices for a healthy and an ill pig are 1000DKK and 300DKK, respectively, while the cost of treatment is 100DKK. We can see that the probability of the pig being ill in the end is the sum of three first probabilities, approximately 30.5%. This matches the probability of state 1 in node 10 in the state probabilities shown above.","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"udist = UtilityDistribution(S, P, U, Z)","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"julia> print_utility_distribution(udist)\n┌─────────────┬─────────────┐\n│     Utility │ Probability │\n│     Float64 │     Float64 │\n├─────────────┼─────────────┤\n│  100.000000 │    0.047857 │\n│  200.000000 │    0.129330 │\n│  300.000000 │    0.127980 │\n│  800.000000 │    0.061753 │\n│  900.000000 │    0.247160 │\n│ 1000.000000 │    0.385920 │\n└─────────────┴─────────────┘","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"Finally, we print some statistics for the utility distribution. The expected value of the utility is 727DKK, the same as in [1].","category":"page"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"julia> print_statistics(udist)\n┌──────────┬────────────┐\n│     Name │ Statistics │\n│   String │    Float64 │\n├──────────┼────────────┤\n│     Mean │ 726.812100 │\n│      Std │ 338.460723 │\n│ Skewness │  -0.811628 │\n│ Kurtosis │  -1.173465 │\n└──────────┴────────────┘","category":"page"},{"location":"examples/pig-breeding/#References","page":"Pig Breeding","title":"References","text":"","category":"section"},{"location":"examples/pig-breeding/","page":"Pig Breeding","title":"Pig Breeding","text":"[1]: Lauritzen, S. L., & Nilsson, D. (2001). Representing and solving decision problems with limited information. Management Science, 47(9), 1235–1251. https://doi.org/10.1287/mnsc.47.9.1235.9779","category":"page"},{"location":"decision-programming/computational-complexity/#computational-complexity","page":"Computational Complexity","title":"Computational Complexity","text":"","category":"section"},{"location":"decision-programming/computational-complexity/#Introduction","page":"Computational Complexity","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"Decision programming relies on mixed-integer linear programming, which is known to be an NP-hard problem. In this section, we analyze how the influence diagram affects the size of the mixed-integer linear model, determining whether it is tractable.","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We use the following inequalities for sum and product of non-negative elements A to derive the lower and upper bounds for the number of paths and the number of decision variables. Sum inequality:","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"A left(min_aA aright)  _aA a  A left(max_aA aright)","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"Product inequality:","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"left(min_aA aright)^A  _aA a  left(max_aA aright)^A","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"The following bounds for the number of paths and the number of decision variables show how the number of states, nodes, and arcs affects the size of the model.","category":"page"},{"location":"decision-programming/computational-complexity/#Number-of-Paths","page":"Computational Complexity","title":"Number of Paths","text":"","category":"section"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"From the definition of the influence diagram, we have the path length of n=CD Then, we have the bounds for the number of paths as","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"left(min_iCD S_iright)^n  𝐒  left(max_iCD S_iright)^n","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We assume that all nodes iCD are non-trivial. That is, each decision or chance node has at least two states S_i2 Then, the number of paths is exponential to the path length of n","category":"page"},{"location":"decision-programming/computational-complexity/#Number-of-Decision-Variables","page":"Computational Complexity","title":"Number of Decision Variables","text":"","category":"section"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"We define the number of decision variables as","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"_iD𝐒_I(i)i = _iD _jI(i)iS_j","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"From the definition of the information set, for all iD we have I(i)iCD with size 1I(i)i=I(i)+1mn where m denotes the upper bound of influence other nodes have on any decision node. Also, we have the number of decision nodes 0Dn Thus, we have the bounds","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"0  _iD𝐒_I(i)i  D left(max_iCD S_jright)^m","category":"page"},{"location":"decision-programming/computational-complexity/","page":"Computational Complexity","title":"Computational Complexity","text":"In the worst case, m=n, a decision node is influenced by every other chance and decision node. However, in most practical cases, we have m  n where decision nodes are influenced only by a limited number of other chance and decision nodes, making models easier to solve.","category":"page"},{"location":"decision-programming/paths-and-properties/#paths-and-properties","page":"Paths and Properties","title":"Paths and Properties","text":"","category":"section"},{"location":"decision-programming/paths-and-properties/#Effective-Paths","page":"Paths and Properties","title":"Effective Paths","text":"","category":"section"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"(Image: )","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"It is possible for some combinations of chance or decision states to be unrealizable. We refer to such subpaths as ineffective. For example, the above tree represents the generation of paths where subpaths 𝐒_12^=(22), 𝐒_123^=(112) (121) are ineffective.","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"Formally, the path 𝐬 is ineffective if and only if 𝐬_A𝐒_A^ given ineffective subpaths 𝐒_A^𝐒_A for nodes ACD Then, effective paths is a subset of all paths without ineffective paths","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"𝐒^=𝐬𝐒𝐬_A𝐒_A^𝐒","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"The Decision Model size depends on the number of effective paths, rather than the number of paths or size of the influence diagram directly. If effective paths is empty, the influence diagram has no solutions.","category":"page"},{"location":"decision-programming/paths-and-properties/#Active-Paths","page":"Paths and Properties","title":"Active Paths","text":"","category":"section"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"If the upper bound of path probability is zero, its probability is zero, and it does not affect the solution. Therefore, we can only consider paths with a positive upper bound of path probability. We refer to these paths as active paths. Formally, we define an active path as a path 𝐬 if all of its chance states are active","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"beginaligned\nX(𝐬)(p(𝐬)0)  _jC (ℙ(X_j=𝐬_jX_I(j)=𝐬_I(j))0)\nendaligned","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"Otherwise, it is an inactive path. We denote the set of active paths as","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"𝐒(X)=𝐬𝐒  X(𝐬)","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"The number of active paths is","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"𝐒(X)𝐒","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"Effective paths are related to active paths, such that, for all jC we have ineffective subpaths","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"𝐒_I(j)j^=𝐬_I(j)j𝐒_I(j)j  ℙ(X_j=𝐬_jX_I(j)=𝐬_I(j))=0","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"Generally, we have","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"𝐒^  𝐒(X)","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"If there are no other ineffective subpaths, we have","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"𝐒^ = 𝐒(X)","category":"page"},{"location":"decision-programming/paths-and-properties/#Compatible-Paths","page":"Paths and Properties","title":"Compatible Paths","text":"","category":"section"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"Each decision strategy Zℤ chooses a set of paths from all paths, referred to as compatible paths. Formally, we denote the set of compatible paths as","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"𝐒(Z)=𝐬𝐒  Z(𝐬)","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"Since each local decision strategy Z_jZ can choose only one of its states, the number of compatible paths is","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"𝐒(Z)=𝐒𝐒_D=𝐒_C","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"The compatible paths of all distinct pairs of decision strategies are disjoint. Formally, for all ZZ^ℤ where ZZ^, we have Z(𝐬)Z^(𝐬) which gives as","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"𝐒(Z)𝐒(Z^)=𝐬𝐒Z(𝐬)Z^(𝐬)=","category":"page"},{"location":"decision-programming/paths-and-properties/#Symmetry","page":"Paths and Properties","title":"Symmetry","text":"","category":"section"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"We define the set of active and compatible paths as","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"𝐒(X)𝐒(Z)=𝐬𝐒X(𝐬)Z(𝐬)","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"An influence diagram is symmetric if the number of active and compatible paths is a constant. Formally, if for all ZZ^ℤ where ZZ^ we have","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"𝐒(X)𝐒(Z)=𝐒(X)𝐒(Z^)","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"For example, if all paths are active X(𝐬) we have 𝐒(X)𝐒(Z)=𝐒(Z) which is a constant. Otherwise, the influence diagram is asymmetric. The figures below demonstrate symmetric and asymmetric influence diagrams.","category":"page"},{"location":"decision-programming/paths-and-properties/#Example-1","page":"Paths and Properties","title":"Example 1","text":"","category":"section"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"(Image: )","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"Consider the influence diagram with two nodes. The first is a decision node with two states, and the second is a chance node with three states.","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"(Image: )","category":"page"},{"location":"decision-programming/paths-and-properties/#Example-2","page":"Paths and Properties","title":"Example 2","text":"","category":"section"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"If there are no inactive chance states, all paths are possible. That is, for all sS we have p(s)0 In this case, the influence diagram is symmetric.","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"(Image: )","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"However, if there are inactive chance states, such as ℙ(s_2=2s_1=2)=0, we can remove (22) from the paths, visualized by a dashed shape. Therefore, there is a varying number of possible paths depending on whether the decision-maker chooses state s_1=1 or s_1=2 in the first node, and the influence diagram is asymmetric.","category":"page"},{"location":"decision-programming/paths-and-properties/#Example-3","page":"Paths and Properties","title":"Example 3","text":"","category":"section"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"(Image: )","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"Let us add one chance node with two states to the influence diagram.","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"(Image: )","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"Now, given inactive chance states such that we remove the dashed paths, we have a symmetric influence diagram. Both decisions will have an equal number of possible paths. However, there are only eight possible paths instead of twelve if there were no inactive chance states.","category":"page"},{"location":"decision-programming/paths-and-properties/#Other-Properties","page":"Paths and Properties","title":"Other Properties","text":"","category":"section"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"In this section, we define more properties for influence diagrams.","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"Discrete influence diagram refers to countable state space. Otherwise, the influence diagram is continuous. We can discretize continuous influence diagrams using discrete bins.","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"Two nodes are sequential if there exists a directed path from one node to the other in the influence diagram. Otherwise, the nodes are parallel. Sequential nodes often model time dimension.","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"Repeated subdiagram refers to a recurring pattern within an influence diagram. Often, influence diagrams do not have a unique structure, but they consist of a repeated pattern due to the underlying problem's properties.","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"Limited-memory influence diagram refers to an influence diagram where an upper bound limits the size of the information set for decision nodes. That is, I(j)m for all jD where the limit m is less than CD Smaller limits of m are desirable because they reduce the decision model size, as discussed in the Computational Complexity page.","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"Isolated subdiagrams refer to an influence diagram that consists of multiple unconnected diagrams. That is, there are no undirected connections between the diagrams. Therefore, one isolated subdiagram's decisions affect decisions on the other isolated subdiagrams only through the utility function.","category":"page"},{"location":"decision-programming/paths-and-properties/","page":"Paths and Properties","title":"Paths and Properties","text":"Chance or decision node is redundant if it is a leaf node and not in any value node's information set. Formally, if jCD is a leaf node and there does not exist a value node iV such that jI(i)","category":"page"},{"location":"examples/CHD_preventative_care/#CHD-preventative-care-allocation","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"","category":"section"},{"location":"examples/CHD_preventative_care/#Description","page":"CHD preventative care allocation","title":"Description","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The goal in this optimisation problem is to determine an optimal decision strategy for the testing and treatment decisions involved in providing preventative care for coronary heart disease (CHD). The optimality is evaluated from the perspective of the national health care system and is measured in quality-adjusted life-years (QALY). The tests available in this model are the traditional risk score (TRS) and the genetic risk score (GRS) and the form of preventative care is statin treatment. The description of the CHD preventative care allocation problem is below. This description is from [1] from section 3.2.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The problem setting is such that the patient is assumed to have a prior risk estimate. A risk estimate is a prediction of the patient’s chance of having a CHD event in the next ten years. The risk estimates are grouped into risk levels, which range from 0% to 100%. The first testing decision is made based on the prior risk estimate. The first testing decision entails deciding whether TRS or GRS should be performed or if no testing is needed. If a test is conducted, the risk estimate is updated and based on the new information, the second testing decision is made. The second testing decision entails deciding whether further testing should be conducted or not. The second testing decision is constrained so that the same test which was conducted in the first stage cannot be repeated. If a second test is conducted, the risk estimate is updated again. The treatment decision – dictating whether the patient receives statin therapy or not – is made based on the resulting risk estimate of this testing process. Note that if no tests are conducted, the treatment decision is made based on the prior risk estimate.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"In this example, we will showcase the subproblem, which optimises the decision strategy given a single prior risk level. The chosen risk level in this example is 12%. The solution to the main problem is found in [1].","category":"page"},{"location":"examples/CHD_preventative_care/#Influence-Diagram","page":"CHD preventative care allocation","title":"Influence Diagram","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"(Image: )","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The influence diagram representation of the problem is seen above. The chance nodes R represent the patient's risk estimate – the prior risk estimate being R0. The risk estimate nodes R0, R1 and R2 have 101 states R = 0 1  100, which are the discretised risk levels for the risk estimates.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The risk estimate is updated according to the first and second test decisions, which are represented by decision nodes T1 and T2. These nodes have states T = textTRS GRS no test. The health of the patient represented by chance node H also affects the update of the risk estimate. In this model, the health of the patient indicates whether they will have a CHD event in the next ten years or not. Thus, the node has states H = textCHD no CHD. The treatment decision is represented by node TD and it has states TD = texttreatment no treatment.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The prior risk estimate represented by node R0 influences the health node H, because in the model we make the assumption that the prior risk estimate accurately describes the probability of having a CHD event.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The value nodes in the model are TC and HB. Node TC represents the testing costs incurred due to the testing decisions T1 and T2. Node HB represents the health benefits achieved. The testing costs and health benefits are measured in QALYs. These parameter values were evaluated in the study [2].","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We begin by declaring the chosen prior risk level and reading the conditional probability data for the tests. The risk level 12% is referred to as 13 because indexing begins from 1 and the first risk level is 0\\%. Note also that the sample data in this repository is dummy data due to distribution restrictions on the real data. We also define functions update_risk_distribution, state_probabilities and analysing_results. These functions will be discussed in the following sections.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"using Logging\nusing JuMP, Gurobi\nusing DecisionProgramming\nusing CSV, DataFrames, PrettyTables\n\n\nconst chosen_risk_level = 13\nconst data = CSV.read(\"risk_prediction_data.csv\", DataFrame)\n\nfunction update_risk_distribution(prior::Int64, t::Int64)...\nend\n\nfunction state_probabilities(risk_p::Array{Float64}, t::Int64, h::Int64, prior::Int64)...\nend\n\nfunction analysing_results(Z::DecisionStrategy, sprobs::StateProbabilities)...\nend","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"Then we begin defining the decision programming model. First, we define the node indices and states:","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"const R0 = 1\nconst H  = 2\nconst T1 = 3\nconst R1 = 4\nconst T2 = 5\nconst R2 = 6\nconst TD = 7\nconst TC = 8\nconst HB = 9\n\n\nconst H_states = [\"CHD\", \"no CHD\"]\nconst T_states = [\"TRS\", \"GRS\", \"no test\"]\nconst TD_states = [\"treatment\", \"no treatment\"]\nconst R_states = map( x -> string(x) * \"%\", [0:1:100;])\nconst TC_states = [\"TRS\", \"GRS\", \"TRS & GRS\", \"no tests\"]\nconst HB_states = [\"CHD & treatment\", \"CHD & no treatment\", \"no CHD & treatment\", \"no CHD & no treatment\"]\n\n@info(\"Creating the influence diagram.\")\nS = States([\n    (length(R_states), [R0, R1, R2]),\n    (length(H_states), [H]),\n    (length(T_states), [T1, T2]),\n    (length(TD_states), [TD])\n])\n\nC = Vector{ChanceNode}()\nD = Vector{DecisionNode}()\nV = Vector{ValueNode}()\nX = Vector{Probabilities}()\nY = Vector{Consequences}()","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"Next, we define the nodes with their information sets and corresponding probabilities for chance nodes and consequences for value nodes.","category":"page"},{"location":"examples/CHD_preventative_care/#Prior-risk-estimate-and-health-of-the-patient","page":"CHD preventative care allocation","title":"Prior risk estimate and health of the patient","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"In this subproblem, the prior risk estimate is given and therefore the node R0 is in effect a deterministic node. In decision programming a deterministic node is added as a chance node for which the probability of one state is set to one and the probabilities of the rest of the states are set to zero. In this case","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"ℙ(R0 = 12)=1","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"and $ℙ(R0 \\neq 12\\%)= 0. $","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"Notice also that node R0 is the first node in the influence diagram, meaning that its information set I(R0) is empty. In decision programming we add node R0 and its state probabilities as follows:","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"I_R0 = Vector{Node}()\nX_R0 = zeros(S[R0])\nX_R0[chosen_risk_level] = 1\npush!(C, ChanceNode(R0, I_R0))\npush!(X, Probabilities(R0, X_R0))","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"Next we add node H and its state probabilities. For modeling purposes, we define the information set of node H to include the prior risk node R0. We set the probability of the patient experiencing a CHD event in the next ten years according to the prior risk level such that","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"ℙ(H = textCHD  R0 = alpha) = alpha","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We define the probability of the patient not experiencing a CHD event in the next ten years as the complement event.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"ℙ(H = textno CHD  R0 = alpha) = 1 - alpha","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"Since node R0 is actually deterministic, defining the health node H in this way means that in the our model the patient has 12% probability of experiencing a CHD event and 88% chance of not suffering one.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"Node H and its probabilities are added in the following way.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"I_H = [R0]\nX_H = zeros(S[R0], S[H])\nX_H[:, 1] = data.risk_levels\nX_H[:, 2] = 1 .- X_H[:, 1]\npush!(C, ChanceNode(H, I_H))\npush!(X, Probabilities(H, X_H))","category":"page"},{"location":"examples/CHD_preventative_care/#Test-decisions-and-updating-the-risk-estimate","page":"CHD preventative care allocation","title":"Test decisions and updating the risk estimate","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The node representing the first test decision is added to the model in the following way.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"I_T1 = [R0]\npush!(D, DecisionNode(T1, I_T1))","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The probabilities of the states of node R1 are determined by calculating the updated risk estimates after a test is performed and aggregating these probabilities into the risk levels. The update of the risk estimate is calculated using the function update_risk_distribution, which calculates the posterior probability distribution for a given health state, test and prior risk estimate.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"$","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"\\textit{risk estimate} = P(\\text{CHD} \\mid \\text{test result}) = \\frac{P(\\text{test result} \\mid \\text{CHD})P(\\text{CHD})}{P(\\text{test result})}$","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The probabilities P(texttest result mid textCHD) are test specific and these are read from the CSV data file. The updated risk estimates are aggregated according to the risk levels. These aggregated probabilities are then the state probabilities of node R1. The aggregating is done using function state_probabilities.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The node R1 and its probabilities are added in the following way.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"I_R1 = [R0, H, T1]\nX_R1 = zeros(S[I_R1]..., S[R1])\nfor s_R0 = 1:101, s_H = 1:2, s_T1 = 1:3\n    X_R1[s_R0, s_H, s_T1, :] =  state_probabilities(update_risk_distribution(s_R0, s_T1), s_T1, s_H, s_R0)\nend\npush!(C, ChanceNode(R1, I_R1))\npush!(X, Probabilities(R1, X_R1))","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"Now we add node T2 and node R2 in a similar fashion as we added T1 and R1 above.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"I_T2 = [R1]\npush!(D, DecisionNode(T2, I_T2))\n\n\nI_R2 = [H, R1, T2]\nX_R2 = zeros(S[I_R2]..., S[R2])\nfor s_R1 = 1:101, s_H = 1:2, s_T2 = 1:3\n    X_R2[s_H, s_R1, s_T2, :] =  state_probabilities(update_risk_distribution(s_R1, s_T2), s_T2, s_H, s_R1)\nend\npush!(C, ChanceNode(R2, I_R2))\npush!(X, Probabilities(R2, X_R2))","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We also add the treatment decision node TD. The treatment decision is made based on the resulting risk estimate of the testing process.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"I_TD = [R2]\npush!(D, DecisionNode(TD, I_TD))","category":"page"},{"location":"examples/CHD_preventative_care/#Test-costs-and-health-benefits","page":"CHD preventative care allocation","title":"Test costs and health benefits","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"To add the value node TC, which represents testing costs, we need to define the consequences of its different information states. The node and the consequences are added in the following way.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"I_TC = [T1, T2]\nY_TC = zeros(S[I_TC]...)\ncost_TRS = -0.0034645\ncost_GRS = -0.004\ncost_forbidden = 0     #the cost of forbidden test combinations is negligible\nY_TC[1 , 1] = cost_forbidden\nY_TC[1 , 2] = cost_TRS + cost_GRS\nY_TC[1, 3] = cost_TRS\nY_TC[2, 1] =  cost_GRS + cost_TRS\nY_TC[2, 2] = cost_forbidden\nY_TC[2, 3] = cost_GRS\nY_TC[3, 1] = cost_TRS\nY_TC[3, 2] = cost_GRS\nY_TC[3, 3] = 0\npush!(V, ValueNode(TC, I_TC))\npush!(Y, Consequences(TC, Y_TC))","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"The health benefits achieved by the strategy are dictated by whether treatment is administered and by the health of the patient. We add the final node to the model.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"I_HB = [H, TD]\nY_HB = zeros(S[I_HB]...)\nY_HB[1 , 1] = 6.89713671259061  # sick & treat\nY_HB[1 , 2] = 6.65436854256236  # sick & don't treat\nY_HB[2, 1] = 7.64528451705134   # healthy & treat\nY_HB[2, 2] =  7.70088349200034  # healthy & don't treat\npush!(V, ValueNode(HB, I_HB))\npush!(Y, Consequences(HB, Y_HB))","category":"page"},{"location":"examples/CHD_preventative_care/#Validating-Influence-Diagram","page":"CHD preventative care allocation","title":"Validating Influence Diagram","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"Before creating the decision model, we need to validate the influence diagram and sort the nodes, probabilities and consequences in increasing order by the node indices.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"validate_influence_diagram(S, C, D, V)\nsort!.((C, D, V, X, Y), by = x -> x.j)","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We also define the path probability and the path utility. We use the default path utility, which is the sum of the consequences of the path.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"P = DefaultPathProbability(C, X)\nU = DefaultPathUtility(V, Y)","category":"page"},{"location":"examples/CHD_preventative_care/#Decision-Model","page":"CHD preventative care allocation","title":"Decision Model","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We begin by defining our model and declaring the decision variables.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"model = Model()\nz = DecisionVariables(model, S, D)","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"In this problem, we want to forbid the model from choosing paths where the same test is repeated twice and the paths where the first testing decision is to not perform a test but then the second testing decision is to conduct a test. We forbid the paths by declaring these combinations of states as forbidden paths and then giving them to the function that declares the path probability variables.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We also choose a scale factor of 1000, which will be used to scale the path probabilities. The probabilities need to be scaled because in this specific problem they are very small since the R nodes have many states. Scaling the probabilities helps the solver find an optimal solution.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We declare the path probability variables and give the forbidden testing strategies and the scale factor to the function as additional information.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"forbidden_tests = ForbiddenPath[([T1,T2], Set([(1,1),(2,2),(3,1),(3,2)]))]\nscale_factor = 1000.0\nπ_s = PathProbabilityVariables(model, z, S, P; hard_lower_bound = true, forbidden_paths = forbidden_tests, probability_scale_factor = scale_factor)","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We define the objective function as the expected value.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"EV = expected_value(model, π_s, U)\n@objective(model, Max, EV)","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We set up the solver for the problem and optimise it. ","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"optimizer = optimizer_with_attributes(\n    () -> Gurobi.Optimizer(Gurobi.Env()),\n    \"TimeLimit\" => 100,\n    \"IntFeasTol\"=> 1e-9,\n    \"MIPGap\" => 1e-6\n)\nset_optimizer(model, optimizer)\noptimize!(model)","category":"page"},{"location":"examples/CHD_preventative_care/#Analyzing-Results","page":"CHD preventative care allocation","title":"Analyzing Results","text":"","category":"section"},{"location":"examples/CHD_preventative_care/#Decision-Strategy","page":"CHD preventative care allocation","title":"Decision Strategy","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We obtain the optimal decision strategy from the z variable values.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"Z = DecisionStrategy(z)","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We use the function analysing_results to visualise the results in order to inspect the decision strategy. We use this tailor made function merely for convinience. From the printout, we can see that when the prior risk level is 12% the optimal decision strategy is to first perform TRS testing. At the second decision stage, GRS should be conducted if the updated risk estimate is between 16% and 28% and otherwise no further testing should be conducted. Treatment should be provided to those who have a final risk estimate greater than 18%. Notice that the blank spaces in the table are states which have a probability of zero, which means that given this data it is impossible for the patient to have their risk estimate updated to those risk levels.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"sprobs = StateProbabilities(S, P, Z)","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"julia> println(analysing_results(Z, sprobs))\n┌─────────────────┬────────┬────────┬────────┐\n│ Information_set │     T1 │     T2 │     TD │\n│          String │ String │ String │ String │\n├─────────────────┼────────┼────────┼────────┤\n│              0% │        │      3 │      2 │\n│              1% │        │      3 │      2 │\n│              2% │        │        │      2 │\n│              3% │        │      3 │      2 │\n│              4% │        │        │        │\n│              5% │        │        │        │\n│              6% │        │      3 │      2 │\n│              7% │        │      3 │      2 │\n│              8% │        │        │      2 │\n│              9% │        │        │      2 │\n│             10% │        │      3 │      2 │\n│             11% │        │      3 │      2 │\n│             12% │      1 │        │      2 │\n│             13% │        │      3 │      2 │\n│             14% │        │      3 │      2 │\n│             15% │        │        │      2 │\n│             16% │        │      2 │      2 │\n│             17% │        │      2 │      2 │\n│             18% │        │      2 │      1 │\n│             19% │        │        │      1 │\n│             20% │        │        │      1 │\n│             21% │        │      2 │      1 │\n│             22% │        │      2 │      1 │\n│             23% │        │      2 │      1 │\n│             24% │        │        │      1 │\n│             25% │        │        │      1 │\n│             26% │        │        │      1 │\n│             27% │        │        │      1 │\n│             28% │        │      3 │      1 │\n│             29% │        │      3 │      1 │\n│             30% │        │        │      1 │\n│        ⋮        │   ⋮     │   ⋮    │   ⋮    │\n└─────────────────┴────────┴────────┴────────┘\n                               70 rows omitted","category":"page"},{"location":"examples/CHD_preventative_care/#Utility-Distribution","page":"CHD preventative care allocation","title":"Utility Distribution","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"We can also print the utility distribution for the optimal strategy and some basic statistics for the distribution.","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"udist = UtilityDistribution(S, P, U, Z)","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"julia> print_utility_distribution(udist)\n┌──────────┬─────────────┐\n│  Utility │ Probability │\n│  Float64 │     Float64 │\n├──────────┼─────────────┤\n│ 6.646904 │    0.005318 │\n│ 6.650904 │    0.038707 │\n│ 6.889672 │    0.011602 │\n│ 6.893672 │    0.064374 │\n│ 7.637820 │    0.034188 │\n│ 7.641820 │    0.073974 │\n│ 7.693419 │    0.035266 │\n│ 7.697419 │    0.736573 │\n└──────────┴─────────────┘","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"julia> print_statistics(udist)\n┌──────────┬────────────┐\n│     Name │ Statistics │\n│   String │    Float64 │\n├──────────┼────────────┤\n│     Mean │   7.583923 │\n│      Std │   0.291350 │\n│ Skewness │  -2.414877 │\n│ Kurtosis │   4.059711 │\n└──────────┴────────────┘","category":"page"},{"location":"examples/CHD_preventative_care/#References","page":"CHD preventative care allocation","title":"References","text":"","category":"section"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"[1]: Hankimaa H. (2021). Optimising the use of genetic testing in prevention of CHD using Decision Programming. http://urn.fi/URN:NBN:fi:aalto-202103302644","category":"page"},{"location":"examples/CHD_preventative_care/","page":"CHD preventative care allocation","title":"CHD preventative care allocation","text":"[2]: Hynninen Y. (2019). Value of genetic testing in the prevention of coronary heart disease events. PLOS ONE, 14(1):1–16. https://doi.org/10.1371/journal.pone.0210010","category":"page"},{"location":"examples/contingent-portfolio-programming/#Contingent-Portfolio-Programming","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/#Description","page":"Contingent Portfolio Programming","title":"Description","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"[1], section 4.2","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"For instance, assume that the first-stage decisions specify which technology development projects will be started to generate patent-based intellectual property ( P ) for a platform. This intellectual property contributes subject to some uncertainties to the technical competitiveness ( T ) of the platform. In the second stage, it is possible to carry out application ( A ) development projects which, when completed, yield cash flows that depend on the market share of the platform. This market share ( M ) depends on the competitiveness of the platform and the number of developed applications. The aim is to maximize the cash flows from application projects less the cost of technology and application development projects.","category":"page"},{"location":"examples/contingent-portfolio-programming/#Influence-Diagram:-Projects","page":"Contingent Portfolio Programming","title":"Influence Diagram: Projects","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"(Image: )","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"The influence diagram of the contingent portfolio programming (CPP) problem.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"There are n_T technology development projects and n_A application development projects.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Decision states to develop patents","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"d_i^PD_i^P=q_1^P q_2^P) q_2^P q_3^P)  q_D^P^P q_D^P+1^P)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Chance states of technical competitiveness c_j^TC_j^T","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Decision states to develop applications","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"d_k^AD^A=q_1^A q_2^A) q_2^A q_3^A)  q_D^A^A q_D^A+1^A)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Chance states of market size c_l^MC_l^M","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"using Logging, Random\nusing JuMP, Gurobi\nusing DecisionProgramming\n\nRandom.seed!(42)\n\nconst dᴾ = 1    # Decision node: range for number of patents\nconst cᵀ = 2    # Chance node:   technical competitiveness\nconst dᴬ = 3    # Decision node: range for number of applications\nconst cᴹ = 4    # Chance node:   market share\nconst DP_states = [\"0-3 patents\", \"3-6 patents\", \"6-9 patents\"]\nconst CT_states = [\"low\", \"medium\", \"high\"]\nconst DA_states = [\"0-5 applications\", \"5-10 applications\", \"10-15 applications\"]\nconst CM_states = [\"low\", \"medium\", \"high\"]\n\nS = States([\n    (length(DP_states), [dᴾ]),\n    (length(CT_states), [cᵀ]),\n    (length(DA_states), [dᴬ]),\n    (length(CM_states), [cᴹ]),\n])\nC = Vector{ChanceNode}()\nD = Vector{DecisionNode}()\nV = Vector{ValueNode}()\nX = Vector{Probabilities}()\nY = Vector{Consequences}()","category":"page"},{"location":"examples/contingent-portfolio-programming/#Decision-on-range-of-number-of-patents","page":"Contingent Portfolio Programming","title":"Decision on range of number of patents","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"I_DP = Vector{Node}()\npush!(D, DecisionNode(dᴾ, I_DP))","category":"page"},{"location":"examples/contingent-portfolio-programming/#Technical-competitiveness-probability","page":"Contingent Portfolio Programming","title":"Technical competitiveness probability","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Probability of technical competitiveness c_j^T given the range d_i^P: ℙ(c_j^Td_i^P)01. A high number of patents increases probability of high competitiveness and a low number correspondingly increases the probability of low competitiveness.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"I_CT = [dᴾ]\nX_CT = zeros(S[dᴾ], S[cᵀ])\nX_CT[1, :] = [1/2, 1/3, 1/6]\nX_CT[2, :] = [1/3, 1/3, 1/3]\nX_CT[3, :] = [1/6, 1/3, 1/2]\npush!(C, ChanceNode(cᵀ, I_CT))\npush!(X, Probabilities(cᵀ, X_CT))","category":"page"},{"location":"examples/contingent-portfolio-programming/#Decision-on-range-of-number-of-applications","page":"Contingent Portfolio Programming","title":"Decision on range of number of applications","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"I_DA = [dᴾ, cᵀ]\npush!(D, DecisionNode(dᴬ, I_DA))","category":"page"},{"location":"examples/contingent-portfolio-programming/#Market-share-probability","page":"Contingent Portfolio Programming","title":"Market share probability","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Probability of market share c_l^M given the technical competitiveness c_j^T and range d_k^A: ℙ(c_l^Mc_j^Td_k^A)01. Higher competitiveness and number of application projects both increase the probability of high market share.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"I_CM = [cᵀ, dᴬ]\nX_CM = zeros(S[cᵀ], S[dᴬ], S[cᴹ])\nX_CM[1, 1, :] = [2/3, 1/4, 1/12]\nX_CM[1, 2, :] = [1/2, 1/3, 1/6]\nX_CM[1, 3, :] = [1/3, 1/3, 1/3]\nX_CM[2, 1, :] = [1/2, 1/3, 1/6]\nX_CM[2, 2, :] = [1/3, 1/3, 1/3]\nX_CM[2, 3, :] = [1/6, 1/3, 1/2]\nX_CM[3, 1, :] = [1/3, 1/3, 1/3]\nX_CM[3, 2, :] = [1/6, 1/3, 1/2]\nX_CM[3, 3, :] = [1/12, 1/4, 2/3]\npush!(C, ChanceNode(cᴹ, I_CM))\npush!(X, Probabilities(cᴹ, X_CM))","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"We add a dummy value node to avoid problems with the influence diagram validation. Without this, the final chance node would be seen as redundant.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"push!(V, ValueNode(5, [cᴹ]))\npush!(Y,Consequences(5, zeros(S[cᴹ])))","category":"page"},{"location":"examples/contingent-portfolio-programming/#Validating-the-Influence-Diagram","page":"Contingent Portfolio Programming","title":"Validating the Influence Diagram","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"validate_influence_diagram(S, C, D, V)\nsort!.((C, D, V, X, Y), by = x -> x.j)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"P = DefaultPathProbability(C, X)","category":"page"},{"location":"examples/contingent-portfolio-programming/#Decision-Model:-Portfolio-Selection","page":"Contingent Portfolio Programming","title":"Decision Model: Portfolio Selection","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"model = Model()\nz = DecisionVariables(model, S, D)\nπ_s = PathProbabilityVariables(model, z, S, P)","category":"page"},{"location":"examples/contingent-portfolio-programming/#Creating-problem-specific-variables","page":"Contingent Portfolio Programming","title":"Creating problem specific variables","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"We recommend reading Section 4.2. in [1] for motivation and details of the formulation.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Technology project t costs I_tℝ^+ and generates O_tℕ patents.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Application project a costs I_aℝ^+ and generates O_aℕ applications. If completed, provides cash flow V(ac_l^M)ℝ^+","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"n_T = 5                     # number of technology projects\nn_A = 5                     # number of application projects\nI_t = rand(n_T)*0.1         # costs of technology projects\nO_t = rand(1:3,n_T)         # number of patents for each tech project\nI_a = rand(n_T)*2           # costs of application projects\nO_a = rand(2:4,n_T)         # number of applications for each appl. project\n\nV_A = rand(S[cᴹ], n_A).+0.5 # Value of an application\nV_A[1, :] .+= -0.5          # Low market share: less value\nV_A[3, :] .+= 0.5           # High market share: more value","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Decision variables x^T(t)0 1 indicate which technologies are selected.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Decision variables x^A(ad_i^Pc_j^T)0 1 indicate which applications are selected.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"x_T = variables(model, [S[dᴾ]...,n_T]; binary=true)\nx_A = variables(model, [S[dᴾ]...,S[cᵀ]...,S[dᴬ]..., n_A]; binary=true)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Number of patents x^T(t) = _i x_i^T(t) z(d_i^P)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Number of applications x^A(ad_i^Pc_j^T) = _k x_k^A(ad_i^Pc_j^T) z(d_k^Ad_i^Pc_j^T)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Helpful variables:","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Large constant M (e.g. frac32textmaxsum_t O_tsum_a O_a)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Small constant varepsilon = frac12textminO_t O_a","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"M = 20                      # a large constant\nε = 0.5*minimum([O_t O_a])  # a helper variable, allows using ≤ instead of < in constraints (28b) and (29b)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Limits q_i^P and q_k^A of the intervals","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"q_P = [0, 3, 6, 9]          # limits of the technology intervals\nq_A = [0, 5, 10, 15]        # limits of the application intervals","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Shorthand for the decision variables z","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"z_dP = z[1]\nz_dA = z[2]","category":"page"},{"location":"examples/contingent-portfolio-programming/#Creating-problem-specific-constraints","page":"Contingent Portfolio Programming","title":"Creating problem specific constraints","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"_t x_i^T(t) le z(d_i^P)n_T quad forall i","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:3],\n    sum(x_T[i,t] for t in 1:n_T) <= z_dP[i]*n_T)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"_a x_k^A(ad_i^Pc_j^T) le z(d_i^P)n_A quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:3, j=1:3, k=1:3],\n    sum(x_A[i,j,k,a] for a in 1:n_A) <= z_dP[i]*n_A)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"_a x_k^A(ad_i^Pc_j^T) le z(d_k^Ad_i^Pc_j^T)n_A quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:3, j=1:3, k=1:3],\n    sum(x_A[i,j,k,a] for a in 1:n_A) <= z_dA[i,j,k]*n_A)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"q_i^P - (1-z(d_i^P))M le sum_t x_i^T(t)O_t le q_i+1^P + (1-z(d_i^P))M - varepsilon quad forall i","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:3],\n    q_P[i] - (1 - z_dP[i])*M <= sum(x_T[i,t]*O_t[t] for t in 1:n_T))\n@constraint(model, [i=1:3],\n    sum(x_T[i,t]*O_t[t] for t in 1:n_T) <= q_P[i+1] + (1 - z_dP[i])*M - ε)\n","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"q_k^A - (1-z(d_k^Ad_i^Pc_j^T))M le sum_a x_k^A(ad_i^Pc_j^T)O_a le q_k+1^A + (1-z(d_k^Ad_i^Pc_j^T))M - varepsilon quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:3, j=1:3, k=1:3],\n    q_A[k] - (1 - z_dA[i,j,k])*M <= sum(x_A[i,j,k,a]*O_a[a] for a in 1:n_A))\n@constraint(model, [i=1:3, j=1:3, k=1:3],\n    sum(x_A[i,j,k,a]*O_a[a] for a in 1:n_A) <= q_A[k+1] + (1 - z_dA[i,j,k])*M - ε)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"We can also model dependencies between the technology and application projects, e.g. application project a can be completed only if technology project t has been completed. This is done by adding constraints","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"x_k^A(ad_i^Pc_j^T) le x_i^T(t) quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"As an example, we state that application projects 1 and 2 require technology project 1, and application project 2 also requires technology project 2.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"@constraint(model, [i=1:3, j=1:3, k=1:3], x_A[i,j,k,1] <= x_T[i,1])\n@constraint(model, [i=1:3, j=1:3, k=1:3], x_A[i,j,k,2] <= x_T[i,1])\n@constraint(model, [i=1:3, j=1:3, k=1:3], x_A[i,j,k,2] <= x_T[i,2])","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"x_i^T(t)0 1 quad forall i","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"x_k^A(ad_i^Pc_j^T)0 1 quad forall ijk","category":"page"},{"location":"examples/contingent-portfolio-programming/#Path-Utility","page":"Contingent Portfolio Programming","title":"Path Utility","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"mathcalU(s) = sum_a x_k^A(ad_i^Pc_j^T) (V(ac_l^M) - I_a) - _t x_i^T(t) I_t","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"struct PathUtility <: AbstractPathUtility\n    expr\nend\n(U::PathUtility)(s::Path) = value.(U.expr[s])\n\nU = PathUtility(@expression(model, [s = paths(S)],\n    sum(x_A[s[1:3]..., a]*(V_A[s[4],a] - I_a[a]) for a in 1:n_A) -\n    sum(x_T[s[1],t]*I_t[t] for t in 1:n_T)))\n\nEV = @expression(model, sum(π_s[s...] * U.expr[s] for s in paths(S)))\n@objective(model, Max, EV)","category":"page"},{"location":"examples/contingent-portfolio-programming/#Solving-the-Model","page":"Contingent Portfolio Programming","title":"Solving the Model","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"optimizer = optimizer_with_attributes(\n    () -> Gurobi.Optimizer(Gurobi.Env()),\n    \"IntFeasTol\"      => 1e-9,\n    \"LazyConstraints\" => 1,\n)\nset_optimizer(model, optimizer)\noptimize!(model)","category":"page"},{"location":"examples/contingent-portfolio-programming/#Analyzing-results","page":"Contingent Portfolio Programming","title":"Analyzing results","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"The optimal decision strategy and the utility distribution are printed. The strategy is to make 6-9 patents (state 3 in node 1) and 5-10 applications if the competitiveness is low, 10-15 otherwise. The expected utility for this strategy is 0.41.","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"Z = DecisionStrategy(z)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"julia> print_decision_strategy(S, Z)\n┌────────┬────┬───┐\n│  Nodes │ () │ 1 │\n├────────┼────┼───┤\n│ States │ () │ 3 │\n└────────┴────┴───┘\n┌────────┬────────┬───┐\n│  Nodes │ (1, 2) │ 3 │\n├────────┼────────┼───┤\n│ States │ (1, 1) │ 1 │\n│ States │ (2, 1) │ 1 │\n│ States │ (3, 1) │ 2 │\n│ States │ (1, 2) │ 1 │\n│ States │ (2, 2) │ 1 │\n│ States │ (3, 2) │ 3 │\n│ States │ (1, 3) │ 1 │\n│ States │ (2, 3) │ 1 │\n│ States │ (3, 3) │ 3 │\n│   ⋮    │   ⋮    │ ⋮ │\n└────────┴────────┴───┘","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"udist = UtilityDistribution(S, P, U, Z)","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"julia> print_utility_distribution(udist)\n┌───────────┬─────────────┐\n│   Utility │ Probability │\n│   Float64 │     Float64 │\n├───────────┼─────────────┤\n│ -2.164246 │    0.097222 │\n│ -0.759404 │    0.083333 │\n│ -0.077398 │    0.236111 │\n│  0.258058 │    0.055556 │\n│  0.505004 │    0.027778 │\n│  1.342020 │    0.500000 │\n└───────────┴─────────────┘","category":"page"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"julia> print_statistics(udist)\n┌──────────┬────────────┐\n│     Name │ Statistics │\n│   String │    Float64 │\n├──────────┼────────────┤\n│     Mean │   0.407403 │\n│      Std │   1.118111 │\n│ Skewness │  -1.004935 │\n│ Kurtosis │   0.071940 │\n└──────────┴────────────┘","category":"page"},{"location":"examples/contingent-portfolio-programming/#References","page":"Contingent Portfolio Programming","title":"References","text":"","category":"section"},{"location":"examples/contingent-portfolio-programming/","page":"Contingent Portfolio Programming","title":"Contingent Portfolio Programming","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#analyzing-decision-strategies","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/#Introduction","page":"Analyzing Decision Strategies","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"This section focuses on how we can analyze fixed decision strategies Z on an influence diagram G, such as ones resulting from the optimization. We can rule out all incompatible paths from the analysis because their path probability is zero, by only generating the compatible paths 𝐬𝐒(Z) However, compatible paths may still contain inactive paths if the influence diagram contains inactive chance states. The other property of compatible paths is that their path probability is equal to the upper bound p(𝐬)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#Generating-Compatible-Paths","page":"Analyzing Decision Strategies","title":"Generating Compatible Paths","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We can generate compatible paths 𝐬𝐒(Z) as follows.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"Initialize path 𝐬 of length n with undefined values.\nFill path with chance states 𝐬_jS_j for all jC\nIn increasing order of decision nodes jD, fill decision states by computing decision strategy 𝐬_j=Z_j(𝐬_I(j))","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#Utility-Distribution","page":"Analyzing Decision Strategies","title":"Utility Distribution","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We define unique path utility values as","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"mathcalU^=mathcalU(𝐬)𝐬𝐒(Z)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The probability mass function of the utility distribution associates each unique path utility to a probability as follows","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(X=u)=_𝐬𝐒(Z)mathcalU(𝐬)=u p(𝐬)quad umathcalU^","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"From the utility distribution, we can calculate the cumulative distribution, statistics, and risk measures. The relevant statistics are expected value, standard deviation, skewness and kurtosis. Risk measures focus on the conditional value-at-risk (CVaR), also known as, expected shortfall.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#Measuring-Risk","page":"Analyzing Decision Strategies","title":"Measuring Risk","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"(Image: )","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We have a discrete probability distribution f(x)=ℙ(X=x)0 1 over the domain xΩ with _xΩℙ(X=x)=1 and its cumulative distribution function F(x) = _x^Ωx^xf(x^) We define the expected value as","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"E(X)=_xΩ x  f(x)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We present the concept of conditional value-at-risk, a risk measure of the conditional expected value of the tail of a probability distribution for a given probability level of α0 1 First, we define the value-at-risk as","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"operatornameVaR_α(X) = x_α = minxΩ  F(x)  α","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"It is the smallest value x such that the cumulative probability is equal or above α Then, we define the conditional value-at-risk as","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"operatornameCVaR_α(X)=textcolordarkorangefrac1α left(textcolordarkred_xx_α x  f(x) textcolordarkblue- left(_xx_α f(x) - αright) x_α right)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The red part measures the conditional expected value of the tail distribution. The blue part corrects the expected value by subtracting the amount of expected value that is between probability level α and F(x_α) and orange part divides by the total probability.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"Value-at-risk and conditional value-at-risk are monotonically increasing functions. Therefore, the lower bound is the value at α=0 and the upper bound is the value at α=1 For value-at-risk, we have","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"operatornameVaR_0(X) = min xΩ","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"operatornameVaR_1(X) = max xΩ","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"For conditional value-at-risk, we have","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"lim_α0 operatornameCVaR_α(X) = operatornameVaR_0(X)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"operatornameCVaR_1(X) = E(X)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The above figure demonstrates these values on a discrete probability distribution.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/#State-Probabilities","page":"Analyzing Decision Strategies","title":"State Probabilities","text":"","category":"section"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We denote paths with fixed states where ϵ denotes an empty state using a recursive definition.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"beginaligned\n𝐒_ϵ = 𝐒(Z) \n𝐒_ϵs_i = 𝐬𝐒_ϵ  𝐬_i=s_i \n𝐒_ϵs_is_j = 𝐬𝐒_ϵs_i  𝐬_j=s_jquad ji\nendaligned","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"The probability of all paths sums to one","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(ϵ) = sum_𝐬𝐒_ϵ p(𝐬) = 1","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"State probabilities for each node iCD and state s_iS_i denote how likely the state occurs given all path probabilities","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(s_iϵ) = sum_𝐬𝐒_ϵs_i fracp(𝐬)ℙ(ϵ) = sum_𝐬𝐒_ϵs_i p(𝐬)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"An active state is a state with positive state probability ℙ(s_ic)0 given conditions c","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We can generalize the state probabilities as conditional probabilities using a recursive definition. Generalized state probabilities allow us to explore how fixing active states affect the probabilities of other states. First, we choose an active state s_i and fix its value. Fixing an inactive state would make all state probabilities zero. Then, we can compute the conditional state probabilities as follows.","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"ℙ(s_jϵs_i) = sum_𝐬𝐒_ϵs_is_j fracp(𝐬)ℙ(s_iϵ)","category":"page"},{"location":"decision-programming/analyzing-decision-strategies/","page":"Analyzing Decision Strategies","title":"Analyzing Decision Strategies","text":"We can then repeat this process by choosing an active state from the new conditional state probabilities s_k that is different from previously chosen states kj","category":"page"},{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"DecisionProgramming.jl API reference.","category":"page"},{"location":"api/#influence_diagram.jl","page":"API Reference","title":"influence_diagram.jl","text":"","category":"section"},{"location":"api/#Nodes","page":"API Reference","title":"Nodes","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Node\nChanceNode\nDecisionNode\nValueNode\nState\nStates\nStates(::Vector{Tuple{State, Vector{Node}}})\nvalidate_influence_diagram","category":"page"},{"location":"api/#DecisionProgramming.Node","page":"API Reference","title":"DecisionProgramming.Node","text":"Primitive type for node. Alias for Int.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.ChanceNode","page":"API Reference","title":"DecisionProgramming.ChanceNode","text":"Chance node type.\n\nExamples\n\nc = ChanceNode(3, [1, 2])\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DecisionNode","page":"API Reference","title":"DecisionProgramming.DecisionNode","text":"Decision node type.\n\nExamples\n\nd = DecisionNode(2, [1])\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.ValueNode","page":"API Reference","title":"DecisionProgramming.ValueNode","text":"Value node type.\n\nExamples\n\nv = ValueNode(4, [1, 3])\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.State","page":"API Reference","title":"DecisionProgramming.State","text":"Primitive type for the number of states. Alias for Int.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.States","page":"API Reference","title":"DecisionProgramming.States","text":"States type. Works like Vector{State}.\n\nExamples\n\nS = States([2, 3, 2, 4])\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.States-Tuple{Array{Tuple{Int64,Array{Int64,1}},1}}","page":"API Reference","title":"DecisionProgramming.States","text":"Construct states from vector of (state, nodes) tuples.\n\nExamples\n\njulia> S = States([(2, [1, 3]), (3, [2, 4, 5])])\nStates([2, 3, 2, 3, 3])\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.validate_influence_diagram","page":"API Reference","title":"DecisionProgramming.validate_influence_diagram","text":"Validate influence diagram.\n\n\n\n\n\n","category":"function"},{"location":"api/#Paths","page":"API Reference","title":"Paths","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Path\npaths","category":"page"},{"location":"api/#DecisionProgramming.Path","page":"API Reference","title":"DecisionProgramming.Path","text":"Path type. Alias for NTuple{N, State} where N.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.paths","page":"API Reference","title":"DecisionProgramming.paths","text":"Iterate over paths in lexicographical order.\n\nExamples\n\njulia> states = States([2, 3])\njulia> vec(collect(paths(states)))\n[(1, 1), (2, 1), (1, 2), (2, 2), (1, 3), (2, 3)]\n\n\n\n\n\nIterate over paths with fixed states in lexicographical order.\n\nExamples\n\njulia> states = States([2, 3])\njulia> vec(collect(paths(states, Dict(1=>2))))\n[(2, 1), (2, 2), (2, 3)]\n\n\n\n\n\n","category":"function"},{"location":"api/#Probabilities","page":"API Reference","title":"Probabilities","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Probabilities","category":"page"},{"location":"api/#DecisionProgramming.Probabilities","page":"API Reference","title":"DecisionProgramming.Probabilities","text":"Construct and validate stage probabilities.\n\nExamples\n\njulia> data = [0.5 0.5 ; 0.2 0.8]\njulia> X = Probabilities(2, data)\njulia> s = (1, 2)\njulia> X(s)\n0.5\n\n\n\n\n\n","category":"type"},{"location":"api/#Path-Probability","page":"API Reference","title":"Path Probability","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"AbstractPathProbability\nDefaultPathProbability","category":"page"},{"location":"api/#DecisionProgramming.AbstractPathProbability","page":"API Reference","title":"DecisionProgramming.AbstractPathProbability","text":"Abstract path probability type.\n\nExamples\n\nstruct PathProbability <: AbstractPathProbability\n    C::Vector{ChanceNode}\n    # ...\nend\n\n(U::PathProbability)(s::Path) = ...\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DefaultPathProbability","page":"API Reference","title":"DecisionProgramming.DefaultPathProbability","text":"Path probability.\n\nExamples\n\nP = DefaultPathProbability(C, X)\ns = (1, 2)\nP(s)\n\n\n\n\n\n","category":"type"},{"location":"api/#Consequences","page":"API Reference","title":"Consequences","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Consequences","category":"page"},{"location":"api/#DecisionProgramming.Consequences","page":"API Reference","title":"DecisionProgramming.Consequences","text":"State utilities.\n\nExamples\n\njulia> vals = [1.0 -2.0; 3.0 4.0]\njulia> Y = Consequences(3, vals)\njulia> s = (1, 2)\njulia> Y(s)\n-2.0\n\n\n\n\n\n","category":"type"},{"location":"api/#Path-Utility","page":"API Reference","title":"Path Utility","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"AbstractPathUtility\nDefaultPathUtility","category":"page"},{"location":"api/#DecisionProgramming.AbstractPathUtility","page":"API Reference","title":"DecisionProgramming.AbstractPathUtility","text":"Abstract path utility type.\n\nExamples\n\nstruct PathUtility <: AbstractPathUtility\n    V::Vector{ValueNode}\n    # ...\nend\n\n(U::PathUtility)(s::Path) = ...\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DefaultPathUtility","page":"API Reference","title":"DecisionProgramming.DefaultPathUtility","text":"Default path utility.\n\nExamples\n\nU = DefaultPathUtility(V, Y)\ns = (1, 2)\nU(s)\n\n\n\n\n\n","category":"type"},{"location":"api/#Decision-Strategy","page":"API Reference","title":"Decision Strategy","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"LocalDecisionStrategy\nDecisionStrategy","category":"page"},{"location":"api/#DecisionProgramming.LocalDecisionStrategy","page":"API Reference","title":"DecisionProgramming.LocalDecisionStrategy","text":"Local decision strategy type.\n\nExamples\n\nZ = LocalDecisionStrategy(1, data)\nZ(s_I)\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.DecisionStrategy","page":"API Reference","title":"DecisionProgramming.DecisionStrategy","text":"Decision strategy type.\n\n\n\n\n\n","category":"type"},{"location":"api/#decision_model.jl","page":"API Reference","title":"decision_model.jl","text":"","category":"section"},{"location":"api/#Decision-Model","page":"API Reference","title":"Decision Model","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"DecisionVariables\nPathProbabilityVariables\nprobability_cut(::Model, ::PathProbabilityVariables, ::AbstractPathProbability)\nactive_paths_cut(::Model, ::PathProbabilityVariables, ::States, ::AbstractPathProbability; ::Float64)","category":"page"},{"location":"api/#DecisionProgramming.DecisionVariables","page":"API Reference","title":"DecisionProgramming.DecisionVariables","text":"Create decision variables and constraints.\n\nExamples\n\nz = DecisionVariables(model, S, D)\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.PathProbabilityVariables","page":"API Reference","title":"DecisionProgramming.PathProbabilityVariables","text":"Create path probability variables and constraints.\n\nExamples\n\nπ_s = PathProbabilityVariables(model, z, S, P)\nπ_s = PathProbabilityVariables(model, z, S, P; hard_lower_bound=false))\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.probability_cut-Tuple{Model,PathProbabilityVariables,AbstractPathProbability}","page":"API Reference","title":"DecisionProgramming.probability_cut","text":"Adds a probability cut to the model as a lazy constraint.\n\nExamples\n\nprobability_cut(model, π_s, P)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.active_paths_cut-Tuple{Model,PathProbabilityVariables,States,AbstractPathProbability}","page":"API Reference","title":"DecisionProgramming.active_paths_cut","text":"Adds a active paths cut to the model as a lazy constraint.\n\nExamples\n\natol = 0.9  # Tolerance to trigger the creation of the lazy cut\nactive_paths_cut(model, π_s, S, P; atol=atol)\n\n\n\n\n\n","category":"method"},{"location":"api/#Objective-Functions","page":"API Reference","title":"Objective Functions","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"PositivePathUtility\nexpected_value(::Model, ::PathProbabilityVariables, ::AbstractPathUtility)\nconditional_value_at_risk(::Model, ::PathProbabilityVariables, ::AbstractPathUtility, ::Float64)","category":"page"},{"location":"api/#DecisionProgramming.PositivePathUtility","page":"API Reference","title":"DecisionProgramming.PositivePathUtility","text":"Positive affine transformation of path utility. Always evaluates positive values.\n\nExamples\n\njulia> U⁺ = PositivePathUtility(S, U)\njulia> all(U⁺(s) > 0 for s in paths(S))\ntrue\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.expected_value-Tuple{Model,PathProbabilityVariables,AbstractPathUtility}","page":"API Reference","title":"DecisionProgramming.expected_value","text":"Create an expected value objective.\n\nExamples\n\nEV = expected_value(model, π_s, U)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.conditional_value_at_risk-Tuple{Model,PathProbabilityVariables,AbstractPathUtility,Float64}","page":"API Reference","title":"DecisionProgramming.conditional_value_at_risk","text":"Create a conditional value-at-risk (CVaR) objective.\n\nExamples\n\nα = 0.05  # Parameter such that 0 ≤ α ≤ 1\nCVaR = conditional_value_at_risk(model, π_s, U, α)\n\n\n\n\n\n","category":"method"},{"location":"api/#Decision-Strategy-from-Variables","page":"API Reference","title":"Decision Strategy from Variables","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"LocalDecisionStrategy(::Node, ::Vector{VariableRef})\nDecisionStrategy(::DecisionVariables)","category":"page"},{"location":"api/#DecisionProgramming.LocalDecisionStrategy-Tuple{Int64,Array{VariableRef,1}}","page":"API Reference","title":"DecisionProgramming.LocalDecisionStrategy","text":"Construct decision strategy from variable refs.\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.DecisionStrategy-Tuple{DecisionVariables}","page":"API Reference","title":"DecisionProgramming.DecisionStrategy","text":"Extract values for decision variables from solved decision model.\n\nExamples\n\nZ = DecisionStrategy(z)\n\n\n\n\n\n","category":"method"},{"location":"api/#analysis.jl","page":"API Reference","title":"analysis.jl","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"CompatiblePaths\nUtilityDistribution\nUtilityDistribution(::States, ::AbstractPathProbability, ::AbstractPathUtility, ::DecisionStrategy)\nStateProbabilities\nStateProbabilities(::States, ::AbstractPathProbability, ::DecisionStrategy)\nStateProbabilities(::States, ::AbstractPathProbability, ::DecisionStrategy, ::Node, ::State, ::StateProbabilities)\nvalue_at_risk(::Vector{Float64}, ::Vector{Float64}, ::Float64)\nconditional_value_at_risk(::Vector{Float64}, ::Vector{Float64}, ::Float64)","category":"page"},{"location":"api/#DecisionProgramming.CompatiblePaths","page":"API Reference","title":"DecisionProgramming.CompatiblePaths","text":"Interface for iterating over active paths given influence diagram and decision strategy.\n\nInitialize path s of length n\nFill chance states s[C] by generating subpaths paths(C)\nFill decision states s[D] by decision strategy Z and path s\n\nExamples\n\nfor s in CompatiblePaths(S, C, Z)\n    ...\nend\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.UtilityDistribution","page":"API Reference","title":"DecisionProgramming.UtilityDistribution","text":"UtilityDistribution type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.UtilityDistribution-Tuple{States,AbstractPathProbability,AbstractPathUtility,DecisionStrategy}","page":"API Reference","title":"DecisionProgramming.UtilityDistribution","text":"Constructs the probability mass function for path utilities on active paths.\n\nExamples\n\nUtilityDistribution(S, P, U, Z)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.StateProbabilities","page":"API Reference","title":"DecisionProgramming.StateProbabilities","text":"StateProbabilities type.\n\n\n\n\n\n","category":"type"},{"location":"api/#DecisionProgramming.StateProbabilities-Tuple{States,AbstractPathProbability,DecisionStrategy}","page":"API Reference","title":"DecisionProgramming.StateProbabilities","text":"Associates each node with array of probabilities for each of its states occuring in active paths.\n\nExamples\n\nStateProbabilities(S, P, Z)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.StateProbabilities-Tuple{States,AbstractPathProbability,DecisionStrategy,Int64,Int64,StateProbabilities}","page":"API Reference","title":"DecisionProgramming.StateProbabilities","text":"Associates each node with array of conditional probabilities for each of its states occuring in active paths given fixed states and prior probability.\n\nExamples\n\n# Prior probabilities\nprev = StateProbabilities(S, P, Z)\n\n# Select node and fix its state\nnode = 1\nstate = 2\nStateProbabilities(S, P, Z, node, state, prev)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.value_at_risk-Tuple{Array{Float64,1},Array{Float64,1},Float64}","page":"API Reference","title":"DecisionProgramming.value_at_risk","text":"Value-at-risk.\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.conditional_value_at_risk-Tuple{Array{Float64,1},Array{Float64,1},Float64}","page":"API Reference","title":"DecisionProgramming.conditional_value_at_risk","text":"Conditional value-at-risk.\n\n\n\n\n\n","category":"method"},{"location":"api/#printing.jl","page":"API Reference","title":"printing.jl","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"print_decision_strategy\nprint_utility_distribution\nprint_state_probabilities\nprint_statistics\nprint_risk_measures","category":"page"},{"location":"api/#DecisionProgramming.print_decision_strategy","page":"API Reference","title":"DecisionProgramming.print_decision_strategy","text":"Print decision strategy.\n\nExamples\n\nprint_decision_strategy(S, Z)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_utility_distribution","page":"API Reference","title":"DecisionProgramming.print_utility_distribution","text":"Print utility distribution\n\nExamples\n\nudist = UtilityDistribution(S, P, U, Z)\nprint_utility_distribution(udist)\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_state_probabilities","page":"API Reference","title":"DecisionProgramming.print_state_probabilities","text":"Print state probabilities with fixed states.\n\nExamples\n\nsprobs = StateProbabilities(S, P, U, Z)\nprint_state_probabilities(sprobs, [c.j for c in C])\nprint_state_probabilities(sprobs, [d.j for d in D])\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_statistics","page":"API Reference","title":"DecisionProgramming.print_statistics","text":"Print statistics.\n\n\n\n\n\n","category":"function"},{"location":"api/#DecisionProgramming.print_risk_measures","page":"API Reference","title":"DecisionProgramming.print_risk_measures","text":"Print risk measures.\n\n\n\n\n\n","category":"function"},{"location":"api/#random.jl","page":"API Reference","title":"random.jl","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"random_diagram(::AbstractRNG, ::Int, ::Int, ::Int, ::Int, ::Int)\nStates(::AbstractRNG, ::Vector{State}, ::Int)\nProbabilities(::AbstractRNG, ::ChanceNode, ::States)\nConsequences(::AbstractRNG, ::ValueNode, ::States; ::Float64, ::Float64)\nLocalDecisionStrategy(::AbstractRNG, ::DecisionNode, ::States)","category":"page"},{"location":"api/#DecisionProgramming.random_diagram-Tuple{AbstractRNG,Int64,Int64,Int64,Int64,Int64}","page":"API Reference","title":"DecisionProgramming.random_diagram","text":"Generate random decision diagram with n_C chance nodes, n_D decision nodes, and n_V value nodes. Parameter m_C and m_D are the upper bounds for the size of the information set.\n\nExamples\n\nrng = MersenneTwister(3)\nrandom_diagram(rng, 5, 2, 3, 2)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.States-Tuple{AbstractRNG,Array{Int64,1},Int64}","page":"API Reference","title":"DecisionProgramming.States","text":"Generate n random states from states.\n\nExamples\n\nrng = MersenneTwister(3)\nS = States(rng, [2, 3], 10)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.Probabilities-Tuple{AbstractRNG,ChanceNode,States}","page":"API Reference","title":"DecisionProgramming.Probabilities","text":"Generate random probabilities for chance node c with S states.\n\nExamples\n\nrng = MersenneTwister(3)\nc = ChanceNode(2, [1])\nS = States([2, 2])\nProbabilities(rng, c, S)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.Consequences-Tuple{AbstractRNG,ValueNode,States}","page":"API Reference","title":"DecisionProgramming.Consequences","text":"Generate random consequences between low and high for value node v with S states.\n\nExamples\n\nrng = MersenneTwister(3)\nv = ValueNode(3, [1])\nS = States([2, 2])\nConsequences(rng, v, S; low=-1.0, high=1.0)\n\n\n\n\n\n","category":"method"},{"location":"api/#DecisionProgramming.LocalDecisionStrategy-Tuple{AbstractRNG,DecisionNode,States}","page":"API Reference","title":"DecisionProgramming.LocalDecisionStrategy","text":"Generate random decision strategy for decision node d with S states.\n\nExamples\n\nrng = MersenneTwister(3)\nd = DecisionNode(2, [1])\nS = States([2, 2])\nLocalDecisionStrategy(rng, d, S)\n\n\n\n\n\n","category":"method"},{"location":"decision-programming/decision-model/#decision-model","page":"Decision Model","title":"Decision Model","text":"","category":"section"},{"location":"decision-programming/decision-model/#Introduction","page":"Decision Model","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Decision programming aims to find an optimal decision strategy Z from all decision strategies ℤ by maximizing an objective function f on the path distribution of an influence diagram","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"undersetZℤtextmaximizequad f((ℙ(X=𝐬Z) mathcalU(𝐬))  𝐬𝐒) tag1","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Decision model refers to the mixed-integer linear programming formulation of this optimization problem. This page explains how to express decision strategy, path probability, path utility, and the objective in the mixed-integer linear form. We also present standard objective functions, including expected value and risk measures.  We based the decision model on [1], sections 3 and 5. We recommend reading the references for motivation, details, and proofs of the formulation.","category":"page"},{"location":"decision-programming/decision-model/#Decision-Variables","page":"Decision Model","title":"Decision Variables","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Decision variables z(s_j𝐬_I(j)) are equivalent to local decision strategies such that Z_j(𝐬_I(j))=s_j if and only if z(s_j𝐬_I(j))=1 and z(s_j^𝐬_I(j))=0 for all s_j^S_js_j Constraint (2) defines the decisions to be binary variables and the constraint (3) limits decisions to one per information path.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"z(s_j𝐬_I(j))  01quad jD s_jS_j 𝐬_I(j)𝐒_I(j) tag2","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_s_jS_j z(s_j𝐬_I(j))=1quad jD 𝐬_I(j)𝐒_I(j) tag3","category":"page"},{"location":"decision-programming/decision-model/#Path-Probability-Variables","page":"Decision Model","title":"Path Probability Variables","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Path probability variables π(𝐬) are equivalent to the path probabilities ℙ(X=𝐬Z) where decision variables z define the decision strategy Z. The constraint (4) defines the lower and upper bound to the probability, constraint (5) defines that the probability equals zero if path is not compatible with the decision strategy, and constraint (6) defines that probability equals path probability if the path is compatible with the decision strategy.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"0π(𝐬)p(𝐬)quad 𝐬𝐒 tag4","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"π(𝐬)  z(𝐬_j𝐬_I(j))quad jD 𝐬𝐒 tag5","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"π(𝐬)  p(𝐬) + _jD z(𝐬_j𝐬_I(j)) - Dquad 𝐬𝐒 tag6","category":"page"},{"location":"decision-programming/decision-model/#Positive-Path-Utility","page":"Decision Model","title":"Positive Path Utility","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can omit the constraint (6) from the model if we use a positive path utility function mathcalU^+ which is an affine transformation of path utility function mathcalU As an example, we can subtract the minimum of the original utility function and then add one as follows.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"mathcalU^+(𝐬) = mathcalU(𝐬) - min_𝐬𝐒 mathcalU(𝐬) + 1 tag7","category":"page"},{"location":"decision-programming/decision-model/#Lazy-Constraints","page":"Decision Model","title":"Lazy Constraints","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Valid equalities are equalities that can be be derived from the problem structure. They can help in computing the optimal decision strategies, but adding them directly may slow down the overall solution process. By adding valid equalities during the solution process as lazy constraints, the MILP solver can prune nodes of the branch-and-bound tree more efficiently. We have the following valid equalities.","category":"page"},{"location":"decision-programming/decision-model/#Probability-Cut","page":"Decision Model","title":"Probability Cut","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can exploit the fact that the path probabilities sum to one by using the probability cut defined as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_𝐬𝐒π(𝐬)=1 tag8","category":"page"},{"location":"decision-programming/decision-model/#Active-Paths-Cut","page":"Decision Model","title":"Active Paths Cut","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"For problems where the number of active and compatible paths is constant, we can exploit it by using the active paths cut defined as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_𝐬𝐒 fracπ(𝐬)p(𝐬)=𝐒(X)𝐒(Z) tag9","category":"page"},{"location":"decision-programming/decision-model/#Expected-Value","page":"Decision Model","title":"Expected Value","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We define the expected value objective as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameE(Z) = _𝐬𝐒 π(𝐬) mathcalU(𝐬) tag10","category":"page"},{"location":"decision-programming/decision-model/#Conditional-Value-at-Risk","page":"Decision Model","title":"Conditional Value-at-Risk","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"The section Measuring Risk explains and visualizes the relationships between the formulation of expected value, value-at-risk and conditional value-at-risk for discrete probability distribution.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Given decision strategy Z we define the cumulative distribution of path probability variables as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"F_Z(t) = _𝐬𝐒mathcalU(𝐬)t π(𝐬)","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Given a probability level α(0 1 we define the value-at-risk as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameVaR_α(Z)=u_α=sup mathcalU(𝐬)𝐬𝐒 F_Z(mathcalU(𝐬))α","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Then, we have the paths that have path utility less than and equal to the value-at-risk as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"𝐒_α^=𝐬𝐒mathcalU(𝐬)u_α","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"𝐒_α^==𝐬𝐒mathcalU(𝐬)=u_α","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We define conditional value-at-risk as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameCVaR_α(Z)=frac1αleft(_𝐬𝐒_α^ π(𝐬) mathcalU(𝐬) + _𝐬𝐒_α^= left(α - _𝐬𝐒_α^ π(𝐬) right) mathcalU(𝐬) right)","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can form the conditional value-at-risk as an optimization problem. We have the following pre-computed parameters.","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Lower and upper bound of the value-at-risk","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameVaR_0(Z)=u^-=minmathcalU(𝐬)𝐬𝐒 tag11","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameVaR_1(Z)=u^+=maxmathcalU(𝐬)𝐬𝐒 tag12","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Largest difference between path utilities","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"M=u^+-u^- tag13","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"Half of the smallest positive difference between path utilities","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"ϵ=frac12 minmathcalU(𝐬)-mathcalU(𝐬^)  mathcalU(𝐬)-mathcalU(𝐬^)  0 𝐬 𝐬^𝐒 tag14","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"The objective is to minimize the variable η whose optimal value is equal to the value-at-risk, that is, operatornameVaR_α(Z)=min η","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We define the constraints as follows:","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"η-mathcalU(𝐬)M λ(𝐬)quad 𝐬𝐒 tag14","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"η-mathcalU(𝐬)(M+ϵ) λ(𝐬) - Mquad 𝐬𝐒 tag15","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"η-mathcalU(𝐬)(M+ϵ) barλ(𝐬) - ϵquad 𝐬𝐒 tag16","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"η-mathcalU(𝐬)M (barλ(𝐬) - 1)quad 𝐬𝐒 tag17","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"barρ(𝐬)  barλ(𝐬)quad 𝐬𝐒 tag18","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"π(𝐬) - (1 - λ(𝐬))  ρ(𝐬)  λ(𝐬)quad 𝐬𝐒 tag19","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"ρ(𝐬)  barρ(𝐬)  π(𝐬)quad 𝐬𝐒 tag20","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"_𝐬𝐒barρ(𝐬) = α tag21","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"barλ(𝐬) λ(𝐬)0 1quad 𝐬𝐒 tag22","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"barρ(𝐬)ρ(𝐬)0 1quad 𝐬𝐒 tag23","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"ηu^- u^+ tag24","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can express the conditional value-at-risk objective as","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameCVaR_α(Z)=frac1α_𝐬𝐒barρ(𝐬) mathcalU(𝐬)tag25","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"The values of conditional value-at-risk are limited to the interval between the lower bound of value-at-risk and the expected value","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"operatornameVaR_0(Z)operatornameCVaR_α(Z)E(Z)","category":"page"},{"location":"decision-programming/decision-model/#Convex-Combination","page":"Decision Model","title":"Convex Combination","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"We can combine expected value and conditional value-at-risk using a convex combination at a fixed probability level α(0 1 as follows","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"w operatornameE(Z) + (1-w) operatornameCVaR_α(Z) tag26","category":"page"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"where the parameter w0 1 expresses the decision maker's risk tolerance.","category":"page"},{"location":"decision-programming/decision-model/#References","page":"Decision Model","title":"References","text":"","category":"section"},{"location":"decision-programming/decision-model/","page":"Decision Model","title":"Decision Model","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"usage/#Usage","page":"Usage","title":"Usage","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"On this page, we demonstrate common patterns for expressing influence diagrams and creating decision models using DecisionProgramming.jl. We can import the package with the using keyword.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"using DecisionProgramming","category":"page"},{"location":"usage/#Chance-Nodes","page":"Usage","title":"Chance Nodes","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"(Image: )","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Given the above influence diagram, we can create the ChanceNode and Probabilities structures for the node 3 as follows:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"S = States([2, 3, 2])\nj = 3\nI_j = Node[1, 2]\nX_j = zeros(S[I_j]..., S[j])\nX_j[1, 1, :] = [0.1, 0.9]\nX_j[1, 2, :] = [0.0, 1.0]\nX_j[1, 3, :] = [0.3, 0.7]\nX_j[2, 1, :] = [0.2, 0.8]\nX_j[2, 2, :] = [0.4, 0.6]\nX_j[2, 3, :] = [1.0, 0.0]\nChanceNode(j, I_j)\nProbabilities(j, X_j)","category":"page"},{"location":"usage/#Decision-Nodes","page":"Usage","title":"Decision Nodes","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"(Image: )","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Given the above influence diagram, we can create the DecisionNode structure for the node 3 as follows:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"S = States([2, 3, 2])\nj = 3\nI_j = Node[1, 2]\nDecisionNode(j, I_j)","category":"page"},{"location":"usage/#Value-Nodes","page":"Usage","title":"Value Nodes","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"(Image: )","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Given the above influence diagram, we can create ValueNode and Consequences structures for node 3 as follows:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"S = States([2, 3])\nj = 3\nI_j = [1, 2]\nY_j = zeros(S[I_j]...)\nY_j[1, 1] = -1.3\nY_j[1, 2] = 2.5\nY_j[1, 3] = 0.1\nY_j[2, 1] = 0.0\nY_j[2, 2] = 3.2\nY_j[2, 3] = -2.7\nValueNode(j, I_j)\nConsequences(j, Y_j)","category":"page"},{"location":"decision-programming/influence-diagram/#influence-diagram","page":"Influence Diagram","title":"Influence Diagram","text":"","category":"section"},{"location":"decision-programming/influence-diagram/#Introduction","page":"Influence Diagram","title":"Introduction","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Decision programming uses influence diagrams, a generalization of Bayesian networks, to model multi-stage decision problems under uncertainty. This section defines the influence diagrams and discusses their properties. It is based on the definitions in [1], [2], and [3].","category":"page"},{"location":"decision-programming/influence-diagram/#Definition","page":"Influence Diagram","title":"Definition","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(Image: )","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the influence diagram as a directed, acyclic graph G=(CDVIS) We describe the nodes N=CDV with CD=1n and n=C+D as follows:","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Chance nodes C1n (circles) represent uncertain events associated with random variables.\nDecision nodes D1n (squares) correspond to decisions among discrete alternatives.\nValue nodes V=n+1n+V (diamonds) represent consequences that result from the realizations of random variables at chance nodes and the decisions made at decision nodes.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the information set I of node jN as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"I(j)iCDij","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Practically, the information set is a collection of arcs to reverse direction in the graph. The conditions enforce that the graph is acyclic, and there are no arcs from value nodes to other nodes.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"In an influence diagram, each chance and decision node jCD is associates with a finite number of states S_j that we encode using integers S_j=1S_j from one to number of states S_j1 A node j is trivial if it has only one state, S_j=1 We refer to the collection of all states S=S_1S_n as the state space.","category":"page"},{"location":"decision-programming/influence-diagram/#Root-and-Leaf-Nodes","page":"Influence Diagram","title":"Root and Leaf Nodes","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Chance or decision node is a root node if it is not affected by other chance or decision nodes. Formally, node jCD is a root node if I(j)=","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Chance or decision node is a leaf node if it does not affect other chance or decision nodes. Formally, node jCD is a leaf node if jI(i) for all iCD","category":"page"},{"location":"decision-programming/influence-diagram/#Drawing-Nodes-and-Arcs","page":"Influence Diagram","title":"Drawing Nodes and Arcs","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(Image: )","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We use a circle to represent chance nodes, a square to represent decision nodes, and a diamond to represent value nodes. The symbol i represents the node's index and symbol S_i the states of the chance or decision node. We use the following colors and styling:","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Chance nodes: Fill color F5F5F5 and line color 666666.\nDecision nodes: Fill color D5E8D4 and line color 82B366\nValue nodes: Fill color FFE6CC and line color D79B00\nLinewidth 2pt and perimeter 2pt (padding around the node).","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We represent directed arcs using arrows from a source node to a target node, colored with the target node's line color. We recommend diagrams.net for drawing graphs.","category":"page"},{"location":"decision-programming/influence-diagram/#Drawing-Layered-Graph","page":"Influence Diagram","title":"Drawing Layered Graph","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(Image: )","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We showed the influence diagram as a linear graph in the Definition section. We can also draw a more concise layered graph, which is better at displaying the influence relationship structure — only nodes at smaller depth influence nodes at greater depth. Also, root and leaf nodes are visible from the layered form.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the depth of a node jN as follows. Root nodes have a depth of one","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"operatornamedepth(j)=1quad I(j)=","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Other nodes have a depth of one greater than the maximum depth of its predecessors","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"operatornamedepth(j)=max_iI(j) operatornamedepth(i) + 1quad I(j)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We can then draw the layered graph by grouping the nodes by their depth, ordering the groups by increasing depth and increasing indices order within each group.","category":"page"},{"location":"decision-programming/influence-diagram/#Paths","page":"Influence Diagram","title":"Paths","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(Image: )","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"In influence diagrams, paths represent realizations of states for chance and decision nodes. For example, the above tree represents generating all paths with states S_1=12 and S_2=123","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Formally, a path is a sequence of states","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐬=(s_1 s_2 s_n)𝐒","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"where each state s_iS_i for all chance and decision nodes iCD We denote the set of paths as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐒=_jCD S_j=S_1S_2S_n","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define a subpath of 𝐬 with ACD is a subsequence","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐬_A=(𝐬_iiA)𝐒_A","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We denote the set of subpaths as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐒_A=_iA S_i","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We define the number of paths as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"𝐒_A=_iAS_i","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We refer to subpath 𝐬_I(j) as an information path and subpaths 𝐒_I(j) as information paths for a node jN","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Also note that 𝐒=𝐒_CD and 𝐒_i=S_i and 𝐬_i=s_i where iCD is an individual node.","category":"page"},{"location":"decision-programming/influence-diagram/#Probabilities","page":"Influence Diagram","title":"Probabilities","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Each chance node is associated with a discrete probability distribution over its states for every information path. Formally, for each chance node jC, we denote the probability of state s_j given information path 𝐬_I(j) as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"ℙ(X_j=s_jX_I(j)=𝐬_I(j))0 1","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"with","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"_s_jS_j ℙ(X_j=s_jX_I(j)=𝐬_I(j)) = 1","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We refer to chance state with given information path as active if its probability is nonzero","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"ℙ(X_j=s_jX_I(j)=𝐬_I(j))0","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Otherwise, it is inactive.","category":"page"},{"location":"decision-programming/influence-diagram/#Decision-Strategies","page":"Influence Diagram","title":"Decision Strategies","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Each decision strategy models how the decision maker chooses a state s_jS_j given an information path 𝐬_I(j) at decision node jD Decision node is a special type of chance node, such that the probability of the chosen state given an information path is fixed to one","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"ℙ(X_j=s_jX_I(j)=𝐬_I(j))=1","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"By definition, the probabilities for other states are zero.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Formally, for each decision node jD a local decision strategy is function that maps an information path 𝐬_I(j) to a state s_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Z_j𝐒_I(j)S_j","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"A decision strategy contains one local decision strategy for each decision node","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Z=Z_jjD","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The set of all decision strategies is denoted ℤ","category":"page"},{"location":"decision-programming/influence-diagram/#Path-Probability","page":"Influence Diagram","title":"Path Probability","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The probability distributions at chance and decision nodes define the probability distribution over all paths 𝐬𝐒 which depends on the decision strategy Zℤ We refer to it as the path probability","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"ℙ(X=𝐬Z) = _jCD ℙ(X_j=𝐬_jX_I(j)=𝐬_I(j))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"We can decompose the path probability into two parts","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"ℙ(X=𝐬Z) = p(𝐬) q(𝐬Z)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The first part consists of the probability contributed by the chance nodes. We refer to it as the upper bound of path probability","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"p(𝐬) = _jC ℙ(X_j=𝐬_jX_I(j)=𝐬_I(j))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The second part consists of the probability contributed by the decision nodes.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"q(𝐬Z) = _jD ℙ(X_j=𝐬_jX_I(j)=𝐬_I(j))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Because the probabilities of decision nodes are defined as one or zero depending on the decision strategy, we can simplify the second part to an indicator function","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"q(𝐬Z)=begincases\n1  Z(𝐬) \n0  textotherwise\nendcases","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The expression Z(𝐬) indicates whether a decision stategy is compatible with the path 𝐬 that is, if each local decision strategy chooses a state on the path. Formally, we have","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Z(𝐬)  _jD (Z_j(𝐬_I(j))=𝐬_j)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Now the path probability equals the upper bound if the path is compatible with given decision strategy. Otherwise, the path probability is zero. Formally, we have","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"ℙ(𝐬XZ)=\nbegincases\np(𝐬)  Z(𝐬) \n0  textotherwise\nendcases","category":"page"},{"location":"decision-programming/influence-diagram/#Consequences","page":"Influence Diagram","title":"Consequences","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"For each value node jV, we define the consequence given information path 𝐬_I(j) as","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Y_j𝐒_I(j)ℂ","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"where ℂ is the set of real-valued consequences.","category":"page"},{"location":"decision-programming/influence-diagram/#Path-Utility","page":"Influence Diagram","title":"Path Utility","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The utility function is a function that maps consequences to real-valued utility","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Uℂ^Vℝ","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The path utility is defined as the utility function acting on the consequences of value nodes given their information paths","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"mathcalU(𝐬) = U(Y_j(𝐬_I(j))  jV)","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The default path utility is the sum of consequences","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"mathcalU(𝐬) = _jV Y_j(𝐬_I(j))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The utility function, in this case, corresponds to the sum of the elements.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"The utility function affects the objectives discussed Decision Model page. We can choose the utility function such that the path utility function either returns:","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"a numerical value, which leads to a mixed-integer linear programming (MILP) formulation or\na linear function with real and integer-valued variables leads to a mixed-integer quadratic programming (MIQP) formulation.","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"Different formulations require a solver capable of solving them.","category":"page"},{"location":"decision-programming/influence-diagram/#Path-Distribution","page":"Influence Diagram","title":"Path Distribution","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"A path distribution is a pair","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"(ℙ(X=𝐬Z) mathcalU(𝐬))","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"that comprises of path probability function and path utility function over paths 𝐬𝐒 conditional to the decision strategy Z","category":"page"},{"location":"decision-programming/influence-diagram/#References","page":"Influence Diagram","title":"References","text":"","category":"section"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"[1]: Salo, A., Andelmin, J., & Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from http://arxiv.org/abs/1910.09196","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"[2]: Howard, R. A., & Matheson, J. E. (2005). Influence diagrams. Decision Analysis, 2(3), 127-143. https://doi.org/10.1287/deca.1050.0020","category":"page"},{"location":"decision-programming/influence-diagram/","page":"Influence Diagram","title":"Influence Diagram","text":"[3]: Shachter, R. D. (1986). Evaluating influence diagrams. Operations research, 34(6), 871-882. https://doi.org/10.1287/opre.34.6.871","category":"page"},{"location":"#DecisionProgramming.jl","page":"Home","title":"DecisionProgramming.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"DecisionProgramming.jl is a Julia package for solving multi-stage decision problems under uncertainty, modeled using influence diagrams, and leveraging the power of mixed-integer linear programming. Solving multi-stage decision problems under uncertainty consists of the following three steps.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the first step, we model the decision problem using an influence diagram with associated probabilities, consequences, and path utility function.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the second step, we create a decision model with an objective for the influence diagram. We solve the model to obtain an optimal decision strategy. We can create and solve multiple models with different objectives for the same influence diagram to receive various optimal decision strategies.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the third step, we analyze the resulting decision strategies for the influence diagram. In particular, we are interested in utility distribution and its associated statistics and risk measures.","category":"page"},{"location":"","page":"Home","title":"Home","text":"DecisionProgramming.jl provides the necessary functionality for expressing and solving decision problems but does not explain how to design influence diagrams. The rest of this documentation will describe the mathematical and programmatic details, touch on the computational challenges, and provide concrete examples of solving decision problems.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The examples start with a rather simple and easily approachable Used Car Buyer problem that can be also solved using more conventional methods such as decision trees. The following two examples illustrate the capabilities of the framework in problems where the no-forgetting assumption does not hold and solving the influence diagram with well-established techniques is thus impossible. In the Pig Breeding problem, only the most recent information is available when making each decision, thus breaking the no-forgetting assumption, while in the N-Monitoring problem, the decisions are made in parallel with no communication between the decision makers, also leading to the assumption not working. The final example is a more advanced one, demonstrating the versatility of the framework in adding decision variables and constraints.","category":"page"},{"location":"","page":"Home","title":"Home","text":"DecisionProgramming.jl is developed in the Systems Analysis Laboratory at Aalto University by Ahti Salo,  Fabricio Oliveira, Juho Andelmin, Olli Herrala, and Jaan Tollander de Balsch.","category":"page"},{"location":"examples/used-car-buyer/#Used-Car-Buyer","page":"Used Car Buyer","title":"Used Car Buyer","text":"","category":"section"},{"location":"examples/used-car-buyer/#Description","page":"Used Car Buyer","title":"Description","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"To illustrate the basic functionality of Decision Programming, we implement a version of the used car buyer problem in [1]. In this problem, Joe is buying a used car. The car's price is 1000 USD (US dollars), and its value is 1100 USD. Joe's base profit on the car is thus 100 USD. However, Joe knows that the car is a \"lemon\", meaning that it has defects in 6 major systems, with a 20% probability. With the remaining 80% probability, the car is a \"peach\", and it has a defect in only one of the systems.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The repair costs for a peach are only 40 USD, decreasing Joe's profit to 60  USD. However, the costs for a lemon are 200 USD, resulting in a total loss of 100 USD. We can now formulate an influence diagram of Joe's initial problem. We present the influence diagram in the figure below. In an influence diagram, circle nodes such as O are called chance nodes, representing uncertainty. Node O is a chance node representing the state of the car, lemon or peach. Square nodes such as A are decision nodes, representing decisions. Node A represents the decision to buy or not to buy the car. The diamond-shaped value node V denotes the utility calculation in the problem. For Joe, the utility function is the expected monetary value. The arrows or arcs show connections between nodes. The two arcs in this diagram point to the value node, meaning that the monetary value depends on the state of the car and the purchase decision.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"(Image: \\label{used-car-buyer-1})","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We can easily determine the optimal strategy for this problem. If Joe decides not to buy the car, his profit is zero. If he buys the car, with 20% probability he loses 100 USD and with an 80% probability he profits 60 USD. Therefore, the expected profit for buying the car is 28 USD, which is higher than the zero profit of not buying. Thus, Joe should buy the car.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We now add two new features to the problem. A stranger approaches Joe and offers to tell Joe whether the car is a lemon or a peach for 25 USD. Additionally, the car dealer offers a guarantee plan which costs 60 USD and covers 50% of the repair costs. Joe notes that this is not a very good deal, and the dealer includes an anti-lemon feature: if the total repair cost exceeds 100 USD, the quarantee will fully cover the repairs.","category":"page"},{"location":"examples/used-car-buyer/#Influence-diagram","page":"Used Car Buyer","title":"Influence diagram","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"(Image: \\label{used-car-buyer-2})","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We present the new influence diagram above. The decision node T denotes the decision to accept or decline the stranger's offer, and R is the outcome of the test. We introduce new value nodes V_1 and V_2 to represent the testing costs and the base profit from purchasing the car. Additionally, the decision node A now can choose to buy with a guarantee.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"using JuMP, Gurobi\nusing DecisionProgramming\n\nconst O = 1  # Chance node: lemon or peach\nconst T = 2  # Decision node: pay stranger for advice\nconst R = 3  # Chance node: observation of state of the car\nconst A = 4  # Decision node: purchase alternative\nconst O_states = [\"lemon\", \"peach\"]\nconst T_states = [\"no test\", \"test\"]\nconst R_states = [\"no test\", \"lemon\", \"peach\"]\nconst A_states = [\"buy without guarantee\", \"buy with guarantee\", \"don't buy\"]\n\nS = States([\n    (length(O_states), [O]),\n    (length(T_states), [T]),\n    (length(R_states), [R]),\n    (length(A_states), [A]),\n])\nC = Vector{ChanceNode}()\nD = Vector{DecisionNode}()\nV = Vector{ValueNode}()\nX = Vector{Probabilities}()\nY = Vector{Consequences}()","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We start by defining the influence diagram structure. The decision and chance nodes, as well as their states, are defined in the first block. Next, the influence diagram parameters consisting of the node sets, probabilities, consequences and the state spaces of the nodes are defined.","category":"page"},{"location":"examples/used-car-buyer/#Car's-State","page":"Used Car Buyer","title":"Car's State","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The chance node O is defined by its information set I(O) and probability distribution X_O. As seen in the influence diagram, the information set is empty and the node is a root node. The probability distribution is thus simply defined over the two states of O.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_O = Vector{Node}()\nX_O = [0.2, 0.8]\npush!(C, ChanceNode(O, I_O))\npush!(X, Probabilities(O, X_O))","category":"page"},{"location":"examples/used-car-buyer/#Stranger's-Offer-Decision","page":"Used Car Buyer","title":"Stranger's Offer Decision","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"A decision node is simply defined by its information state.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_T = Vector{Node}()\npush!(D, DecisionNode(T, I_T))","category":"page"},{"location":"examples/used-car-buyer/#Test's-Outcome","page":"Used Car Buyer","title":"Test's Outcome","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The second chance node, R, has nodes O and T in its information set, and the probabilities ℙ(s_j𝐬_I(j)) must thus be defined for all combinations of states in O, T and R.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_R = [O, T]\nX_R = zeros(S[O], S[T], S[R])\nX_R[1, 1, :] = [1,0,0]\nX_R[1, 2, :] = [0,1,0]\nX_R[2, 1, :] = [1,0,0]\nX_R[2, 2, :] = [0,0,1]\npush!(C, ChanceNode(R, I_R))\npush!(X, Probabilities(R, X_R))","category":"page"},{"location":"examples/used-car-buyer/#Purchace-Decision","page":"Used Car Buyer","title":"Purchace Decision","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_A = [R]\npush!(D, DecisionNode(A, I_A))","category":"page"},{"location":"examples/used-car-buyer/#Testing-Cost","page":"Used Car Buyer","title":"Testing Cost","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We continue by defining the utilities (consequences) associated with value nodes. The value nodes are defined similarly as the chance nodes, except that instead of probabilities, we define consequences Y_j(𝐬_I(j)). Value nodes can be named just like the other nodes, e.g. V1 = 5, but considering that the index of value nodes is not needed elsewhere (value nodes can't be in information sets), we choose to simply use the index number when creating the node.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_V1 = [T]\nY_V1 = [0.0, -25.0]\npush!(V, ValueNode(5, I_V1))\npush!(Y, Consequences(5, Y_V1))","category":"page"},{"location":"examples/used-car-buyer/#Base-Profit-of-Purchase","page":"Used Car Buyer","title":"Base Profit of Purchase","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_V2 = [A]\nY_V2 = [100.0, 40.0, 0.0]\npush!(V, ValueNode(6, I_V2))\npush!(Y, Consequences(6, Y_V2))","category":"page"},{"location":"examples/used-car-buyer/#Repairing-Cost","page":"Used Car Buyer","title":"Repairing Cost","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The rows of the consequence matrix Y_V3 correspond to the state of the car, while the columns correspond to the decision made in node A.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"I_V3 = [O, A]\nY_V3 = [-200.0 0.0 0.0;\n        -40.0 -20.0 0.0]\npush!(V, ValueNode(7, I_V3))\npush!(Y, Consequences(7, Y_V3))","category":"page"},{"location":"examples/used-car-buyer/#Validating-Influence-Diagram","page":"Used Car Buyer","title":"Validating Influence Diagram","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Validate influence diagram and sort nodes, probabilities and consequences","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"validate_influence_diagram(S, C, D, V)\nsort!.((C, D, V, X, Y), by = x -> x.j)","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Default path probabilities and utilities are defined as the joint probability of all chance events in the diagram and the sum of utilities in value nodes, respectively. In the Contingent Portfolio Programming example, we show how to use a user-defined custom path utility function.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"P = DefaultPathProbability(C, X)\nU = DefaultPathUtility(V, Y)","category":"page"},{"location":"examples/used-car-buyer/#Decision-Model","page":"Used Car Buyer","title":"Decision Model","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We then construct the decision model using the DecisionProgramming.jl package, using the expected value as the objective.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"model = Model()\nz = DecisionVariables(model, S, D)\nπ_s = PathProbabilityVariables(model, z, S, P)\nEV = expected_value(model, π_s, U)\n@objective(model, Max, EV)","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"We can perform the optimization using an optimizer such as Gurobi.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"optimizer = optimizer_with_attributes(\n    () -> Gurobi.Optimizer(Gurobi.Env()),\n    \"IntFeasTol\"      => 1e-9,\n    \"LazyConstraints\" => 1,\n)\nset_optimizer(model, optimizer)\noptimize!(model)","category":"page"},{"location":"examples/used-car-buyer/#Analyzing-Results","page":"Used Car Buyer","title":"Analyzing Results","text":"","category":"section"},{"location":"examples/used-car-buyer/#Decision-Strategy","page":"Used Car Buyer","title":"Decision Strategy","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Once the model is solved, we obtain the following decision strategy:","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"Z = DecisionStrategy(z)","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"julia> print_decision_strategy(S, Z)\n┌────────┬────┬───┐\n│  Nodes │ () │ 2 │\n├────────┼────┼───┤\n│ States │ () │ 2 │\n└────────┴────┴───┘\n┌────────┬──────┬───┐\n│  Nodes │ (3,) │ 4 │\n├────────┼──────┼───┤\n│ States │ (1,) │ 3 │\n│ States │ (2,) │ 2 │\n│ States │ (3,) │ 1 │\n└────────┴──────┴───┘","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"To start explaining this output, let's take a look at the top table. On the right, we have the decision node 2. We defined earlier that the node T is node number 2. On the left, we have the information set of that decision node, which is empty. The strategy in the first decision node is to choose alternative 2, which we defined to be testing the car.","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"In the bottom table, we have node number 4 (node A) and its predecessor, node number 3 (node R). The first row, where we obtain no test result, is invalid for this strategy since we tested the car. If the car is a lemon, Joe should buy the car with a guarantee (alternative 2), and if it is a peach, buy the car without guarantee (alternative 1).","category":"page"},{"location":"examples/used-car-buyer/#Utility-Distribution","page":"Used Car Buyer","title":"Utility Distribution","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"udist = UtilityDistribution(S, P, U, Z)","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"julia> print_utility_distribution(udist)\n┌───────────┬─────────────┐\n│   Utility │ Probability │\n│   Float64 │     Float64 │\n├───────────┼─────────────┤\n│ 15.000000 │    0.200000 │\n│ 35.000000 │    0.800000 │\n└───────────┴─────────────┘","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"From the utility distribution, we can see that Joe's profit with this strategy is 15 USD, with a 20% probability (the car is a lemon) and 35 USD with an 80% probability (the car is a peach).","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"julia> print_statistics(udist)\n┌──────────┬────────────┐\n│     Name │ Statistics │\n│   String │    Float64 │\n├──────────┼────────────┤\n│     Mean │  31.000000 │\n│      Std │   8.000000 │\n│ Skewness │  -1.500000 │\n│ Kurtosis │   0.250000 │\n└──────────┴────────────┘","category":"page"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"The expected profit is thus 31 USD.","category":"page"},{"location":"examples/used-car-buyer/#References","page":"Used Car Buyer","title":"References","text":"","category":"section"},{"location":"examples/used-car-buyer/","page":"Used Car Buyer","title":"Used Car Buyer","text":"[1]: Howard, R. A. (1977). The used car buyer. Reading in Decision Analysis, 2nd Ed. Stanford Research Institute, Menlo Park, CA.","category":"page"}]
}
