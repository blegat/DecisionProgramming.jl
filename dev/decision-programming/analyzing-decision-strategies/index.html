<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Analyzing Decision Strategies · DecisionProgramming.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="DecisionProgramming.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">DecisionProgramming.jl</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Decision Programming</span><ul><li><a class="tocitem" href="../influence-diagram/">Influence Diagram</a></li><li><a class="tocitem" href="../decision-model/">Decision Model</a></li><li class="is-active"><a class="tocitem" href>Analyzing Decision Strategies</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Generating-Compatible-Paths"><span>Generating Compatible Paths</span></a></li><li><a class="tocitem" href="#Utility-Distribution"><span>Utility Distribution</span></a></li><li><a class="tocitem" href="#Measuring-Risk"><span>Measuring Risk</span></a></li><li><a class="tocitem" href="#State-Probabilities"><span>State Probabilities</span></a></li></ul></li><li><a class="tocitem" href="../computational-complexity/">Computational Complexity</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/used-car-buyer/">Used Car Buyer</a></li><li><a class="tocitem" href="../../examples/pig-breeding/">Pig Breeding</a></li><li><a class="tocitem" href="../../examples/n-monitoring/">N-Monitoring</a></li><li><a class="tocitem" href="../../examples/contingent-portfolio-programming/">Contingent Portfolio Programming</a></li></ul></li><li><a class="tocitem" href="../../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Decision Programming</a></li><li class="is-active"><a href>Analyzing Decision Strategies</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Analyzing Decision Strategies</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/gamma-opt/DecisionProgramming.jl/blob/master/docs/src/decision-programming/analyzing-decision-strategies.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Analyzing-Decision-Strategies"><a class="docs-heading-anchor" href="#Analyzing-Decision-Strategies">Analyzing Decision Strategies</a><a id="Analyzing-Decision-Strategies-1"></a><a class="docs-heading-anchor-permalink" href="#Analyzing-Decision-Strategies" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>This section focuses on how we can analyze fixed decision strategies <span>$Z$</span> on an influence diagram <span>$G$</span>, such as ones resulting from the optimization. We can rule out all incompatible paths from the analysis because their path probability is zero, by only generating the compatible paths <span>$𝐬∈𝐒(Z).$</span> However, compatible paths may still contain inactive paths if the influence diagram contains inactive chance states. The other property of compatible paths is that their path probability is equal to the upper bound <span>$p(𝐬).$</span></p><h2 id="Generating-Compatible-Paths"><a class="docs-heading-anchor" href="#Generating-Compatible-Paths">Generating Compatible Paths</a><a id="Generating-Compatible-Paths-1"></a><a class="docs-heading-anchor-permalink" href="#Generating-Compatible-Paths" title="Permalink"></a></h2><p>We can generate compatible paths <span>$𝐬∈𝐒(Z)$</span> as follows.</p><ol><li>Initialize path <span>$𝐬$</span> of length <span>$n$</span> with undefined values.</li><li>Fill path with chance states <span>$𝐬_j∈S_j$</span> for all <span>$j∈C.$</span></li><li>In increasing order of decision nodes <span>$j∈D$</span>, fill decision states by computing decision strategy <span>$𝐬_j=Z_j(𝐬_{I(j)}).$</span></li></ol><h2 id="Utility-Distribution"><a class="docs-heading-anchor" href="#Utility-Distribution">Utility Distribution</a><a id="Utility-Distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Utility-Distribution" title="Permalink"></a></h2><p>We define unique path utility values as</p><div>\[\mathcal{U}^∗=\{\mathcal{U}(𝐬)∣𝐬∈𝐒(Z)\}.\]</div><p>The probability mass function of the <strong>utility distribution</strong> associates each unique path utility to a probability as follows</p><div>\[ℙ(X=u)=∑_{𝐬∈𝐒(Z)∣\mathcal{U}(𝐬)=u} p(𝐬),\quad ∀u∈\mathcal{U}^∗.\]</div><p>From the utility distribution, we can calculate the cumulative distribution, statistics, and risk measures. The relevant statistics are expected value, standard deviation, skewness and kurtosis. Risk measures focus on the conditional value-at-risk (CVaR), also known as, expected shortfall.</p><h2 id="Measuring-Risk"><a class="docs-heading-anchor" href="#Measuring-Risk">Measuring Risk</a><a id="Measuring-Risk-1"></a><a class="docs-heading-anchor-permalink" href="#Measuring-Risk" title="Permalink"></a></h2><p><img src="../figures/risk_measures.svg" alt/></p><p>We have a discrete probability distribution <span>$f(x)=ℙ(X=x)∈[0, 1]$</span> over the domain <span>$x∈Ω$</span> with <span>$∑_{x∈Ω}ℙ(X=x)=1$</span> and its cumulative distribution function <span>$F(x) = ∑_{x^′∈Ω∣x^′≤x}f(x^′).$</span></p><p>We present the concept of conditional value-at-risk, a <em>risk measure</em> of the conditional expected value of the tail of a probability distribution for a given threshold of <span>$α∈(0, 1).$</span> First, we define the <strong>value-at-risk</strong> as</p><div>\[\operatorname{VaR}(α) = x_α = \inf\{x∈Ω ∣ F(x) &gt; α\}.\]</div><p>Then, we define the <strong>conditional value-at-risk</strong> as</p><div>\[\operatorname{CVaR}(α)=\left(∑_{x≤x_α} x ⋅ f(x) - \left(∑_{x≤x_α} f(x) - α\right) x_α \right) / α.\]</div><p>In the above figure, we have an example of discrete probability distribution with a positive expected value (<em>green diamond</em>) and its cumulative distribution. The <em>red horizontal line</em> represents the threshold <span>$α$</span> and the <em>yellow diamond</em> marks the value-at-risk <span>$x_α$</span>, that is, the smallest value <span>$x$</span> such that the cumulative probability is above <span>$α.$</span> The <em>red circles</em> are the values <span>$x$</span> below that fall below or equal <span>$x_α$</span> and the <em>orange diamond</em> is the conditional value-at-risk.</p><h2 id="State-Probabilities"><a class="docs-heading-anchor" href="#State-Probabilities">State Probabilities</a><a id="State-Probabilities-1"></a><a class="docs-heading-anchor-permalink" href="#State-Probabilities" title="Permalink"></a></h2><p>We denote <strong>paths with fixed states</strong> where <span>$ϵ$</span> denotes an empty state using a recursive definition.</p><div>\[\begin{aligned}
𝐒_{ϵ} &amp;= 𝐒(Z) \\
𝐒_{ϵ,s_i} &amp;= \{𝐬∈𝐒_{ϵ} ∣ 𝐬_i=s_i\} \\
𝐒_{ϵ,s_i,s_j} &amp;= \{𝐬∈𝐒_{ϵ,s_i} ∣ 𝐬_j=s_j\},\quad j≠i
\end{aligned}\]</div><p>The probability of all paths sums to one</p><div>\[ℙ(ϵ) = \sum_{𝐬∈𝐒_ϵ} p(𝐬) = 1.\]</div><p><strong>State probabilities</strong> for each node <span>$i∈C∪D$</span> and state <span>$s_i∈S_i$</span> denote how likely the state occurs given all path probabilities</p><div>\[ℙ(s_i∣ϵ) = \sum_{𝐬∈𝐒_{ϵ,s_i}} \frac{p(𝐬)}{ℙ(ϵ)} = \sum_{𝐬∈𝐒_{ϵ,s_i}} p(𝐬)\]</div><p>An <strong>active state</strong> is a state with positive state probability <span>$ℙ(s_i∣c)&gt;0$</span> given conditions <span>$c.$</span></p><p>We can <strong>generalize the state probabilities</strong> as conditional probabilities using a recursive definition. Generalized state probabilities allow us to explore how fixing active states affect the probabilities of other states. First, we choose an active state <span>$s_i$</span> and fix its value. Fixing an inactive state would make all state probabilities zero. Then, we can compute the conditional state probabilities as follows.</p><div>\[ℙ(s_j∣ϵ,s_i) = \sum_{𝐬∈𝐒_{ϵ,s_i,s_j}} \frac{p(𝐬)}{ℙ(s_i∣ϵ)}\]</div><p>We can then repeat this process by choosing an active state from the new conditional state probabilities <span>$s_k$</span> that is different from previously chosen states <span>$k≠j.$</span></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../decision-model/">« Decision Model</a><a class="docs-footer-nextpage" href="../computational-complexity/">Computational Complexity »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 19 August 2020 09:56">Wednesday 19 August 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
