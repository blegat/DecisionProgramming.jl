<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Decision Model · DecisionProgramming.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="DecisionProgramming.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">DecisionProgramming.jl</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Decision Programming</span><ul><li><a class="tocitem" href="../influence-diagram/">Influence Diagram</a></li><li class="is-active"><a class="tocitem" href>Decision Model</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Decision-Variables"><span>Decision Variables</span></a></li><li><a class="tocitem" href="#Path-Probability-Variables"><span>Path Probability Variables</span></a></li><li><a class="tocitem" href="#Positive-Path-Utility"><span>Positive Path Utility</span></a></li><li><a class="tocitem" href="#Lazy-Constraints"><span>Lazy Constraints</span></a></li><li><a class="tocitem" href="#Expected-Value"><span>Expected Value</span></a></li><li><a class="tocitem" href="#Conditional-Value-at-Risk"><span>Conditional Value-at-Risk</span></a></li><li><a class="tocitem" href="#Mixed-Objective"><span>Mixed Objective</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../analyzing-decision-strategies/">Analyzing Decision Strategies</a></li><li><a class="tocitem" href="../computational-complexity/">Computational Complexity</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/used-car-buyer/">Used Car Buyer</a></li><li><a class="tocitem" href="../../examples/pig-breeding/">Pig Breeding</a></li><li><a class="tocitem" href="../../examples/n-monitoring/">N-Monitoring</a></li><li><a class="tocitem" href="../../examples/contingent-portfolio-programming/">Contingent Portfolio Programming</a></li></ul></li><li><a class="tocitem" href="../../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Decision Programming</a></li><li class="is-active"><a href>Decision Model</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Decision Model</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/gamma-opt/DecisionProgramming.jl/blob/master/docs/src/decision-programming/decision-model.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="decision-model"><a class="docs-heading-anchor" href="#decision-model">Decision Model</a><a id="decision-model-1"></a><a class="docs-heading-anchor-permalink" href="#decision-model" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p><strong>Decision programming</strong> aims to find an optimal decision strategy <span>$Z$</span> from all decision strategies <span>$ℤ$</span> by maximizing an objective function <span>$f$</span> on the path distribution of an influence diagram</p><div>\[\underset{Z∈ℤ}{\text{maximize}}\quad f(\{(ℙ(𝐬∣Z), \mathcal{U}(𝐬)) ∣ 𝐬∈𝐒\}). \tag{1}\]</div><p><strong>Decision model</strong> refers to the mixed-integer linear programming formulation of this optimization problem. This page explains how to express decision strategy, path probability, path utility, and the objective in the mixed-integer linear form. We also present standard objective functions, including expected value and risk measures.  We based the decision model on <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>, sections 3 and 5. We recommend reading the references for motivation, details, and proofs of the formulation.</p><h2 id="Decision-Variables"><a class="docs-heading-anchor" href="#Decision-Variables">Decision Variables</a><a id="Decision-Variables-1"></a><a class="docs-heading-anchor-permalink" href="#Decision-Variables" title="Permalink"></a></h2><p><strong>Decision variables</strong> <span>$z(s_j∣𝐬_{I(j)})$</span> are equivalent to the decision strategies <span>$Z$</span> such that <span>$Z_j(𝐬_I(j))=s_j$</span> if and only if <span>$z(s_j∣𝐬_{I(j)})=1$</span> and <span>$z(s_{j}^′∣𝐬_{I(j)})=0$</span> for all <span>$s_{j}^′∈S_j∖s_j.$</span> Constraint <span>$(2)$</span> defines the decisions to be binary variables and the constraint <span>$(3)$</span> limits decisions to one per information path.</p><div>\[z(s_j∣𝐬_{I(j)}) ∈ \{0,1\},\quad ∀j∈D, s_j∈S_j, 𝐬_{I(j)}∈𝐒_{I(j)} \tag{2}\]</div><div>\[∑_{s_j∈S_j} z(s_j∣𝐬_{I(j)})=1,\quad ∀j∈D, 𝐬_{I(j)}∈𝐒_{I(j)} \tag{3}\]</div><h2 id="Path-Probability-Variables"><a class="docs-heading-anchor" href="#Path-Probability-Variables">Path Probability Variables</a><a id="Path-Probability-Variables-1"></a><a class="docs-heading-anchor-permalink" href="#Path-Probability-Variables" title="Permalink"></a></h2><p><strong>Path probability variables</strong> <span>$π(𝐬)$</span> are equivalent to the path probabilities <span>$ℙ(𝐬∣Z)$</span> where decision variables <span>$z$</span> define the decision strategy <span>$Z$</span>. The constraint <span>$(4)$</span> defines the lower and upper bound to the probability, constraint <span>$(5)$</span> defines that the probability equals zero if path is not compatible with the decision strategy, and constraint <span>$(6)$</span> defines that probability equals path probability if the path is compatible with the decision strategy.</p><div>\[0≤π(𝐬)≤p(𝐬),\quad ∀𝐬∈𝐒 \tag{4}\]</div><div>\[π(𝐬) ≤ z(𝐬_j∣𝐬_{I(j)}),\quad ∀j∈D, 𝐬∈𝐒 \tag{5}\]</div><div>\[π(𝐬) ≥ p(𝐬) + ∑_{j∈D} z(𝐬_j∣𝐬_{I(j)}) - |D|,\quad ∀𝐬∈𝐒 \tag{6}\]</div><h2 id="Positive-Path-Utility"><a class="docs-heading-anchor" href="#Positive-Path-Utility">Positive Path Utility</a><a id="Positive-Path-Utility-1"></a><a class="docs-heading-anchor-permalink" href="#Positive-Path-Utility" title="Permalink"></a></h2><p>We can omit the constraint <span>$(6)$</span> from the model if we use a <strong>positive path utility</strong> function <span>$\mathcal{U}^+$</span> which is an affine transformation of path utility function <span>$\mathcal{U}.$</span> As an example, we can subtract the minimum of the original utility function and then add one as follows.</p><div>\[\mathcal{U}^+(𝐬) = \mathcal{U}(𝐬) - \min_{𝐬∈𝐒} \mathcal{U}(𝐬) + 1.\]</div><h2 id="Lazy-Constraints"><a class="docs-heading-anchor" href="#Lazy-Constraints">Lazy Constraints</a><a id="Lazy-Constraints-1"></a><a class="docs-heading-anchor-permalink" href="#Lazy-Constraints" title="Permalink"></a></h2><p>Valid equalities are equalities that can be be derived from the problem structure. They can help in computing the optimal decision strategies, but adding them directly may slow down the overall solution process. By adding valid equalities during the solution process as <em>lazy constraints</em>, the MILP solver can prune nodes of the branch-and-bound tree more efficiently. We have the following valid equalities.</p><h3 id="Probability-Cut"><a class="docs-heading-anchor" href="#Probability-Cut">Probability Cut</a><a id="Probability-Cut-1"></a><a class="docs-heading-anchor-permalink" href="#Probability-Cut" title="Permalink"></a></h3><p>We can exploit the fact that the path probabilities sum to one by using the <strong>probability cut</strong> defined as</p><div>\[∑_{𝐬∈𝐒}π(𝐬)=1. \tag{7}\]</div><h3 id="Active-Paths-Cut"><a class="docs-heading-anchor" href="#Active-Paths-Cut">Active Paths Cut</a><a id="Active-Paths-Cut-1"></a><a class="docs-heading-anchor-permalink" href="#Active-Paths-Cut" title="Permalink"></a></h3><p>For problems where the number of active paths is known, we can exploit it by using the <strong>active paths cut</strong> defined as</p><div>\[∑_{𝐬∈𝐒} \frac{π(𝐬)}{p(𝐬)}=|𝐒^+(Z)|. \tag{8}\]</div><h2 id="Expected-Value"><a class="docs-heading-anchor" href="#Expected-Value">Expected Value</a><a id="Expected-Value-1"></a><a class="docs-heading-anchor-permalink" href="#Expected-Value" title="Permalink"></a></h2><p>We define the <strong>expected value</strong> objective as</p><div>\[\operatorname{E}(Z) = ∑_{𝐬∈𝐒} π(𝐬) \mathcal{U}(𝐬). \tag{?}\]</div><h2 id="Conditional-Value-at-Risk"><a class="docs-heading-anchor" href="#Conditional-Value-at-Risk">Conditional Value-at-Risk</a><a id="Conditional-Value-at-Risk-1"></a><a class="docs-heading-anchor-permalink" href="#Conditional-Value-at-Risk" title="Permalink"></a></h2><p>The section <a href="../analyzing-decision-strategies/#Measuring-Risk">Measuring Risk</a> explains and visualizes the relationships between the formulation of expected value, value-at-risk and conditional value-at-risk for discrete probability distribution.</p><p>Given decision strategy <span>$Z,$</span> we define the cumulative distribution of path probability variables as</p><div>\[F_Z(t) = ∑_{𝐬∈𝐒∣\mathcal{U}(𝐬)≤t} π(𝐬).\]</div><p>Given a <strong>probability level</strong> <span>$α∈(0, 1],$</span> we define the <strong>value-at-risk</strong> as</p><div>\[\operatorname{VaR}_α(Z)=u_α=\sup \{\mathcal{U}(𝐬)∣𝐬∈𝐒, F_Z(\mathcal{U}(𝐬))&lt;α\}.\]</div><p>Then, we have the paths that have path utility less than and equal to the value-at-risk as</p><div>\[𝐒_{α}^{&lt;}=\{𝐬∈𝐒∣\mathcal{U}(𝐬)&lt;u_α\},\]</div><div>\[𝐒_{α}^{=}=\{𝐬∈𝐒∣\mathcal{U}(𝐬)=u_α\}.\]</div><p>We define <strong>conditional value-at-risk</strong> as</p><div>\[\operatorname{CVaR}_α(Z)=\frac{1}{α}\left(∑_{𝐬∈𝐒_α^{&lt;}} π(𝐬) \mathcal{U}(𝐬) + ∑_{𝐬∈𝐒_α^{=}} \left(α - ∑_{𝐬∈𝐒_α^{&lt;}} π(𝐬) \right) \mathcal{U}(𝐬) \right).\]</div><p>We can form the conditional value-at-risk as an optimization problem. We have the following pre-computed parameters.</p><p>Lower and upper bound of the value-at-risk</p><div>\[\operatorname{VaR}_0(Z)=u^-=\min\{\mathcal{U}(𝐬)∣𝐬∈𝐒\},\]</div><div>\[\operatorname{VaR}_1(Z)=u^+=\max\{\mathcal{U}(𝐬)∣𝐬∈𝐒\}.\]</div><p>Largest difference between path utilities</p><div>\[M=u^+-u^-.\]</div><p>Half of the smallest positive difference between path utilities</p><div>\[ϵ=\frac{1}{2} \min\{|\mathcal{U}(𝐬)-\mathcal{U}(𝐬^′)| ∣ |\mathcal{U}(𝐬)-\mathcal{U}(𝐬^′)| &gt; 0, 𝐬, 𝐬^′∈𝐒\}.\]</div><p>The objective is to minimize the variable <span>$η$</span> whose optimal value is equal to the value-at-risk, that is, <span>$\operatorname{VaR}_α(Z)=η^∗.$</span></p><div>\[\min η\]</div><p>We define the constraints as follows:</p><div>\[η-\mathcal{U}(𝐬)≤M λ(𝐬),\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[η-\mathcal{U}(𝐬)≥(M+ϵ) λ(𝐬) - M,\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[η-\mathcal{U}(𝐬)≤(M+ϵ) \bar{λ}(𝐬) - ϵ,\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[η-\mathcal{U}(𝐬)≥M (\bar{λ}(𝐬) - 1),\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[\bar{ρ}(𝐬) ≤ \bar{λ}(𝐬),\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[π(𝐬) - (1 - λ(𝐬)) ≤ ρ(𝐬) ≤ λ(𝐬),\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[ρ(𝐬) ≤ \bar{ρ}(𝐬) ≤ π(𝐬),\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[∑_{𝐬∈𝐒}\bar{ρ}(𝐬) = α \tag{?}\]</div><div>\[\bar{λ}(𝐬), λ(𝐬)∈\{0, 1\},\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[\bar{ρ}(𝐬),ρ(𝐬)∈[0, 1],\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[η∈[u^-, u^+] \tag{?}\]</div><p>We can express the conditional value-at-risk objective as</p><div>\[\operatorname{CVaR}_α(Z)=\frac{1}{α}∑_{𝐬∈𝐒}\bar{ρ}(𝐬) \mathcal{U}(𝐬)\tag{?}.\]</div><p>The values of conditional value-at-risk are limited to the interval between the lower bound of value-at-risk and the expected value</p><div>\[\operatorname{VaR}_0(Z)&lt;\operatorname{CVaR}_α(Z)≤E(Z).\]</div><h2 id="Mixed-Objective"><a class="docs-heading-anchor" href="#Mixed-Objective">Mixed Objective</a><a id="Mixed-Objective-1"></a><a class="docs-heading-anchor-permalink" href="#Mixed-Objective" title="Permalink"></a></h2><p>We can combine expected value and conditional value-at-risk using a convex combination at a fixed probability level <span>$α$</span> as follows</p><div>\[w \operatorname{E}(Z) + (1-w) \operatorname{CVaR}_α(Z), \tag{?}\]</div><p>where the parameter <span>$w∈(0, 1)$</span> expresses the decision maker&#39;s risk tolerance.</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Salo, A., Andelmin, J., &amp; Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from <a href="http://arxiv.org/abs/1910.09196">http://arxiv.org/abs/1910.09196</a></li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../influence-diagram/">« Influence Diagram</a><a class="docs-footer-nextpage" href="../analyzing-decision-strategies/">Analyzing Decision Strategies »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Friday 4 September 2020 04:56">Friday 4 September 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
