<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Decision Model · DecisionProgramming.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="DecisionProgramming.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">DecisionProgramming.jl</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Decision Programming</span><ul><li><a class="tocitem" href="../influence-diagram/">Influence Diagram</a></li><li class="is-active"><a class="tocitem" href>Decision Model</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Formulation"><span>Formulation</span></a></li><li><a class="tocitem" href="#Lazy-Constraints"><span>Lazy Constraints</span></a></li><li><a class="tocitem" href="#Expected-Value"><span>Expected Value</span></a></li><li><a class="tocitem" href="#Conditional-Value-at-Risk"><span>Conditional Value-at-Risk</span></a></li><li><a class="tocitem" href="#Mixed-Objective"><span>Mixed Objective</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../analyzing-decision-strategies/">Analyzing Decision Strategies</a></li><li><a class="tocitem" href="../computational-complexity/">Computational Complexity</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/used-car-buyer/">Used Car Buyer</a></li><li><a class="tocitem" href="../../examples/pig-breeding/">Pig Breeding</a></li><li><a class="tocitem" href="../../examples/n-monitoring/">N-Monitoring</a></li><li><a class="tocitem" href="../../examples/contingent-portfolio-programming/">Contingent Portfolio Programming</a></li><li><a class="tocitem" href="../../examples/multi-period-investment/">Multi-period Investment</a></li></ul></li><li><a class="tocitem" href="../../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Decision Programming</a></li><li class="is-active"><a href>Decision Model</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Decision Model</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/gamma-opt/DecisionProgramming.jl/blob/master/docs/src/decision-programming/decision-model.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Decision-Model"><a class="docs-heading-anchor" href="#Decision-Model">Decision Model</a><a id="Decision-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Decision-Model" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p><strong>Decision programming</strong> aims to find a decision strategy <span>$Z$</span> which optimizes some metric of the path distribution on an influence diagram such as expected value or risk. The <strong>decision model</strong> is a mixed-integer linear programming formulation of this optimization problem. The model that is presented here, is based on <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>, sections 3 and 5. We recommend reading it for motivation, details, and proofs of the formulation.</p><h2 id="Formulation"><a class="docs-heading-anchor" href="#Formulation">Formulation</a><a id="Formulation-1"></a><a class="docs-heading-anchor-permalink" href="#Formulation" title="Permalink"></a></h2><p>The mixed-integer linear program maximizes a linear objective function <span>$f$</span> that acts on the path distribution over all decision strategies as follows.</p><div>\[\underset{Z∈ℤ}{\text{maximize}}\quad
f(\{(ℙ(𝐬∣Z), \mathcal{U}(𝐬)) ∣ 𝐬∈𝐒\}) \tag{1}\]</div><p><strong>Decision variables</strong> <span>$z(s_j∣𝐬_{I(j)})$</span> are equivalent to the decision strategies <span>$Z$</span> such that <span>$Z_j(𝐬_I(j))=s_j$</span> if and only if <span>$z(s_j∣𝐬_{I(j)})=1$</span> and <span>$z(s_{j^′}∣𝐬_{I(j)})=0$</span> for all <span>$s_{j^′}≠s_j.$</span> Constraint <span>$(2)$</span> defines the decisions to be binary variables and the constraint <span>$(3)$</span> limits decisions to one per information path.</p><div>\[z(𝐬_j∣𝐬_{I(j)}) ∈ \{0,1\},\quad ∀j∈D, 𝐬_j∈𝐒_j, 𝐬_{I(j)}∈𝐒_{I(j)} \tag{2}\]</div><div>\[∑_{s_j∈S_j} z(s_j∣𝐬_{I(j)})=1,\quad ∀j∈D, 𝐬_{I(j)}∈𝐒_{I(j)} \tag{3}\]</div><p><strong>Path probability variables</strong> <span>$π(𝐬)$</span> are equivalent to the path probabilities <span>$ℙ(𝐬∣Z)$</span> where decision variables <span>$z$</span> define the decision strategy <span>$Z$</span>. The constraint <span>$(4)$</span> defines the lower and upper bound to the probability, constraint <span>$(5)$</span> defines that the probability equals zero if path is not compatible with the decision strategy, and constraint <span>$(6)$</span> defines that probability equals path probability if the path is compatible with the decision strategy.</p><div>\[0≤π(𝐬)≤p(𝐬),\quad ∀𝐬∈𝐒 \tag{4}\]</div><div>\[π(𝐬) ≤ z(𝐬_j∣𝐬_{I(j)}),\quad ∀j∈D, 𝐬∈𝐒 \tag{5}\]</div><div>\[π(𝐬) ≥ p(𝐬) + ∑_{j∈D} z(𝐬_j∣𝐬_{I(j)}) - |D|,\quad ∀𝐬∈𝐒 \tag{6}\]</div><p>We can omit the constraint <span>$(6)$</span> from the model if we use a <strong>positive path utility</strong> function <span>$\mathcal{U}^+$</span> which is an affine transformation of path utility function <span>$\mathcal{U}.$</span> As an example, we can subtract the minimum of the original utility function and then add one as follows.</p><div>\[\mathcal{U}^+(𝐬) = \mathcal{U}(𝐬) - \min_{𝐬∈𝐒} \mathcal{U}(𝐬) + 1.\]</div><p>Next we discuss lazy constraint and concrete objective functions below.</p><h2 id="Lazy-Constraints"><a class="docs-heading-anchor" href="#Lazy-Constraints">Lazy Constraints</a><a id="Lazy-Constraints-1"></a><a class="docs-heading-anchor-permalink" href="#Lazy-Constraints" title="Permalink"></a></h2><p>Valid equalities are equalities that can be be derived from the problem structure. They can help in computing the optimal decision strategies, but adding them directly may slow down the overall solution process. By adding valid equalities during the solution process as <em>lazy constraints</em>, the MILP solver can prune nodes of the branch-and-bound tree more efficiently. We have the following valid equalities.</p><p>We can exploit the fact that the path probabilities sum to one by using the <strong>probability sum cut</strong></p><div>\[∑_{𝐬∈𝐒}π(𝐬)=1. \tag{7}\]</div><p>For problems where the number of active paths <span>$|𝐒^Z|$</span> is known, we can exploit it by using the <strong>number of active paths cut</strong></p><div>\[∑_{𝐬∈𝐒} \frac{π(𝐬)}{p(𝐬)}=|𝐒^Z|. \tag{8}\]</div><h2 id="Expected-Value"><a class="docs-heading-anchor" href="#Expected-Value">Expected Value</a><a id="Expected-Value-1"></a><a class="docs-heading-anchor-permalink" href="#Expected-Value" title="Permalink"></a></h2><p>We define the <strong>expected value</strong> as</p><div>\[\operatorname{E}(Z) = ∑_{𝐬∈𝐒} π(𝐬) \mathcal{U}(𝐬). \tag{?}\]</div><p>However, the expected value objective does not account for risk caused by the variablity in the path distribution.</p><h2 id="Conditional-Value-at-Risk"><a class="docs-heading-anchor" href="#Conditional-Value-at-Risk">Conditional Value-at-Risk</a><a id="Conditional-Value-at-Risk-1"></a><a class="docs-heading-anchor-permalink" href="#Conditional-Value-at-Risk" title="Permalink"></a></h2><p>Given a <strong>probability level</strong> <span>$α∈(0, 1]$</span> and decision strategy <span>$Z$</span> we denote <strong>value-at-Risk</strong> <span>$\operatorname{VaR}_α(Z)$</span> and <strong>conditional Value-at-Risk</strong> <span>$\operatorname{CVaR}_α(Z).$</span></p><p>Pre-computed parameters</p><div>\[u^+=\max\{\mathcal{U}(𝐬)∣𝐬∈𝐒\}\]</div><div>\[u^-=\min\{\mathcal{U}(𝐬)∣𝐬∈𝐒\}\]</div><div>\[M=u^+-u^-\]</div><div>\[ϵ=\frac{1}{2} \min\{|\mathcal{U}(𝐬)-\mathcal{U}(𝐬^′)| ∣ |\mathcal{U}(𝐬)-\mathcal{U}(𝐬^′)| &gt; 0, 𝐬, 𝐬^′∈𝐒\}\]</div><p>Objective</p><div>\[\min η\]</div><p>Constraints</p><div>\[η-\mathcal{U}(𝐬)≤M λ(𝐬),\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[η-\mathcal{U}(𝐬)≥(M+ϵ) λ(𝐬) - M,\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[η-\mathcal{U}(𝐬)≤(M+ϵ) \bar{λ}(𝐬) - ϵ,\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[η-\mathcal{U}(𝐬)≥M (\bar{λ}(𝐬) - 1),\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[\bar{ρ}(𝐬) ≤ \bar{λ}(𝐬),\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[π(𝐬) - (1 - λ(𝐬)) ≤ ρ(𝐬) ≤ λ(𝐬),\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[ρ(𝐬) ≤ \bar{ρ}(𝐬) ≤ π(𝐬),\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[∑_{𝐬∈𝐒}\bar{ρ}(𝐬) = α \tag{?}\]</div><div>\[\bar{λ}(𝐬), λ(𝐬)∈\{0, 1\},\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[\bar{ρ}(𝐬),ρ(𝐬)∈[0, 1],\quad ∀𝐬∈𝐒 \tag{?}\]</div><div>\[η∈[u^-, u^+] \tag{?}\]</div><p>Solution</p><div>\[\operatorname{VaR}_α(Z)=η \tag{?}\]</div><div>\[\operatorname{CVaR}_α(Z)=\frac{1}{α}∑_{𝐬∈𝐒}\bar{ρ}(𝐬) \mathcal{U}(𝐬)\tag{?}\]</div><h2 id="Mixed-Objective"><a class="docs-heading-anchor" href="#Mixed-Objective">Mixed Objective</a><a id="Mixed-Objective-1"></a><a class="docs-heading-anchor-permalink" href="#Mixed-Objective" title="Permalink"></a></h2><p>We can formulate</p><div>\[w \operatorname{E}(Z) + (1-w) \operatorname{CVaR}_α(Z) \tag{?}\]</div><p>where <span>$w∈(0, 1)$</span> is the <strong>trade-off</strong> between maximization of</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Salo, A., Andelmin, J., &amp; Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from <a href="http://arxiv.org/abs/1910.09196">http://arxiv.org/abs/1910.09196</a></li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../influence-diagram/">« Influence Diagram</a><a class="docs-footer-nextpage" href="../analyzing-decision-strategies/">Analyzing Decision Strategies »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Friday 14 August 2020 09:02">Friday 14 August 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
