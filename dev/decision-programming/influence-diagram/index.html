<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Influence Diagram · DecisionProgramming.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="DecisionProgramming.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">DecisionProgramming.jl</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Decision Programming</span><ul><li class="is-active"><a class="tocitem" href>Influence Diagram</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Definition"><span>Definition</span></a></li><li><a class="tocitem" href="#Root-and-Leaf-Nodes"><span>Root and Leaf Nodes</span></a></li><li><a class="tocitem" href="#Visualization"><span>Visualization</span></a></li><li><a class="tocitem" href="#Paths"><span>Paths</span></a></li><li><a class="tocitem" href="#Probabilities"><span>Probabilities</span></a></li><li><a class="tocitem" href="#Decision-Strategy"><span>Decision Strategy</span></a></li><li><a class="tocitem" href="#Path-Probability"><span>Path Probability</span></a></li><li><a class="tocitem" href="#Consequences"><span>Consequences</span></a></li><li><a class="tocitem" href="#Path-Utility"><span>Path Utility</span></a></li><li><a class="tocitem" href="#Path-Distribution"><span>Path Distribution</span></a></li><li><a class="tocitem" href="#Active-Paths"><span>Active Paths</span></a></li><li><a class="tocitem" href="#Properties"><span>Properties</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../decision-model/">Decision Model</a></li><li><a class="tocitem" href="../analyzing-decision-strategies/">Analyzing Decision Strategies</a></li><li><a class="tocitem" href="../computational-complexity/">Computational Complexity</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/used-car-buyer/">Used Car Buyer</a></li><li><a class="tocitem" href="../../examples/pig-breeding/">Pig Breeding</a></li><li><a class="tocitem" href="../../examples/n-monitoring/">N-Monitoring</a></li><li><a class="tocitem" href="../../examples/contingent-portfolio-programming/">Contingent Portfolio Programming</a></li></ul></li><li><a class="tocitem" href="../../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Decision Programming</a></li><li class="is-active"><a href>Influence Diagram</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Influence Diagram</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/gamma-opt/DecisionProgramming.jl/blob/master/docs/src/decision-programming/influence-diagram.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Influence-Diagram"><a class="docs-heading-anchor" href="#Influence-Diagram">Influence Diagram</a><a id="Influence-Diagram-1"></a><a class="docs-heading-anchor-permalink" href="#Influence-Diagram" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>Based on <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>, sections 3.</p><p>The paper <sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup> explains details about influence diagrams.</p><h2 id="Definition"><a class="docs-heading-anchor" href="#Definition">Definition</a><a id="Definition-1"></a><a class="docs-heading-anchor-permalink" href="#Definition" title="Permalink"></a></h2><p>We define the <strong>influence diagram</strong> as a directed, acyclic graph</p><div>\[G=(C,D,V,I,S).\]</div><p>The nodes <span>$N=C∪D∪V$</span> consists of <strong>chance nodes</strong> <span>$C,$</span> <strong>decision nodes</strong> <span>$D,$</span> and <strong>value nodes</strong> <span>$V$</span>. We index the chance and decision nodes such that <span>$C∪D=\{1,...,n\}$</span> and values nodes such that <span>$V=\{n+1,...,n+|V|\}$</span> where <span>$n=|C|+|D|.$</span></p><p>We define the <strong>information set</strong> <span>$I$</span> of node <span>$j∈N$</span> as</p><div>\[I(j)⊆\{i∈C∪D∣i&lt;j\}\]</div><p>The condition enforces that the graph is directed and acyclic, and there are no arcs from value nodes to other nodes. Practically, the information set is an edge list to reverse direction in the graph.</p><p>We refer to <span>$S$</span> as the <strong>state space</strong>. Each chance and decision node <span>$j∈C∪D$</span> is associates with a finite number of <strong>states</strong> <span>$S_j$</span> that we encode using integers <span>$\{1,...,|S_j|\}$</span> from one to number of states <span>$|S_j|.$</span></p><h2 id="Root-and-Leaf-Nodes"><a class="docs-heading-anchor" href="#Root-and-Leaf-Nodes">Root and Leaf Nodes</a><a id="Root-and-Leaf-Nodes-1"></a><a class="docs-heading-anchor-permalink" href="#Root-and-Leaf-Nodes" title="Permalink"></a></h2><p>In the subdiagram of <span>$G$</span> which consists of the chance and decision nodes <span>$j∈C∪D,$</span> we call node <span>$j$</span> a <strong>root</strong> node if its information set if empty, that is, <span>$I(j)=∅.$</span></p><p>Similarly, we call node <span>$j$</span> a <strong>leaf</strong> node if it is not in any information set, that is, <span>$j∉I(i)$</span> for all <span>$i∈C∪D.$</span> Each leaf node must be in at least one of the information sets of value nodes. That is, for each leaf node <span>$j$</span> exists a value node <span>$i∈V$</span> such that <span>$j∈I(i).$</span> Otherwise, the node <span>$j$</span> is <strong>redundant</strong>.</p><h2 id="Visualization"><a class="docs-heading-anchor" href="#Visualization">Visualization</a><a id="Visualization-1"></a><a class="docs-heading-anchor-permalink" href="#Visualization" title="Permalink"></a></h2><p>To visualize influence diagrams, we define the different node types and how to order the nodes. There are two ways to order directed acyclic graphs, linear and depth-wise. We use <a href="https://www.diagrams.net/">diagrams.net</a> for drawing influence diagrams.</p><h3 id="Node-Types"><a class="docs-heading-anchor" href="#Node-Types">Node Types</a><a id="Node-Types-1"></a><a class="docs-heading-anchor-permalink" href="#Node-Types" title="Permalink"></a></h3><p><img src="../figures/node-types.svg" alt/></p><p>We use a circle to represent chance nodes, square to represent decision nodes and diamond to represent value nodes. The symbol <span>$i$</span> represents the node&#39;s index and symbol <span>$S_i$</span> the states of the chance or decision node.</p><h3 id="Linear-Order"><a class="docs-heading-anchor" href="#Linear-Order">Linear Order</a><a id="Linear-Order-1"></a><a class="docs-heading-anchor-permalink" href="#Linear-Order" title="Permalink"></a></h3><p><img src="../figures/linear-order.svg" alt/></p><p>We can order the nodes in increasing linear order based on indices.</p><h3 id="Depth-wise-Order"><a class="docs-heading-anchor" href="#Depth-wise-Order">Depth-wise Order</a><a id="Depth-wise-Order-1"></a><a class="docs-heading-anchor-permalink" href="#Depth-wise-Order" title="Permalink"></a></h3><p><img src="../figures/depth-wise-order.svg" alt/></p><p>We define the <strong>depth</strong> of a node <span>$j∈N$</span> as follows. Root nodes have a depth of one</p><div>\[\operatorname{depth}(j)=1,\quad I(j)=∅.\]</div><p>Other nodes have a depth of one greater than the maximum depth of its predecessors</p><div>\[\operatorname{depth}(j)=\max_{i∈I(j)} \operatorname{depth}(i) + 1,\quad I(j)≠∅.\]</div><p>We can group the nodes by their depth and then order them by increasing depth and increasing indices order within that depth. Compared to linear order, the depth-wise order is more concise. It displays more information about the influence relationships, because nodes can only be influenced by nodes with smaller depth.</p><h2 id="Paths"><a class="docs-heading-anchor" href="#Paths">Paths</a><a id="Paths-1"></a><a class="docs-heading-anchor-permalink" href="#Paths" title="Permalink"></a></h2><p>Paths in influence diagrams represent realizations of states for chance and decision nodes. Formally, a <strong>path</strong> is a sequence of states</p><div>\[𝐬=(s_1, s_2, ...,s_n),\]</div><p>where each state <span>$s_i∈S_i$</span> for all chance and decision nodes <span>$i∈C∪D.$</span></p><p>We define a <strong>subpath</strong> of <span>$𝐬$</span> is a subsequence</p><div>\[(𝐬_{i_1}, 𝐬_{i_2}, ..., 𝐬_{i_{k}}),\]</div><p>where <span>$1≤i_1&lt;i_2&lt;...&lt;i_k≤n$</span> and <span>$k≤n.$</span></p><p>The <strong>information path</strong> of node <span>$j∈N$</span> on path <span>$𝐬$</span> is a subpath defined as</p><div>\[𝐬_{I(j)}=(𝐬_i ∣ i∈I(j)).\]</div><p>We define the set of <strong>all paths</strong> as a product set of all states</p><div>\[𝐒=∏_{j∈C∪D} S_j.\]</div><p>The set of <strong>information paths</strong> of node <span>$j∈N$</span> is the product set of the states in its information set</p><div>\[𝐒_{I(j)}=∏_{i∈I(j)} S_i.\]</div><p>We denote elements of the sets using notation <span>$s_j∈S_j$</span>, <span>$𝐬∈𝐒$</span>, and <span>$𝐬_{I(j)}∈𝐒_{I(j)}.$</span></p><h2 id="Probabilities"><a class="docs-heading-anchor" href="#Probabilities">Probabilities</a><a id="Probabilities-1"></a><a class="docs-heading-anchor-permalink" href="#Probabilities" title="Permalink"></a></h2><p>For each chance node <span>$j∈C$</span>, we denote the <strong>probability</strong> of state <span>$s_j$</span> given information path <span>$𝐬_{I(j)}$</span> as</p><div>\[ℙ(X_j=s_j∣X_{I(j)}=𝐬_{I(j)})=ℙ(s_j∣𝐬_{I(j)})∈[0, 1],\]</div><p>with</p><div>\[∑_{s_j∈S_j} ℙ(s_j∣𝐬_{I(j)}) = 1.\]</div><p>We refer to a chance state <span>$s_j∈S_j$</span> given information path <span>$𝐬_{I(j)}$</span> as <strong>inactive</strong> if its probability is zero <span>$ℙ(s_j∣𝐬_{I(j)})=0.$</span></p><p>Implementation wise, we can think probabilities as functions of information paths concatenated with state <span>$X_j : 𝐒_{I(j)};S_j → [0, 1]$</span> where <span>$∑_{s_j∈S_j} X_j(𝐬_{I(j)};s_j)=1.$</span></p><h2 id="Decision-Strategy"><a class="docs-heading-anchor" href="#Decision-Strategy">Decision Strategy</a><a id="Decision-Strategy-1"></a><a class="docs-heading-anchor-permalink" href="#Decision-Strategy" title="Permalink"></a></h2><p>For each decision node <span>$j∈D,$</span> a <strong>local decision strategy</strong> maps an information path <span>$𝐬_{I(j)}$</span> to a state <span>$s_j$</span></p><div>\[Z_j:𝐒_{I(j)}↦S_j.\]</div><p><strong>Decision strategy</strong> <span>$Z$</span> contains one local decision strategy for each decision node. Set of <strong>all decision strategies</strong> is denoted <span>$ℤ.$</span></p><p>A decision stategy <span>$Z∈ℤ$</span> is <strong>compatible</strong> with the path <span>$𝐬∈𝐒$</span> if and only if <span>$Z_j(𝐬_{I(j)})=s_j$</span> forall <span>$Z_j∈Z$</span> and <span>$j∈D.$</span></p><h2 id="Path-Probability"><a class="docs-heading-anchor" href="#Path-Probability">Path Probability</a><a id="Path-Probability-1"></a><a class="docs-heading-anchor-permalink" href="#Path-Probability" title="Permalink"></a></h2><p>We define the <strong>path probability (upper bound)</strong> as</p><div>\[p(𝐬) = ∏_{j∈C} ℙ(𝐬_j∣𝐬_{I(j)}).\]</div><p>The path probability <span>$ℙ(𝐬∣Z)$</span> equals <span>$p(𝐬)$</span> if the path <span>$𝐬$</span> is compatible with the decision strategy <span>$Z$</span>. Otherwise, the path cannot occur, and the probability is zero.</p><h2 id="Consequences"><a class="docs-heading-anchor" href="#Consequences">Consequences</a><a id="Consequences-1"></a><a class="docs-heading-anchor-permalink" href="#Consequences" title="Permalink"></a></h2><p>For each value node <span>$j∈V$</span>, we define the <strong>consequence</strong> given information path <span>$𝐬_{I(j)}$</span> as</p><div>\[Y_j:𝐒_{I(j)}↦ℂ,\]</div><p>where <span>$ℂ$</span> is the set of real-valued consequences.</p><h2 id="Path-Utility"><a class="docs-heading-anchor" href="#Path-Utility">Path Utility</a><a id="Path-Utility-1"></a><a class="docs-heading-anchor-permalink" href="#Path-Utility" title="Permalink"></a></h2><p>The <strong>utility function</strong> is a function that maps consequences to real-valued utility</p><div>\[U:ℂ^{|V|}↦ℝ.\]</div><p>The <strong>path utility</strong> is defined as the utility function acting on the consequences of value nodes given their information paths</p><div>\[\mathcal{U}(𝐬) = U(\{Y_j(𝐬_{I(j)}) ∣ j∈V\}).\]</div><p>The <strong>default path utility</strong> is the sum of consequences</p><div>\[\mathcal{U}(𝐬) = ∑_{j∈V} Y_j(𝐬_{I(j)}).\]</div><h2 id="Path-Distribution"><a class="docs-heading-anchor" href="#Path-Distribution">Path Distribution</a><a id="Path-Distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Path-Distribution" title="Permalink"></a></h2><p>A <strong>path distribution</strong> is a pair</p><div>\[(ℙ(𝐬∣Z), \mathcal{U}(𝐬))\]</div><p>that comprises of path probability function and path utility function over paths <span>$𝐬∈𝐒$</span> conditional to the decision strategy <span>$Z.$</span></p><h2 id="Active-Paths"><a class="docs-heading-anchor" href="#Active-Paths">Active Paths</a><a id="Active-Paths-1"></a><a class="docs-heading-anchor-permalink" href="#Active-Paths" title="Permalink"></a></h2><p>An <strong>active path</strong> is a path <span>$𝐬∈𝐒$</span> that has positive path probability <span>$ℙ(𝐬∣Z)&gt;0.$</span> We denote the set of <strong>all active paths</strong> given a decision strategy <span>$Z$</span> as</p><div>\[𝐒(Z)=\{𝐬∈𝐒 ∣ ℙ(𝐬∣Z)&gt;0\}.\]</div><p>Since each decision strategy <span>$Z_j$</span> chooses only one of its states the <strong>number of active paths</strong> is bounded by</p><div>\[|𝐒(Z)|≤|𝐒|/\prod_{j∈D}|S_j|=\prod_{j∈C}|S_j|.\]</div><p>If an influece diagram has <strong>zero inactive chance states</strong> the number of active paths is equal to the upper bound</p><div>\[|𝐒(Z)|=\prod_{j∈C}|S_j|.\]</div><h2 id="Properties"><a class="docs-heading-anchor" href="#Properties">Properties</a><a id="Properties-1"></a><a class="docs-heading-anchor-permalink" href="#Properties" title="Permalink"></a></h2><p>In this section, we define common properties for influence diagrams. The paper <sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup> discusses many of these properties.</p><p><strong>Discrete</strong> influence diagram refers to countable state space. Otherwise, the influence diagram is <strong>continuous</strong>. We can discretize continuous influence diagrams using discrete bins.</p><p>Influence diagram is <strong>symmetric</strong> if there is zero inactive chance states. Otherwise, it is <strong>assymetric</strong>.</p><p>Two nodes are <strong>sequential</strong> if there exists a directed path from one node to the other in the influence diagram. Otherwise, the nodes are <strong>parallel</strong>. Sequential nodes often model time dimension.</p><p><strong>Repeated subdiagram</strong> refers to a recurring pattern within an influence diagram. Often, influence diagrams do not have a unique structure, but they consist of a repeated pattern due to the underlying problem&#39;s properties.</p><p><strong>Limited-memory</strong> influence diagram refers to an influence diagram where an upper bound limits the size of the information set for decision nodes. It is a desired attribute because it affects the decision model size, as discussed in the <a href="../computational-complexity/#Computational-Complexity">Computational Complexity</a> section.</p><p><strong>Isolated subdiagrams</strong> refer to an influence diagram that consists of multiple unconnected diagrams, that is, there are no undirected connections between the diagrams. Therefore, one isolated subdiagram&#39;s decisions affect decisions on the other isolated subdiagrams only through the utility function.</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Salo, A., Andelmin, J., &amp; Oliveira, F. (2019). Decision Programming for Multi-Stage Optimization under Uncertainty, 1–35. Retrieved from <a href="http://arxiv.org/abs/1910.09196">http://arxiv.org/abs/1910.09196</a></li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>Bielza, C., Gómez, M., &amp; Shenoy, P. P. (2011). A review of representation issues and modeling challenges with influence diagrams. Omega, 39(3), 227–241. https://doi.org/10.1016/j.omega.2010.07.003</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Home</a><a class="docs-footer-nextpage" href="../decision-model/">Decision Model »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 19 August 2020 07:55">Wednesday 19 August 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
